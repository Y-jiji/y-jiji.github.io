{"path":"_assets/Twenty-Five Years of Constructive Type Theory Proceedings of a Congress held in Venice, October 1995 (Giovanni Sambin, Jan M. Smith).pdf","text":"OXFORD LOGIC GUIDES: 36 General Editors DOV GABBAY ANGUS MACINTYRE DANA SCOTT OXFOR D LOGI C GUIDE S 1. Jane Bridge: Beginning model theory: the completeness theorem and some consequences 2. Michael Dummett: Elements of intuitionism 3. A.S. Troelstra: Choice sequences: a chapter of intuitionistic mathematics 4. J.L. Bell: Boolean-valued models and independence proofs in set theory (1st edition) 5. Krister Seberberg: Classical propositional operators: an exercise in the foundation of logic 6. G.C. Smith: The Boole-De Morgan correspondence 1842-1864 1. Alec Fisher: Formalnumber theory and computability: a work book 8. Anand Pillay: An introduction to stability theory 9. H.E. Rose: Subrecursion: functions and hierarchies 10. Michael Hallett: Cantorian set theory and limitation of size 11. R. Mansfield and G. Weitkamp: Recursive aspects of descriptive set theory 12. J.L. Bell: Boolean-valued models and independence proofs in set theory (2nd edition) 13. Melvin Fitting: Computability theory: semantics and logic programming 14. J.L. Bell: Toposes and local set theories: an introduction 15. R.Kaye: Models ofPeano arithmetic 16. J. Chapman and F. Rowbottom: Relative category theory and geometric morphisms: a logical approach 17. Stewart Shapiro: Foundations without foundationalism 18. John P. Cleave: A study of logics 19. R.M. Smullyan: Godel's incompleteness theorems 20. T.E. Forster: Set theory with a universal set: exploring an untyped universe 21. C. McLarty: Elementary categories, elementary toposes 22. R.M. Smullyan: Recursion theory for metamathematics 23. Peter Clote and Jan Krajicek: Arithmetic, proof theory, and computational complexity 24. A. Tarski: Introduction to logic and to the methodology of deductive sciences 25. G. Malinowski: Many valued logics 26. Alexandre Borovik and Ali Nesin: Groups of finite Morley rank 27. R.M. Smullyan: Diagonalization and self-reference 28. Dov M. Gabbay, Ian Hodkinson, and Mark Reynolds: Temporal logic: mathematical foundations and computational aspects: volume 1 29. Saharon Shelah: Cardinal arithmetic 30. Erik Sandewall: Features and fluents: volume I: a systematic approach to the representation of knowledge about dynamical systems 31. T.E. Forster: Set theory with a universal set: exploring an untyped universe (2nd edition) 32. Anand Pillay: Geometric stability theory 33. Dov. M. Gabbay: Labelled deductive systems 34. Raymond M. Smullyan and Melvin Fitting: Set theory and the continuum problem 35. Alexander Chagrov and Michael Zakharyaschev: Modal logic 36. G. Sambin and J. Smith: Twenty-five years of constructive type theory 37. Maria Manzano: Model theory 38. Dov M. Gabbay: Fibring logics Twenty-five Years of Constructive Type Theory Proceedings of a Congress Held in Venice, October 1995 Edited by GIOVANNI SAMBIN University of Padua, Italy and JAN M. SMITH Chalmers University of Technology, Goteborg, Sweden CLARENDO N PRES S • OXFOR D 1998 This book has been printed digitally and produced to a standard design in order to ensure its continuing availability OXFORD UNIVERSITY PRESS Great Clarendon Street, Oxford OX2 6DP Oxford University Press is a department of the University of Oxford. It furthers the University's objective of excellence in research, scholarship, and education by publishing worldwide in Oxford New York Auckland Bangkok Buenos Aires Cape Town Chennai Dar es Salaam Delhi Hong Kong Istanbul Karachi Kolkata Kuala Lumpur Madrid Melbourne Mexico City Mumbai Nairobi Sao Paulo Shanghai Singapore Taipei Tokyo Toronto with an associated company in Berlin Oxford is a registered trade mark of Oxford University Press in the UK and in certain other countries Published in the United States by Oxford University Press Inc., New York © Oxford University Press, 1998 The moral rights of the author have been asserted Database right Oxford University Press (maker) Reprinted 2002 All rights reserved. No part of this publication may be reproduced, stored in a retrieval system, or transmitted, in any form or by any means, without the prior permission in writing of Oxford University Press, or as expressly permitted by law, or under terms agreed with the appropriate reprographics rights organization. Enquiries concerning reproduction outside the scope of the above should be sent to the Rights Department, Oxford University Press, at the address above You must not circulate this book in any other binding or cover and you must impose this same condition on any acquirer A catalogue record for this book is available from the British Library Library of Congress Cataloging in Publication Data (Data available) ISBN 0-19-850127-7 Preface In lectures and a series of papers, beginning in 1970, Per Martin-L6f has developed a constructive foundation of mathematics, which he called intuitionistic type theory and which has come to be known as Martin-L6f 's type theory. This work has made an important contribution to the fields of logic and the foundations of mathematics and is also of broader philosophical significance. Its depth and relevance can be seen by its increasing application to a variety of fields from computing science to linguistics. The conference \"Twenty-five years of constructive type theory\" took place in Venice, 19-21 October 1995. It originated from a desire to celebrate the anniversary by gath- ering together those people who have worked or are still working on type theory and related topics. The idea for the meeting was indeed well received. The speakers - invited by a committee consisting of Furio Honsell, Giovanni Sambin (chair), Jan Smith, Goran Sundholm and Jan von Plato - were Peter Aczel, Stefano Berardi, Robert Constable, Thierry Coquand, Nicolaas Govert de Bruijn, Jean-Yves Girard, Martin Hofmann, Petri Maenpaa, Lena Magnusson, Per Martin-L6f, Christine Paulin, Aarne Ranta, Anton Set- zer, Goran Sundholm, William Tail, Silvio Valentini and Dirk van Dalen. The total number of participants was over fifty. Also, the magic surroundings of the unique city, the beautiful renaissance halls, and an extremely fortunate warm and sunny autumn, contributed to create something memorable. From pioneers to young researchers of type theory, all could meet each other, some for the first time, and interact in a stimu- lating and relaxed atmosphere. At the congress, the invited speakers and the committee together decided to publish the proceedings, but without restricting contributions to par- ticipants. Thus this book is the result of an open call for papers. Martin-Lof's first paper, in 1971, contained a theory with a universe V of all types and the axiom V € V, which was shown by Girard to be inconsistent. The following paper in 1972, \"An intuitionistic theory of types\", had instead a theory with a universe of small types, the resulting theory becoming predicative. It circulated only as a preprint of the Department of Mathematics, University of Stockholm. We are pleased to publish it here (with no change) for the first time. The next paper \"An intuitionistic theory of types: predicative part\", which was published in the proceedings of the Logic Collo- quium in Bristol, 1973, had a sequence VQ, ... ,V n ,... of universes and an inductively defined identity relation on each type. Compared with the paper in this volume, it had a different approach to syntax: the theory from 1973 had no variable binding opera- tions and the expressions were typed. Also, the normalization proof was more model theoretic in character. The works of Nicolaas Govert de Bruijn and William Tail played an important role in the early development of constructive type theory, and we are happy that they both contributed to this volume, de Bruijn designed Automath, the first system for computer- checked proofs. His contribution here is a dense and forceful overview of the problems vi Preface in the philosophy of mathematics connected with machine-verified proofs. This is also the subject of Robert Pollack's paper, based on his experience with the type theory implementation LEGO. Tait's normalization technique played a central role in Martin- Lof's early papers on type theory; here Tail gives an extension of the usual combinator calculus with S and K to a calculus in which the Curry-Howard isomorphism for full first-order arithmetic can be expressed. Catarina Coquand's paper is also related to normalization. She gives a realizability model of a type theory closely related, to the one of Martin-L6f in this volume; this theory is used in Half and Alfa, two recent computer implementations of type theory. The main original aim of Martin-L6f was to provide a formal foundation for con- structive mathematics, which should play a role analogous to that of Zermelo-Fraenkel set theory for classical mathematics. He later made it clear how his type theory could also be used as a system for program verification. In both cases, when using type theory as one's basic framework, it is convenient, even necessary, to extend it with new con- structs and notation. Gustavo Betarte and Alvaro Tasistro show how to add record types and subtyping to express algebraic structures and abstract data types. Giovanni Sam- bin and Silvio Valentini show in which way the usual informal notation and treatment of subsets is formally expressible inside type theory. Valentini also proves a metathe- orem giving a rigorous status to the treatment of the form of judgement saying that a proposition is true, with no mention of its proof. One role for type theory has been to provide the constructive setting for a devel- opment of topology, now known as formal topology. The work on subsets by Sambin and Valentini was intended as a tool for this. Formal topology provides an example of the use of type theory in mathematical practice and not only in metamathematics. Building on formal topology, Jan Cederquist, Thierry Coquand and Sara Negri give a proof of the Hahn-Banach theorem in functional analysis. This is a good example of how the type theoretic framework for formal topology makes it possible to give a fully formal and constructive treatment of a classical result that had seemed to be essentially non-constructive. A basic new feature of Martin-Lof's formulation of type theory is the extension to all types and type formers of the Curry-Howard formulae-as-type isomorphism. Thus any proposition becomes provable exactly when, viewed as a type, it is inhabited by some element. So the computational content of a proof is directly provided by the term inhabiting the type corresponding to the proposition proved. For this reason one of the main applications of type theory is to the derivation of programs from specifications, which guarantees that the programs are correct. Petri Maenpaa here relates program derivation to the method of analysis-synthesis from Ancient Greek mathematics. Con- siderable interest has arisen in recent years in extracting computational content from classical proofs. Stefano Baratella and Stefano Berardi give here a contribution to this field, using type theory as a metalanguage. Also related to classical logic is the paper by Karim Nour on storage operators, which is concerned with the efficiency of lazy evaluation. An important feature of Martin-Lof's formulation of type theory is the construc- tive treatment of identity, universes and well-orderings. Martin Hofmann and Preface vii Thomas Streicher introduce a model for type theory in which, surprisingly, the inter- pretation of an identity type may have several elements. Erik Palmgren discusses the notion of universe and introduces new ways of extending the hierarchy of universes. The metamathematical investigation of the proof theoretic strength of type theory with well- orderings has recently received renewed interest and new results have been obtained. Anton Setzer, one of those who have contributed to this area, gives an introduction to it here. Finally, we would like to thank all the institutions and people who made both the congress and this book possible. We thank the Consiglio Nazionale delle Ricerche, the Istituto Italiano per gli Studi Filosofici, the University of Helsinki and the Univer- sita di Padova for financial support. We thank Ateneo Veneto for providing a marvel- lous site for the congress. We thank all the authors who submitted a paper, as well as the referees who helped us in our selection and gave many valuable suggestions. We thank Michael Hedberg for transferring Martin-L6f's paper into LaTeX. Lastly, we thank Per Martin-L6f himself for his consent to publish his paper here. We hope that he will also consider this as an incentive to write down and publish some of his later lec- tures, which have always had such a profound influence. We have both been fortunate to be amongst his listeners for a very long time. Padova and Goteborg G. S. December 1997 J.M.S. Contents 1. Yet another constructivization of classical logic Stefano Baratella and Stefano Berardi 1 2. Extension of Martin-Lof's type theory with record types and subtyping Gustavo Betarte and Alvaro Tasistro 21 3. Type-theoretical checking and philosophy of mathematics Nicolaas Covert de Bruijn 41 4. The Hahn-Banach theorem in type theory Jan Cederquist, Thierry Coquand and Sara Negri 57 5. A realizability interpretation of Martin-Lof's type theory Catarina Coquand 73 6. The groupoid interpretation of type theory Martin Hofmann and Thomas Stretcher 83 7. Analytic program derivation in type theory PetriMaenpaa 113 8. An intuitionistic theory of types Per Martin-Lof 127 9. On storage operators Karim Nour 173 10. On universes in type theory Erik Palmgren 191 11. How to believe a machine-checked proof Robert Pollack 205 12. Building up a toolbox for Martin-Lof's type theory: subset theory Giovanni Sambin and Silvio Valentini 221 13. An introduction to well-ordering proofs in Martin-Lof's type theory Anton Setier 245 14. Variable-free formalization of the Curry-Howard theory William W. Tail 265 15. The forget-restore principle: a paradigmatic example Silvio Valentini 275 1 Yet another constructivization of classical logic Stefano Baratella Dipartimento di Matematica, University di Trento and Stefano Berardi Dipartimento di Informatica, University di Torino 1 Introduction The aim of this paper is to provide a way of extracting the constructive content of a certain family of classical proofs directly from the proofs themselves. The paper itself is written in a purely constructive style. Our work is inspired by the game interpretations of classical logic due to Novikov (1943) and Coquand (1995). These interpretations date back to Gentzen (1969) and Bernays (1970) and were recently studied by Coquand (1995) who made use of techni- cal tools developed by Novikov (1943). We will introduce an interpretation which is a short and compact description of the meaning assigned to classical formulas by Coquand's interpretation. Contrary to Coquand, we will completely avoid any game terminology, by making use of the intu- itionistic notion of continuous computation. A posteriori, our interpretation turns out to be related to Kreisel's no-counterexample interpretation (Kreisel 1957) but, compared with his, it provides simpler constructive proofs. The reader is referred to Baratella and Berardi (1997) for a number of examples of constructive proofs provided by our interpretation that can be used for a comparison. Indeed, our interpretation is a fragment of Coquand's that can be easily expanded to a variant of his. However, we claim that our interpretation suffices as long as we are only interested in the constructive meaning of classical formulas (whilst we need Coquand's if we are interested in computations lying behind the constructive meaning). We will support this claim by proving, as the main result, that our interpretation is intuitionistically complete, in the same way as Coquand's (Herbelin 1995). That is, we will intuitionistically prove that a formula is derivable in infmitary classical logic if and only if its interpretation holds. Since infinitary classical logic is classically complete, loosely speaking we can re- state our result as follows: the classical truth of a classical formula is intuitionistically equivalent to the intuitionistic truth of the constructive interpretation of the formula. 2 S. Baratella and S. Berardi We also recall that Godel's Dialectica interpretation is not intuitionistically com- plete (see section 7). In this regard, see also Berardi (1997). In addition, we point out that, contrary to the game interpretations, our interpretation is not a sort of reformulation of what is going on in the sequent calculus. It is based on the notion of Brouwer's continuity, which is central to intuitionism. Furthermore, if is our intuitionistic interpretation of a formula A, the possibility of recovering a classical proof of A from an intuitionistic proof of ) (as will be done in section 5) is not evident at all. The outline of the paper is as follows: in section 2 we introduce the notion of con- structive interpretation of classical logic. Then, by means of simple examples, we give an intuitive account of Coquand's interpretation and of ours. In this section we deliber- ately choose to remain informal. In section 3 we introduce an infinitary formalization of predicative classical logic. In section 4 we describe our interpretation , and relate it to Kreisel's no-counter- example interpretation, the most famous constructive interpretation of classical logic, which is similar to ours in the interpretation of formulas (but not of proofs). In section 5, we prove the intuitionistic completeness of . In section 7, we compare with Godel's functional interpretation and argue that the latter is not complete. So, roughly speaking, it does not preserve the \"classical meaning\" of a formula. 2 Intuitionistic interpretations of classical logic We begin by giving some intuition on how predicative classical logic can be understood from a constructive viewpoint. These ideas were introduced by Coquand (1995) and Herbelin (1995). We first recall some well-known facts. In an intuitionistic framework (where we will always operate), we say that we have a proof of the formula >, where are param- eters, if we can write a program taking i as input, and returning x such that holds. If P is not a decidable property, we also ask the program to return a proof of ~ ' \\ Since the statement P is simpler than the definition of proof of in terms of proof of P introduces no circularity. There is no way of proving intuitionistically the axiom of the excluded middle for an arbitrary formula A. If we write . as }.(£> is the truth value of A(x)), we see that, in order to prove i, we need a program taking x as input and returning the truth value of A(x) as output. In general, we can prove that no such program exists. If we want to interpret the excluded middle constructively, we have to weaken the interpretation of the existential quantifier. We now sketch how Coquand (1995) does it, by presenting and commenting on two examples of his. Example 2.1 Let P and Q be decidable predicates on the sets / and J, respectively. Assume that a classical proof of the formula _ is given, where Yet another constmctivization of classical logic 3 I is (a reformulation of) the only instance of excluded middle that has been used. We may intuitionistically interpret such an instance as a temporary assumption i, to be retained until we derive a contradiction. The only way to produce a contradiction is to find, in the sequel of the proof, some x such that P(x) holds (recall that P is decidable). In this case, we have an intuitionistic proof of and, a fortiori, one of As long as we only find the x for which —<P(x) holds, our temporary hypothesis ) is in force. If we reach the end of the proof without finding any x for which P(x) holds, then this means that the axiom is not really needed and can be replaced by (equivalently by , where x \\,... ,x n are the values of x tested during the proof). In any case we get a correct intuitionistic argument replacing the classical one. Coquand's argument can be made more compact by using the notion of continuous computation, which will be the main tool of this paper. In this example we got an intuitionistic proof of In other words, we got a computable function(al) F mapping a proof of , that is either a proof of or a proof of , to a proof of By decidability of Q, the latter actually pro- vides such that Q(y) holds. The map F is really a functional because a proof of is a function / on / such that f(x) is a proof of ->P(x), for every \" , Being computable, F is also continuous, so it will only use the values of / on some finite subset of /. Thus, F itself \"is\" a proof of By decidability of P(x), the premise is intuitionistically provable, so F yields a proof of ~ In this way, we also see that the meaning implicitly assigned by Coquand's interpretation to the formula as n and x\\,..., xn vary on the domains N and 7, respectively. Example 2.2 We show how Coquand's interpretation sketched in the previous example generalizes to arbitrary formulas. A careful analysis shows us that the classical meaning of .(b is the truth value of A(;t)) was previously interpreted as a guess at the value of b, together with the possibility of changing our guess finitely many times only (at most twice in the previous example). This suggests to Coquand the constructive interpretation of the classical meaning of, say, where F is a decidable predicate, as the existence of a program producing a temporary guess XQ at a value for x such that holds. Then the program waits for a counterexample, namely for VQ such that • holds, and, „ , is indeed the conjunction of all formulas 4 S. Baratella and S. Berardi in such a case, it returns a new guess x\\. Then it waits for a y\\ such that ->P(x\\,y\\) holds and so on. Eventually, the program must stop. In other words, we require the tree of all possible sequences XQ, yo, x\\, y\\, X2, y>2, • • • being well-founded. So, following Coquand, we are led to interpret the classical truth of the statement (i given by (every function / : N -» N attains a minimum) as follows. We have a program which starts running with a guess XQ at the minimum point of / and then waits for some yo such that j . If such a yo is received, the program returns yo as a new (improved) guess, so x\\ is now yo. If the program gets some y\\ such that ), then it chooses y\\ as the new guess X2, etc. Eventually, the computation ends by well-foundedness of natural numbers. From this example we also see that our intuitionistic interpretation of the \"classical\" existential quantifier is weaker than its usual intuitionistic interpretation. For, /u, is intu- itionistically true if we can actually compute a minimum point x of /, but this cannot be done in general. We may think of using the program described above for comput- ing a minimum point of / in this way: after receiving xt, if there some y/ such that f(yi) < /(*i)> w e sen d it back to the program. If not, then xi is a minimum. Unfor- tunately, this is impossible: there is no way of deciding, in general, whether a given xi is a minimum point of / or if there is some point y,- on which / takes a smaller value. If the program stops at xt, either it found a minimum point of /, or it just received no other y;. In the second case, Xj is indeed a minimum point of / on {yo,..., y<-i}, but not on the whole N. Again, Coquand's argument can be simplified by appealing to continuity, if we are not interested in how the set {yo,..., y/-i} was found, that is if we are not interested in the details of computations defined by our interpretation. For, suppose ^ is the only classical theorem used in the proof of , with Q decidable. Then we have an intuitionistic proof of, i, that is a continuous functional from proofs of , to proof of _ ,„ )• A proof of fi can be viewed as a pair (x,h x), where and h x is a map with h x (y) a proof of , for all Being continuous on each argument (x,h x) the functional F needs the values of h x only on a finite subset N* of N. Thus F is actually a proof of We have already noted that is intuitionistically provable, so we can obtain a proof of ~ - - f ro m p_ implicitly, Coquand interprets /^ as the intuitionistic validity of for every map defining a family of finite subsets N* of N. We are now ready for an overview of Coquand's interpretation. Informally, a (pos- sibly wrong) argument in favour of the truth of is a program returning a temporary guess XQ, and a (possibly wrong) argument po in favour of the truth of P (XQ) . If a counterexample for the argument po is found, the program tries with a new guess Yet another constructivization of classical logic 5 x\\ and a new argument p\\ in favour of the truth of P(x\\), and so on. Eventually the program terminates (the tree of all possible computations is well-founded), either giv- ing up or because no further counterexample was found for its argument. A proof of is an argument for never giving up and an argument (proof) for is a family of arguments (proofs), one for each P(x). As already re- marked, since the statement P(x) is simpler than i and there is no circularity in the definition. The only restriction is that it applies exclusively to predicative statements (a class of statements to be described in the next section). In order to formalize this informal description, we need to define what arguments, proofs and counterexamples are. Coquand (1995) proposed to interpret arguments and counterexamples as strategies for suitable games and proofs as winning strategies for those games. His proposal has the advantage of describing in great detail the compu- tations defined by the constructive interpretation. Yet, for the same reason, it has the drawback of somehow hiding the meaning of the formula being interpreted. Assuming that we are only interested in such a meaning, we want to interpret a classical proof of a formula A as an intuitionistic proof of all possible \"restrictions\" of A obtained by lim- iting the range of each universal quantifier in A to a finite subdomain, as we did in the previous examples. We will use the term simulation for \"restriction\". Thus, a classical proof of A will be interpreted as a continuous map accepting as input a simulation of A and returning as output an intuitionistic proof of such a simulation. We will see how to do it in section 4, after introducing the classical logic CL. 3 Predicative classical logic CL In this section we provide an infinitary formalization of predicative classical logic (in short, CL). In the next section we will present our interpretation of CL. We fix a set Atoms, whose elements are actually atomic statements of elementary mathematics. We assume that Atoms contains, for every the statements and The set L of formulas of CL is inductively defined as follows. Definition 3.1 (1) a and are in L, for every atom a. (2) If is a family of formulas of L, and I is either finite or enumerated, then and are in L. We introduce some notation and definitions relative to L. Atoms will be denoted with lower case letters a, b, c, ... and formulas with upper case letters A, B,C, .... We call a negated atom, a and - atomic formulas, „ ind quantified formulas (respectively, existential and universal) with domain / . The negation or dual of A is the formula obtained by switching V with and a with , for every atom a in A. Note that is involutory, namely for every formula A. We will write and , for and , respectively. Also, . _ . _ will be abbreviated to We will write nested indices, like (.. . ((A x) y)...), in the more readable form Ax<y<,,.. Here is an example: starting from the double-indexed family 6 S. Baratella and S. Berardi we may first form and then . If Ax<y is the atom , for , _, _ \"\", we feel free to write the previous formula as \"•. More generally, every first-order arithmetical formula (or formula of Peano arithmetic), with free variables in x\\,..., x n , can be thought as an abbreviation for a family of elements of L. It suffices to interpret first-order quantifiers V by , in by on a finite domain; and - respectively. Every closed formula is an abbreviation for a single element of L. We will often write closed first-order arithmetical formulas while indeed referring to the elements of L they abbreviate. The instances of a quantified formula, or ' , are the A x for The subformulas of a formula A are inductively defined as A itself, and all subformulas of some instance of A, when A is quantified. We keep distinct different occurrences of the same subformula. 1 A formula with no proper subformulas is said to be minimal. Minimal formulas are all the atomic formulas and We now fix a metatheory to be used in the sequel when dealing with L. Any in- tuitionistic set of principles, including first-order connectives, quantifications on func- tions, functionals, etc., and inductive definitions will do. In particular, the reader may assume that we are using, in a very informal way, the intuitionistic principles of Martin- Lof 's type theory (Dybjer 1994). Whenever we claim that we have a proof of a certain statement, we mean that a proof can be formalized in Martin-L6f's type theory. When saying that a statement holds classically, we will actually mean that it can be proved in Martin-L6f 's type theory plus the principle of the excluded middle. Sometimes we will also say that a given statement does not hold intuitionistically: the meaning of such an assertion will be explained case by case. In what follows a total order < on a set / is well-founded if the following holds for every property P: We inductively define a predicate (_ is true) on L, assigning to each , a statement (A is true), interpreting A in our metalanguage. We fix a decidable subset Atomstrue of Atoms, consisting of exactly those atoms we want to interpret as true statements. We also assume that t are in Atoms true if and only if « is equal to, less than, less than or equal to m, respectively. We can now give an inductive definition of (A is true). Definition 3.2 (1) (a is true) if a & Atoms true and (^ is true) if , for an atom a. (2) if I for some. if ( ' for all Since membership of Atoms true is decidable, truth of atomic formulas is decidable (and in general only of atomic formulas). We will often abbreviate (A is true) by \"A 1 Alternatively, one may represent formulas as labelled trees and occurrences as nodes of such trees. How - ever, we choose to remain more informal. Yet another constructivization of classical logic 1 true\", and ->(A is true) by \"A is false\". The reader acquainted with intuitionism may notice that ( ' is true) is, in general, intuitionistically stronger (more informative) than - | (A is true) and that the two are classically equivalent. In order to complete the description of CL, we still have to introduce its deduction rules. We assume that a set £ of Post rules of the form is given. We also assume that is complete with respect to our interpretation. In other words, we assume that a is derivable if and only if a is true, and that j is derivable if and only if a is false. Deduction rules of CL will infer finite lists A \\,..., An of formulas, or contexts. We will denote contexts by , , We say that a context F is true if some is true. Deduction rules in CL will be classical, so we will be able to derive in CL contexts that cannot be proved true in our intuitionistic metalanguage. The rules of CL are: i. if the rule - is in . ii. if the rule a\\,..., an a is in iii. iv. v. We say that CL proves (notation: CL F) if there exists a well-founded proof of F. We write CL A as an abbreviation for CL {A}. Here are some elementary properties of . together with some remarks: (1) ._ ._ (proof: by induction on A). (2) if and only if ( for all „ ^ . (proof: by induction on the proof tree of ). (3) If then (proof: by induction on the proof tree). (4) If F then ' (proof: by induction on the proof tree). (5) CL has only normal proofs. Let us return to the notion of truth that we introduced for contexts. The logic CL is classically complete, that is ( (A is true) holds classically for every for- mula A (Tail 1968). Thus, we may think of' ' as an intuitionistic translation of the statement \"A is classically true\". Since truth is decidable on atoms, all rules of CL, with the exception of the V-rule, are intuitionistically sound (i.e. we can intuitionisti- cally prove that they produce true contexts from true contexts). Regarding the V-rule, in general we cannot intuitionistically prove that , F is true under the assump- tion that A x , P is true for all . In order to know whether or is true, we need to know whether, for any . the context A x, F is true because A x is, or if, for some it is true because is. This is impossible in general, unless / is finite. Thus we cannot intuitionistically prove that (A is true) holds for every formula A. The converse can be proved by induction on A. The point is that we are comparing 8 S. Baratella and S. Berardi the notion of classical truth, of which is an intuitionistic translation, with that of intuitionistic truth expressed by (A is true). Since our metatheory is intuitionistic, then (A is true) actually means \"A is intuitionistically true\". Hence the reason why only one implication holds. Let us call simply existential a formula whose universal quantifiers are all bound to finite sets. Every proof tree of a context consisting of simply existential formulas uses the V-rule only on finite sets: this can be proved by induction on the proof tree. Hence all of its rules are intuitionistically correct. Thus, we can intuitionistically prove (A is true), by induction on simply existential formulas. As we have already said, (A is true) ) holds for every formula A (proof: by induction on A, using the properties of 4 Our interpretation In this section we introduce our interpretation and prove that it is intuitionistically complete; in other words, that ) holds intuitionistically if and only if A holds clas- sically. The first part of this section provides an intuitionistic translation of the notion of continuity for which the notion of well-founded tree is needed. In the sequel, concate- nation of sequences will be denoted simply by justaxposition. Definition 4.1 A well-founded tree T is a set of sequences over an enumerated set, including the empty sequence ( ), downward closed, well-founded with respect to the extension relation on sequences and such that for each sequence belonging to the tree we know the list of its one-step extensions, and we know if it is finite or infinite. The elements of T are called nodes, the empty sequence is the root of T and the maximal sequences are the leaves ofT. Given any two sets / and J, we denote by the set of all functions from / to / . We now introduce the intuitionistic (strongly) continuous functionals. Intuitively, a functional is strongly continuous if its \"tree of all possible computations\" (a concept formalized by the notion of question/answer tree given below) is well-founded. Definition 4.2 Let /, J and K be effectively enumerated sets. Let and . Strongly continuous functionals are inductively defined as follows: F is strongly continuous on H if either F is constant, or, for some and all , F is strongly continuous on _ _ \\ , „}. An equivalent definition is given in the sequel, after some preliminary definitions. (1) A question/answer pair fin short, q/a pair) for the functional F is a pair (i, j), with and Intuitively, a q/a for F represents a request of F, during the computation of F(f), for the value j = /(/) . If fy is any finite list of q/a pairs, then we write /o for all (i, j) in fy. (2) A question/answer tree for F is, roughly speaking, the tree of all possible se- quences of q/a pairs between F and some of its inputs f. Formally, a tree T on is a q/a tree for F if and only if the branching from any either consists, for some , of all nodes /o(i, j) for _ , or is empty. In this case fy is a maximal sequence in T and we require that for all Yet another constructivization of classical logic 9 f such that % we have F(f) = F(g). (3) A functional is weakly continuous if and only if for all there is some and some finite such that F(g) = k for all including /o. (4) A functional . _ „ — 'is strongly continuous if and only if there exists a well-founded q/a tree for F. Intuitionistically, strong continuity implies weak continuity. The converse holds if we assume CL and the axiom of choice. From a classical viewpoint, strong continuity is just a reformulation of the notion of continuity, chosen in order to bypass the use of excluded middle in our metatheory. From now on, whenever we say \"continuous\", we will actually mean \"strongly continuous\". IfJ _ and / ~~, then the restriction of / to /o will be denoted by / f/o and H f/o will denote the set ~ ~ ~\". Suppose F\\,..., Fn are continuous on H \\I\\, ..., H [/„, respectively. For every g : we can define a functional F on H, called the sequentialization of F\\, ..., Fn with respect to g, by The functional F is continuous on H. A proof of this fact is by principal induction over n and secondary induction over the q/a trees of the Ff . Intuitively, this means that F can be computed by computing in sequence F\\,..., Fn. So far we have just introduced the notion of continuity. According to what we said in the introduction, we want to interpret a proof of any formula by a continuous functional mapping each \"restriction\" of A into a proof of such a restriction. Hence, we still have to define what a restriction (but we will use the word simulation) of a formula is. We begin with some examples. A simulation of , where the ax are atoms, is a finite conjunction , of instances of the formula. More generally, we obtain a simulation of / - by hereditarily replacing every subformula of A with some conjunction ~ ~ , of its instances. A simulation is a simple existential statement. For instance, let A be the formula A simulation of A is . For every , what we have done is to replace the instance of A by by Notice that every instance of A has been replaced by a different conjunction: this is possible because we consider different instances of A as different subformulas. Now we introduce the formal definition. We will also define simulations of con- texts. In the sequel we will say that a formula is a subformula of a context if it is a subformula of some formula in F. Given a set /, we will denote by ) the set of finite subsets of / and by the set Definition 4.3 Let be a context. (1) A simulation map a for F is a function from an arbitrary subset of the set of oc- currences of universal subformulas of T, such that (I) for 10 S. Baratella and S. Berardi all in dom(a). Different occurrences of the same universal subformula may be replaced by different formulas. (2) Let a be a simulation map for . Then _ L. 3 is the context obtained from by replacing every universal subformula ' in dom where We call simulation of , we write < . _ for An inductive definition of simulation can also be given: (1) If a is any atom, the only simulations of a and are a and „ .respectively. (2) If for each the formula is a simulation of , then : is a simulation oi (3) If for each the formula is a simulation of , then is a simulation of' for every Notice that the axiom of choice is needed in order to prove the equivalence of the two definitions of simulation. We are now ready to define our interpretation 1 We first provide an example. Let A be the classical formula where P is an arbitrary mapping from to the set of atoms. Intuitively, • i) means that there exists a continuous functional depending on the maps ), and both restricting the range of each universal quantifier in A to a finite subdomain. The functional returns an intuitionistic proof of the restriction Formally, we have the following: Definition 4.4 Let rhen L) is the metalinguistic statement \"there exists a (strongly) continuous functional F : (simulations of A} —> (finite proofs in CL} such that F(a) is a proof of a [A], for every a\". Remember that a finite proof in CL is actually an intuitionistic proof. A posteriori, the interpretation inspired by Coquand's work, is closely related to Kreisel's no- counterexample interpretation. Kreisel's interpretation can be obtained from ours by forcing each simulation to take singletons as values, whenever possible. At the level of formulas, the differences between our interpretation and Kreisel's are minor for what concerns the theory, but relevant in practice. For, Kreisel deals with negations of counter examples of a formula A, thus conceptually using two nested negations. On the contrary, we \"think positive\" by considering finite approximations of A. Furthermore, since a Yet another constructivization of classical logic 11 simulation takes not only singletons as values, our approximations of A can get \"as close as we want\" to A. The main difference between our interpretation and Kreisel's lies in the interpretation of proofs, where we rather followed (a simplified version of) Coquand's ideas. The interpretation is sound, whenever we have we also have . This means that we can effectively turn a classical proof of A into an intuitionistic proof of , which is, in general, intuitionistically strictly weaker than A. Moreover, ) and (A is true) are classically equivalent and they are also intu- itionistically equivalent on simply existential formulas. The former property implies that we may think of a substitution of A with in a classical proof just as a choice of a particular reformulation of the goal A of the proof, chosen to bypass the use of excluded middle. The latter property implies that if we classically proved a simply existential state- ment A, expressing, say, the existence of an integer x having some decidable property, we can effectively turn the classical proof first into a proof of • ), and then into an intuitionistic proof of (the truth of) A. Since from an intuitionistic proof of A we can ef- fectively compute such an x, by means of we are able to extract concrete information from a classical proof. All the properties of just mentioned are proved in the following: Lemma 4.5 For every . we have: (1) (2) (3) . (4) ''\"—>• (A is true), if A simply existential. However, in general, is intu- itionistically strictly weaker than the truth of A. (5) Suppose either (A is true) or ( is true). Then (A is true) «-» Hence (A is true) -o- holds classically. Proof (1) Let We define a continuous functional F mapping a simulation < of F to a proof ( [~~] of . NF) and then we prove its continuity. Our thesis follows by taking . Let n be a proof tree foran d letb e a simulation of All formulas occurring in n are subformulas of F. For any node in , replace J by . Then remove all the assumptions for . The tree i so obtained is a proof of the simulation ] of which is intuitionistically correct because all universal quantifiers are restricted to finite domains. It follows that all simulations of A are intuitionistically provable. We define F by . The continuity of F can be proved by in- duction on by distinguishing a number of cases according to the last rule in . Here we only consider the case when ends with a V-rule. Then F is and the premises of are ^ , for each By (the 12 S. Baratella and S. Berardi first) definition of continuity, we have just to define a continuous functional /% on H = (simulations on : }, for each finite sub- set } of /. By induction hypothesis, we can define functionals FI , ... , Fn which are continuous on the simulations of respectively. Since each subformula of . is (identified with) some subfor- mula of F, we can extend these functionals to functionals on simulations of . , for simplicity still denoted by FI, ..., Fn. We can now define a functional F on H. We let be the proof of obtained by composing with a V-introduction on the domain /Q. The functional F is continuous because it is the sequentialization of FI ,..., Fn. (2) Follows from (A is true) -> and from the previous point. (3) Assume in order to find some simulation a such that - . We argue intu- itionistically by induction on A. If A is a or , then is the same as —>A and the conclusion follows easily. Let A be : . By induction hypothesis, for all we have that - implies • , for some simulation of A x . From the assumption we get that there is some ; and some simulation for such that - holds. We can extend to a simulation for A, such that . For such _ J clearly holds. Let A be By induction hypothesis and by assuming we have that for every .. _ _ there exists a simulation of Ax such that - holds. By applying the axiom of choice, we get a family =/ of simulations for each A x and, from it, a simulation of A. For such a < , ^ ] does hold. (4) If A is simply existential, a simulation of A is A itself. One can prove that \\ does not hold intuitionistically for every for- mula, by taking as A any classically but not intuitionistically provable formula. (5) Follows from (1) and (2). D Note that, when intuitionistically proving ( , we described how to obtain from a proof of A a continuous functional F mapping a simulation of A into a proof of < The reader may wonder which role is played by the continuity of F in the proof of the previous lemma. Indeed, none: we could have proved the same properties for an interpretation such that L) means \"there exists functional F from simulations of A to finite proofs in CL such that is a proof of > ,,for every •\". Such an interpretation of a formula in L (i.e. Kreisel's interpretation with the continuity requirement dropped) was studied by Godel (1958). See also Shoenfield (1967), ch. 8. The point is that i is strictly weaker than from an intuitionistic viewpoint. Indeed, we cannot prove for every formula A that if we do not assume the continuity of F. Otherwise stated, is not intuitionistically complete. See Kreisel (1951) or section 7 for a proof. Yet another constructivization of classical logic 13 5 Intuitionistic completeness of We prove in this section that is intuitionistically equivalent to ( , that is to the classical truth of A. This means that retains one of the two main properties of Coquand's interpretation (the other one will be briefly discussed in section 6). The idea is to reverse the process that led to a definition of a functional F from a proof of A in CL in the proof of lemma 4.5 (point 1). After some preliminary notions, we introduce the notion of connected functional that singles out the functionals obtained from proofs in CL. Intuitively, a continuous functional F from simulations of a given formula A to finite proofs in CL is connected if the following holds for every simulation a in the domain of F and every subformula B of A: if cr(B) is requested at some point of the computation of , ) then the value I has already been requested for all the universal subformulas C in the subformula path from A to B. On one hand, a functional obtained from a classical proof of A as in the proof of lemma 4.5 is connected. The reason is that a subformula B of A can appear in a branch of a proof of A only when all subformulas between A and B have already appeared in the same branch. On the other hand, it is easier to reconstruct a classical proof of A from a functional as in definition 4.4, when such a functional is connected. Definition 5.1 A finite simulation map is a simulation map with finite domain, that is one defined only on a finite number of universal subformulas of a formula (recall from the definition of subformula given in section 2 that the instances of a quantified formula are pairwise distinct formulas, and hence a quantified formula may have infinitely many universal subformulas). Notice that, in a q/a tree relative to a functional, every branch can be identified with a finite simulation whenever the set of its nodes satisfies the usual condition of functionality. In general, there are branches of a q/a tree that do not correspond to any simulation. For, it may be that a branch contains two different answers relative to the same instance of a universal formula. Of course, those branches do not correspond to any computation; nevertheless they appear in the q/a tree. Definition 5.2 Let be a finite simulation. (1) CTO is unary if is a singleton for every Notice that all uni- versal formulas occurring in the domain of a unary simulation have non-empty domain. (2) The formula Bz is a -instance of if t \\ and (3) Let B be a subformula of A, and A = B\\, ..., Bn = B be the subformula path from A to B. We say that B is connected by if whenever and B,: is universal then BI+\\ is a ^-instance ofE{. o is connected if all points in dom( N are connected by (4) A continuous functional F : {simulations of A} -> {finite proofs in CL} is con- nected if it has a q/a tree whose branches are all connected finite simulations. 14 S. Baratella and S. Berardi We claim the following: Claim 1 Each continuous functional on simulations can be turned into a connected functional defined only on unary simulations. Claim 2 From a connected functional defined only on unary substitutions we can recover a proof of A in CL. Intuitionistic completeness of follows from the two claims. Claim 1 is crucial because one cannot directly recover a classical proof of a formula from a continuous functional when the functional is not connected. This is formally stated in the following: Lemma 5.3 Let , and let F be a continuous functional such that - x_ , .s a proof °f -> fo r every simulation a of A. Then there exists a continuous and connected functional G defined only on unary simulations such that ( s a proof of t u J( for every i Proof We define G on a unary simulation by creating a correspondence between nodes of the computation of and nodes of the computation of , , where_ • is defined by _ v _, _ v _ , if B is a universal subformula of A connected by and by otherwise. Let X be the last node of the computation of < I already defined (we let X = () = root of the q/a tree of G, at the beginning) and let Y be the node in the computation of that has been associated to it (with Y = () = root of the q/a tree of F, at the beginning). If Y is a leaf of F, then the computation of is over, and we let Otherwise, let be the immediate successor of Y in the compu- tation of : the intuition i s that B i s the question and < ) i s the answer. Let C{,..., Cn = B be the list of the universal formulas in the subformula path from A to B (endpoints included). By definition, C\\ is a -connected. Let z = max n and C/ is < - connected} and let ; Then we associate with Y' all nodes from X (excluded) to X' (included). Intuitively, G explores the subformula path from A to B and checks if some a- instance of C\\, €2,... is in the path from A to B or not. G stops at the last a -connected Cj, namely at Q . If; , then B is not cr-connected, so and X' is associated with Roughly speaking, this means that, B not being -connected, the (trivial) value of B is skipped in the computation of G. If z = «, then B = Cj is -connected, so i and * is associated with , Intuitively, this corresponds to the fact that the value of B is used in the computation of G, because B is cr-connected. Notice that, by definition, G is allowed to reuse the same values many times. We might avoid this drawback by complicating the definition of G a bit, but we prefer to keep it as simple as possible. Yet another constructivization of classical logic 15 We can now define the q/a tree of G from the set of the X corresponding to some , for some a. We just have to add, for each , all nodes of the form ), for all finite subsets l\\ of I. The functional G is connected by construction. It is also continuous: by induction on Y one can prove that its q/a tree is well-founded. To finish, we have to show that ) is actually a proof of a [A]. Indeed, one can prove inductively that, for every sub- formula B of A connected by , we have ]. By definition, A is connected by and so |. The conclusion follows by noticing that is a proof of ], and hence of i D Before proving claim 2, we need a technical result. Lemma 5.4 Let A and F be as in lemma 5.3 and let <JQ be a unary simulation which is a leaf in the q/a tree of F. Then there exists a subformula B of A which is minimal and connected by DO such that Proof By definition of the q/a tree of F, there exists a proof tree such that for every simulation of A extending Let us choose a extending CTQ defined by 'or all _ . Then _ _ and, being , unary, the domain of every universal quantification in has cardinality\" Since all conjunctions in are trivial, then is equivalent to an infinitary disjunction of its minimal subformulas. Also, is (intuitionistically) true because it is simply existential and provable in CL. By induction on A we can prove that if < is true, then some minimal subformula of | is true and hence provable in CL. Since a minimal formula is either atomic or an empty quantification, then is actually a subformula of A. The formula B is connected by and hence by by choice of , D We will now prove claim 2 and intuitionistic completeness. The proof is quite in- volved, the reason being that it depends very closely on the features of the functional whose existence is claimed by the statement . We have already mentioned that we may not have intuitionistic completeness without assuming strong continuity of the functional (see section 7). Theorem 5.5 For we have Proof We argue by induction on A. The case A minimal is trivial. If A is universal, by induction hypothesis and the axiom of choice we have a family of proofs in CL, one for each instance of A. By performing a V-introduction, we get a proof of A in CL. The only case left is A existential and not minimal. Assume By lemma 5.3, there exists a continuous and connected functional F taking unary simulations a of A to finite proofs of • in CL. Let T be the q/a tree of F. Recall that some branches of T \"are\" finite simulations (see remark after definition 5.1). We define a proof 1 : A in CL by associating to each finite simulation t „ _ T a node X of , decorated by a context We define such an X by induction on CTQ- The idea is to associate with each pair i list of 3-introductions in '. followed by a V-introduction of the formula B. We will prove simultaneously that: 16 5. Baratella and S. Berardi (a) (b) contains the set of -instances of formulas in ( v „) which are not in ). We will need conditions (a) and (b) when defining the correspondence between T and FT and also when defining the leaves of __. Suppose is the empty substitution. Then we associate with it the root X = () of , decorated by the context A. The node X satisfies (a) and (b) with Suppose now that satisfies the induction hypothesis, and let X be the node as- sociated to it. Every unary simulation one-step extending is of the form }, for some universal subformula and some ^ _ „ . To each such TO we associate the node , or a node X' extending X if . We split the case into two subcases. In order to understand what follows, it is convenient to think of the tree as having the root at the bottom and being constructed upwards. Subcase 1 Suppose first that all formulas (distinct from B) in the subformula path from A to B are existential. As node X' associated to ro we then take X concatenated (in reverse order) to the zo-th hypothesis of a V-introduction inferring B, followed by a sequence of 3-introductions inferring A from Recall that A is in the decoration of X by (a). Note also that, since to is in the q/a tree of F and . , then < is a unary simulation in the q/a tree of F, for all : this makes the V-introduction correct. Example 1 Let A be the formula , with B the formula , for some XQ, yo- Assume that the node X associ- ated to CTO is decorated by some context A. Then we extend X with three new nodes whose decorations (from top to bottom) are The corresponding bit of derivation is the following: The node X' satisfies the induction hypothesis: A is in the decoration of X, and hence of X' (the only formula we remove when going upwards is B, which is universal). Condition (b) also holds. For, let be a ro-instance of . __.: we Yet another constructivization of classical logic 17 claim that D is in the decoration of X'. HE = B, then D = Bl(}, and D is in the decoration of X' by construction. If then . The formula D is in the decoration of X by induction hypothesis (b) and by T If D were not in the decoration of X', then D would be the conclusion of some V-rule between X and X''. By construction of X', the only possibility is B = D, but then would contradict Subcase 2 Suppose there is some universal formula distinct from B in the subformula path from A to B. Let be the one closest to B. By connectedness of F, B is connected by TO', hence we have < ), and thus ) since Since is unary, is a singleton, say . Note also that if it were <~ ' then , would be universal and, by choice of C, it would be ), contradicting Thus and, by \" ' ' ' \" an d induction hypothesis, is in th e decoration o f th e node X associated to ~ As node X' associated to TO, we then take X concatenated (in reverse order) to the zo-th assumption of a V-introduction inferring B, followed by a sequence of 3-introductions inferring from ,8. Example 2 Let be the formula and let B be the formula , . Assume that the node X associated to OQ is decorated by the context T, C(u;o)- We extend X by three new nodes whose decorations (from top to bottom) are The corresponding bit of derivation is the following: The node X' satisfies (a) and (b) and, again, A is in the decoration of X, and hence of X'. Now let be a ro-instance of - - , „, we claim that D is in the decoration of X'. If E = B, then , , and D is in the decoration of X' by construction. If , then , By induction hypothesis (b) and , then D is in the decoration of X. If D were not in the decoration of X', then D would be the conclusion of some V-rule between X and X'. By construction of X', the only possibility is B = D. But B, contradicts In both the previous cases, if is maximal in T, since is unary, by lemma 5.4 there exists a minimal formula D which is provable in CL and is connected by By 18 S. Baratella and S. Berardi connectedness of F and by , _,i (since TO is unary), the formulas in dom( between A and D are exactly the universal formulas between A and D (excluded). Let C be the only ro-instance of if , and C = A if n = 0. If by construction, C is between A and D but after £\"„, and hence not in dom(ro). So, by induction hypotheses (a) and (b), in any case C is in the decoration of X. By the choice of C, between D (excluded) and C there are only existential formulas. So one can extend the node X (whose decoration contains C) with a proof of C from D and then a proof of D. The reader can easily work out an example in this case. By induction on the depth of T we can check that we get a well-founded tree, which is a proof tree of A because, by construction, each node corresponds to a correct logical rule and all branches end with axioms. D 6 Conclusion In this paper we have provided a constructive interpretation of classical formulas (defi- nition 4.4) that turns out to be intuitionistically complete. That is, the classical truth of a classical formula is intuitionistically equivalent to the intuitionistic truth of the con- structive interpretation of the formula (lemma 4.5 and theorem 5.5). In order to do this, we have introduced the crucial notion of simulation of a formula (definition 4.3). As already mentioned in the introduction, other interpretations either lack intuition- istic completeness (like Godel's) or lead to constructive proofs that are more compli- cated than those obtained from ours (like Kreisel's). We want to point out another feature of our interpretation: formalizing it in induc- tive type theory, one can prove that the set of classical (normal) proofs of the original formula and the set of intuitionistic (normal) proofs of its interpretation are isomorphic (in a sense that can be made precise). This result is inspired by the isomorphism theo- rem between game strategies for Coquand's interpretation and infinitary proofs proved by Herbelin (1995), chapter 6. This is an easy consequence of intuititionistic complete- ness, yet we consider it crucial. For, in type theory, the structure of the set of (normal) proofs of a formula is supposed to be an implicit description of the meaning of the formula. If we share this position, we get that the meaning of a formula and of its inter- pretation are really very close. From a more practical viewpoint, the isomorphism result implies that we may \"see\" an intuitionistic proof directly \"inside\" a classical proof and that it is possible to recover the original classical proof from its intuitionistic translation. Such a possibility of \"back-and-forth\" makes our interpretation particularly flexible, as can be seen in Baratella and Berardi (1997). 7 Appendix: intuitionistic incompleteness of Godel's Dialectica interpretation Let <f> be the interpretation briefly discussed at the end of section 4. In this section we show the intuitionistic unprovability of the statement FC given by The interpretation 0 is a trivial variant of Godel's Dialectica interpretation (Godel 1958), restricted to formulas of L. In L, negation is pushed down to atomic Yet another constructivization of classical logic 19 formulas, and hence Godel's interpretation requires functions but not functionals (Shoenfield 1967). We begin with a well-known fact (Beeson 1985): we cannot intuitionistically prove -•CT, where CT is simulation a on A.( is recursive).2 If we prove that FC implies —•CT, the unprovability of FC will follow from the unprovability of —>CT. Assume FC and CT, in order to find a contradiction. Let i be the relativization of to the recursive simulation maps, that is the statement ] is true), where r runs on recursive simulation maps. If all simulations were recursive, then FC would be equivalent to ). In order to get a contradiction, it suffices to find a formula B such that f and Let • Atoms be a recursive map such that T(e, x, y) is true if and only if the recursive map of code e applied to the input x converges in y steps. So T represents Kleene's predicate in CL. Let j / be The intuitive meaning of B is that there exists a recursive map of code e that is simul- taneously convergent and divergent on some input x. Clearly, Hence, by consistency of CL, ., _ . It remains to show , that is intuitionistically true for every recursive simulation map a. We can view a as a recursive map Thentr[S]is It suffices to find e such that the recursive map of code e converges on input e and holds. Notice that L is decidable because a and T are recursive and N£]e is finite. Let m be the code of a partial recursive function with domain {e : Q(e)}. By definition of m, the function of code m converges on m if and only if Q(ni) holds. On the other hand, if —•Q(m) then the function of code m converges on input m, by definition of Q. Thus, assuming — >Q(m), we derive Q(tri). Hence Q(ni) holds and so the function of code m converges on m. Now take now e = m. We get that a(B) is intuitionistically true for every recursive simulation map a. So holds but 2We mean that -^CT is not provable in any intuitionistic system, in particular in Martin-Lof s type theory. In order to see this, it suffices to define a model of Martin-Lof's type theory in which sets are sets and maps are the recursive maps. In such a model CT is true. Hence —<CT is not provable. 20 S. Baratella and S. Berardi Bibliography Baratella, S. and Berardi, S. (1997). Approximating classical theorems. In preparation. Beeson, M. J. (1985). Foundations of constructive mathematics: metamathematical studies. Springer-Verlag, Berlin. Berardi, S. (1997). Intuitionistic completeness of classical logic. To appear in Journal of Symbolic Logic, in press. Bernays, P. (1970). On the original Gentzen consistency proof for number theory. In Intuitionism and proof theory. A. Kino, J. Myhill and R. E. Vesley editors. North- Holland, Amsterdam, 409-^17. Coquand, T. (1995). A semantic of evidence for classical arithmetic. Journal of Sym- bolic Logic, 60, 325-337. Dybjer, P. (1994). Inductive families. Formal Aspects of Computing, 6,440-465. Gentzen, G. (1969). The collected papers of Gerhard Gentzen. M. E. Szabo editor. North-Holland, Amsterdam. Godel, K. (1958). Uber eine bisher noch nicht beniitzte Erweiterung des finiten Stand- punktes. Dialectica, 12, 280-287. Herbelin, H. (1995). Sequents qu'on calcule. Ph.D. Thesis. University of Paris VII. Kreisel, G. (1951). On the interpretation of non-finist proofs. Journal of Symbolic Logic, 16, 241-267. Kreisel, G. (1957). Interpretation of analysis by means of constructive functionals. In Constructivity in mathematics. A. Heyting editor. North-Holland, Amsterdam, 101— 128. Novikov, P. S. (1943). On the consistency of certain logical calculus. Matematiceskij sbornik(Recueil-Mathematique T.I2), 54, 230-260. Shoenfield, J. R. (1967). Mathematical logic. Addison-Wesley, London. Tail, W. W. (1968). Normal derivability in classical logic. In The syntax and seman- tics ofinfinitary languages. J. Barwise editor. Lecture Notes in Mathematics no. 72. Springer-Verlag, Berlin, 204-236. Extension of Martin-L6f s type theory with record types and subtyping Gustavo Betarte and Alvaro Tasistro Department of Computing Science, Chalmers University of Technology and University of Gothenburg 1 Introduction Our starting point, to which we refer hereafter as type theory, is the formulation of Martin-L6f's set theory using the theory of types as a logical framework (Martin-L6f 1987; Nordstrom etal. 1990). The question that we address is that of the representation of systems of structures such as algebraic systems or abstract data types. In order to provide a general means to this end, we extend type theory with a new mechanism of type formation, namely that of dependent record types. This allows us to form types of tuples in such a manner as to allow any arbitrary set (i.e. not restricted to be among those generated by a fixed repertoire of set forming operations) to be used as a component of tuples of those types. Such types of tuples cannot be formed in the original theory. Moreover, as is well known from the theory of programming languages, a natural notion of inclusion arises between record types. Given two record types p and p', if p contains every label declared in p' (and possibly more) and the types of the common labels are in the inclusion relation then p is included in p'\\ in symbols, p c p'. This is justified because then every object of type p is also an object of type p', since it contains components of appropriate types for all the fields specified in p'. Our extension contains the form of judgement expressing that the type is included in the type ft and corresponding proof rules, which generalize record type inclusion to dependent record types and propagate it to the rest of the types of the language. In the present formulation, no proper inclusion between ground types is allowed. Having type inclusion represents a considerable advantage for the formalization of the types of structures in which we are interested. In particular, systems of algebras will be represented as record types and, according to the subtyping rule explained above, any algebraic system obtained by enriching another with additional structure will be a subtype of the original system. Thus, for instance, we can directly express in the formalism that every group is a monoid. As a consequence, every function defined on monoids can be applied to any group, which implies that any proof of a property of monoids is itself a proof of exactly the same property of groups. This is precisely the principle that we use in informal reasoning, which is then formalized without further encoding. 2 22 G. Betarte and A. Tasistro The extension preserves the decidability of the formal correctness of judgements, which is a fundamental property of the original theory. Hence, type checking can still be used for verifying the validity of proofs of theorems and the correctness of programs with respect to specifications. A type checking algorithm for the extended theory is given in Tasistro (1997) and Betarte (1998). The structure of the paper is as follows. In the next section we develop in detail the motivations for the extension that have been outlined above by considering a case of formalization of algebra. It consists of the proof of a basic property of groups, namely that the right identity of the operation of the group is unique. In an appendix we present the complete code of this formalization as verified by a prototype implementation of the type checking algorithm for the extended theory. In section 3 we present the formal stipulation of the extension. To explain the re- sulting calculus we proceed according to the syntactico-semantical method given in Martin-L6f (1984) and used in every presentation of Martin-Lof 's type theory to which we refer in this work. We introduce the forms of judgements of the extended theory, which are those of the original theory plus four new ones, and explain them semanti- cally. Then we present the whole system of formal rules of inference. Each rule can be justified by showing that the meaning of the conclusion follows from those of the premisses. We give detailed justifications of the most important rules. As for the other rules, their justifications are either immediate or can easily be obtained from the ones that we give. Finally, in the last section of the paper, we give some conclusions and discuss related work. 2 Formalization of algebraic systems 2.1 Record types In order to motivate the introduction of record types in type theory we consider the problem of formalizing a proof of a basic property of groups, namely that the right identity for the operation of a group is unique. We will get to the formal definition of group after a process of successively enriching previously defined systems of algebras with further structure. This procedure is common practice in algebra and could be called incremental definition of the algebraic systems. A convenient starting point is the notion of a set with an equivalence relation on it, which has elsewhere been called a setoid. The reason why this is taken as the most basic kind of structure is that in formalizing systems of algebras it appears natural to require the relation informally denoted by the equality symbol = to be given explicitly as a component of the system being defined. So, for the sake of presentation we shall consider setoids as constructed from a still simpler notion, namely that of a set with a binary relation on it. Now, the representation in type theory of systems of algebraic structures presents a difficulty. Such structures are defined as tuples in informal language, so to represent them in type theory we ought to use tuple types. In view of the mechanisms of type formation available, the only way to get tuple types is to introduce sets of tuples. But now consider setoids as defined above, i.e. structures composed out of a set X together Extension of Martin-Lof's type theory with record types and subtyping 23 with an equivalence relation on X. If X can be any set then the type of setoids cannot itself be a set or it would be allowed to form a part of some of its own elements. Another possibility would be to restrict X in the setoid to be an element of a previously constructed set of sets that we call a universe. This particular type of setoid could be introduced as a set, obviously then not belonging to the universe. Now, if we still want to allow any set to be used possibly as a component of setoids, then the present approach leads us to the requirement that every set is a member of a certain universe. In such a case, the general notion of a setoid would be split in the formalization into several types that could be called setoids over U for each universe U of sets. But, actually, there would be no way to introduce all these types of setoids once and for all unless we know each individual universe U, since there is no such thing as the type of the universes of sets. And, in turn, to give rules for forming all possible universes of sets implies fixing once and for all the possible ways to form sets, since each universe must be defined inductively. It would then still be possible to introduce set-valued functions, i.e. set operators or predicates and relations on given sets. But each of these would have to be defined in terms of the fixed primitive mechanisms of set formation. They would in general, then, have to be introduced as recursively defined functions giving values in a certain universe of sets. Besides the one above, there is also the understanding of type theory according to which the notion of a set is indeed an open notion, in the sense that it is at any time pos- sible to introduce new primitive set formers. Further, the version of type theory that we are considering allows this to be done in a simple way, i.e. just by declaring primitive constants corresponding to the set former itself and its constructors and defined con- stants corresponding to the recursion operators. Type theory in this way is understood as a basic framework in which it is possible to express various other theories. Each of these starts simply as a vocabulary of constants and definitions that is determined by one or more set formers in the way explained above. Then it is extended by further def- initions corresponding to the various individual theorems. According to this approach there is simply no question of knowing or enumerating all the individual set formers. Therefore, to obtain in this case a formalization of the notion of setoid that allows any set to be a component of setoids one has no alternative but to state this latter condition explicitly. In general, then, one needs types of tuples some of whose components are allowed to be arbitrary sets—not just members of sets of sets. As explained above, such a type cannot itself be a set. This provides a first motivation for introducing the dependent record types as a new mechanism of type formation. Dependent record types are just sequences of fields in which labels are declared as of certain types: In dependent record types, the type a,; may depend on the preceding labels In the notation that we are going to use in this section, labels are allowed to participate in the formation of types in the same way as ordinary variables or constants do. So, they have to be syntactically distinguished from the latter, in order to avoid ambiguities. We do this by writing labels in a distinguishing font. 24 G. Betarte and A. Tasistro We can now write the type of binary relations on a set as: Let us call this type B. Components of objects of a record type are accessed by selection of the labels of the record type in question, which we write using the usual dot notation. Then if r is of type B, r.S is a set and r.R is a binary relation on r.S. Record objects are constructed as sequences of fields that are assignments of objects of appropriate types to labels. For instance, if N is the set of natural numbers and the usual order relation on N, then the following is an object of type B: That two objects r and s of type are the same means that the selection of the labels L,- from r and s results in equal objects of the corresponding types. Now we can show how the example at hand can be formalized in type theory with record types. 2.2 Setoids We begin by introducing the type of binary relations on a given set: B: type From this definition we obtain that of a setoid by adding properties of the binary relation. Thus we have the first example of incremental definition of systems. In the present extension of type theory, the possibility of incremental definition is given directly by the rules of formation of record types. Formally, record types are constructed from the record type with no fields by iterating the operation of extension of a record type with one more field. Then setoids can be introduced as follows: Setoid: type Setoid = Now we can prove a very simple property which is a consequence of the axioms for setoids. Stated informally it is: Proposition. For any objects x, y, z, w of a setoid, if x = y,x — z and y = w then z = w. In plain words, this proposition could be called of replacement of equivalents by equiva- lents. It allows us simultaneously to replace both sides of an equation x = y by objects z and w that are, respectively, equivalent to x and y. Now the formal statement will not Extension ofMartin-Lo'f's type theory with record types and subtyping 25 use = but the equivalence relation explicitly given with the setoid. It is proved by a function: eqtoeq : whose definition can be found in the appendix. 2.3 Subtyping The formalization continues by introducing several types of algebraic structures by the procedure of incremental definition. In this way, we first get the definitions of semi- group and monoid, which can be found in the appendix. Eventually, we formulate the definition of group in the following way: Group : type Group = {Monoid, The informal counterpart of this definition says that groups are monoids with some additional structure, namely the inverse operation. Then every group is a monoid, which is of course used straightforwardly in the informal language. A direct expression of this use in type theory requires that every object of the type Group is itself also an object of the type Monoid, i.e. a form of polymorphism. Now, both Group and Monoid are record types and, as it happens, the required form of polymorphism is natural for record objects. The source of the idea can be traced back at least to Dahl and Nygaard (1966) and consists in observing that, given a record type p, it is possible in general to drop and permute fields of p and still get a record type p'. Moreover, any object of type p then also satisfies the requirements imposed by the type p'. That is, given r : p, we are justified in asserting also r : p 1. This is so because what is required to make the latter judgement is that the selections of the labels declared in p' from r are defined as objects of the appropriate types. We have this, because every label declared in p' is also declared in p and with the same type. To realize this idea in full generality in the formal language we introduce the form of judgement for types and , which is to be read: is a subtype of This means that every object of is also an object of 0.1 and that equal objects of are equal objects of We also refer to these judgements as type inclusion. In the case of record types, the condition for is read as follows: for each field L : _ in there must be a field L : in / with . The formal stipulation of this rule takes care of the dependence of the types occurring in fields on labels, as will be shown in the next section. It also requires that rules of subtyping are given for all the type formers of the language. In the present formulation, this is done by propagating type inclusion to the functional types in the standard manner and without allowing proper inclusion between ground types. 26 G. Betarte and A. Tasistro 2.4 Unicity of the identity element of a group Now we can consider the property of groups in which we have been interested from the beginning, namely that the identity element of a group is unique. To prove this, we make use of the following: Lemma. Let (S, o) be a group in which e is a right identity. If x is any element of S such that then* = e. This is proved as follows. First, note that ( , using associativ- ity and the property of the right inverse. Further, since by assumption. So, . But now we also have that by the right identity property, and that by the property of the right inverse. So, replacing equals by equals we finally have that x = e. Consider now, for instance, the last step of the proof. There we used the rule of replacement which was proved for setoids. That is, we are using the rule that every group is itself a setoid, which is of course correct. In the formalization of this proof we will then have an application of subtyping. More precisely, the proof eqtoeq which was introduced earlier as a function on Setoid will be applied to a group. The application is correct because every group also has the type Setoid since Group \\ Setoid. Actually, every step in which a property of the equivalence relation associated to the group is used gives rise to an application of subtyping. Finally, to prove the unicity of e we assume that there exists e\\ in S such that for all element x of 5, . .I n particular, Then by the lemma above, e\\ = e. The formal proofs are given and explained in the appendix. 2.5 Multiple inheritance As a final point, consider the definition of abelian monoid as a subtype of the system monoid: AbMonoid: type AbMonoid = (Monoid, comm : (x,y : S) R(op x v)(op y x)). By an analogous procedure, we define abelian group as a subtype of group: AbGroup : type AbGroup = (Group, comm : (x,y : S) R(0p x y)(0p y x*)). Of course, abelian groups could also have been introduced as extending abelian monoids, i.e. just in the same way as groups extend monoids. Now, because of the rules of inclusion of record types, the definition above gives us AbGroup AbMonoid anyway. A first observation is then that a type may be a subtype of several other types, each of which needs not to be in the inclusion relation with any of the others. When, we use record types to represent systems of algebras, this provides a direct formalization of the principle that a system may inherit properties and proofs from several other systems, themselves defined independently of each other. Extension of Martin-Lof's type theory with record types and subtyping 27 3 Formulation of the extension We now proceed to give the formal stipulation of the extended theory. We will follow the syntactico-semantical method given in Martin-Lof (1984) and used in every presen- tation of Martin-Lof's type theory to which we refer in this work. Therefore the first step is to introduce the various forms of judgement of the theory. This is done by ex- hibiting their syntax and at the same time explaining them semantically, i.e. stating what it is that has to be known in order to assert a judgement of each of the forms in question. In the extended theory, four new forms of judgement are added to those of the original theory. After having introduced the forms of judgement, we set up a system of formal rules of inference. Each individual rule is to be justified by showing that the meaning of the conclusion follows from those of the premisses. 3.1 The forms of judgement 3.1.1 The original forms of judgement Let us recall the forms of categorical judgement of type theory: To know that i : type is to know what it means to be an object of type as well as what it means for two objects of type a. to be the same. That a is an object of type is written Given and , that they are the same object of type is written That two types are the same—in symbols, —means that to be an object of type is the same as to be an object of type „, and to be the same object of type is the same as to be the same object of type That is a family of types over the type means that for any is a type, and that for any two objects a, b of type such that a =b : ~ and > are the same type. Given type that is a family of types over is written That two families of types and over a type are the same—in symbols, —means that : for any The present notion of a family of types was introduced in the formulation of the calculus of substitutions for type theory (Martin-Lof 1992; Tasistro 1997). It makes it possible to have abstraction as a uniform mechanism of variable binding in the language. The forms of judgements above are generalized to forms of relative judgements, i.e. of judgements depending on variables . For the sake of brevity, we consider this done here in the way it was usually done in the formulations of type theory prior to the calculus of substitutions, in for instance Martin-Lof (1984) and Nordstrom etal. (1990). It may be useful to remark that we make (nominal) definitions of types and families of types in addition to those of objects of the various types which are ordinary in type theory. An (explicit) definition of a type is as follows. Let be a type and A a name not previously given any meaning. Then we define A as the type by stating the two axioms: 28 G. Betarte and A. Tasistro A : type Then as a consequence of the second axiom, a : A and a=b : A have the same meaning as a : and a=b : respectively. We say that A is the definiendum and a the definiens of the definition. We shall also say that A has a as its definiens. Definitions of families of types are explained similarly. Let F be a name not yet given any meaning, a type and a type depending on variable x of type . Then we define F as a family of types over by means of the following two axioms: The second axiom is a relative judgement depending on variable x of type a. Then by virtue of this, Fa turns out to be by definition the type i for 3.1.2 Judgements of inclusion We now have to introduce some new forms of judgement. We consider first those for expressing inclusion of types and of families of types on a given type: Given types and , that is a subtype of —in symbols, —means that every object of type is also an object of type and equal objects of type < are equal objects of type Given a type and families r , and over < that is a subfamily of —in symbols, >type—means that/ _ for every object a of type a. 3.1.3 Record types and families of record types We intend to introduce a new type former, namely that of record types. In principle, all that we would have to do for this is to formulate a number of rules. But in the present case something else has to be considered first. Record types are constructed as lists of fields. We formalize this as is usually done with lists, i.e. from the record type with no fields, by means of an operation of extension of a record type with a further field. And then, as just stated, the operation of extension must require that what is to be extended is indeed a record type. We will express this condition by means of a further form of judgement. This, in turn, is most simply explained as being about types. That is, for type p we will have the judgement that p is a record type—in symbols, p : record-type. Similarly, we need to distinguish families of record types on a type a since they give rise to record types when applied to appropriate objects. Therefore we will also have the judgements record-type for a a family of types over a. These two new forms of judgement will now be explained. To explain what it means for a type to be a record type we have to distinguish between defined and primitive types. A defined type is a record type if its definiens is a record type. A primitive type is a record type if it is generated by the rules referred to above, namely. 1 In definitions of the present form, the dependence of a i on x must be uniform. That is to say, families of types cannot be defined by case analysis of the argument. Extension ofMartin-Lof's type theory with record types and subtyping 29 {} is a record type. If p is a record type and a family of types over p, then (p, L :/J) is a record type, provided L is not already declared in p. We will later justify rules to the effect that there are indeed types generated by the clauses above. In the case of record types generated by the second clause, is a field and L a label, which we say to be declared in the field in question. Labels are just identifiers, i.e. names. In the formal notation that we are introducing, no situation will actually arise in which labels can be confused with either constants or variables. Notice that labels may occur at most once in each record type. That a label L is not declared in a record type p will be later referred to as L fresh in p. Finally, that these are dependent record types is expressed in the second clause, in the following way. The \"type\" declared to the new label is in fact a family on p, i.e. it is allowed to use the labels already present in p. In fact, what : is allowed to use is a generic object (i.e. a variable) r of type p. Then the labels in p will appear in as taking part in selections from r. Below we will show how the type of binary relations on a given set is written formally. Families of types are formed by abstraction, which we write using square brackets: There is a direct way of translating the notation used in the previous section into the present formal notation. We conclude by explaining what a family of record types is. Given type a and -*-type, that i record-type means that era is a record type for arbitrary. The forms of judgements introduced are all categorical. From now on we consider their generalizations to forms of relative judgements as given in the way indicated at the beginning of this section. 3.2 Inference rules We will now formulate a system of inference rules involving the preceding forms of relative judgement. The rules will be written as of natural deduction, i.e. only the discharged variables will be mentioned. In principle, the rules ought to have enough premisses for them to be completely formal and thereby make it possible to justify each rule individually using only the explanations of the various forms of judgement. We will, for conciseness, often omit premisses. A general principle allowing us to recover the omitted premisses of a rule is that they are just those strictly necessary for guar- anteeing that every (explicit) premiss and the conclusion of the rule are well formed as instances of the respective forms of judgement. Also, we allow ourselves to men- tion side conditions to rules. These are of two simple forms, each of them of a purely syntactic nature. We give detailed explanations of rules in those cases where we think it could be relevant. The entire system corresponding to the extended theory that we are presenting is obtained by adding to the rules below the rule of assumption and the various substitution rules, which are just the same as those of the original theory. 30 G. Betarte and A. Tasistro 3.2.1 General rules of equality and inclusion To begin with, we have that the various equality judgements give rise to equivalence relations. That is, we have rules of: Reflexivity, symmetry and transitivity of identity of types, identity of objects of a given type and identity of families of types over a given type. Next we have rules expressing that inclusion follows from identity: Using these two rules it is possible to derive those of reflexivity of type inclusion and of inclusion of type families. We also have: Transitivity of type inclusion and of inclusion of type families. The following are the rules of type subsumption. They are justified immediately by virtue of the explanations of the judgements of inclusion. 3.2.2 Remarks A number of comments on the preceding rules are now in order. Let us first consider the rules of type subsumption. They replace those of type conversion in the original theory, for instance the rule: The rules of type conversion can actually be derived from those of type subsumption by using the rules expressing that inclusion follows from identity. In the original theory, the rule of type conversion displayed above expresses the part played by definitional identity in the formation of objects of the various types. It is then the formal counterpart of the use of definitions in proofs of theorems. The link between definitional identity and formation of objects obviously subsists in the extended theory, since the rule of type conversion is derivable. On the other hand, the mechanisms of formation of types and objects are in principle generalized by the presence of type inclusion and the rules of type subsumption. That is, the rules for forming types and objects of the various types Extension of Martin-Lof's type theory with record types and subtyping 31 in the original theory are as follows. There is first a rule for each of the various syntactic forms of the theory that states the conditions under which an expression of the form in question denotes or has a type. To these, we have to add the rules of substitution in types and objects. And, finally, there is the rule of type conversion. Exactly the same rules will occur for the extended theory, with the rule of type subsumption taking the part of the rule of type conversion. On another point, note that we have not given rules to the effect that identities of types and of families of types are equivalent to the respective mutual inclusions. That is, the rules: Now consider the first of these rules. To justify it, we ought to have that the two pre- misses together constitute precisely the meaning of the conclusion. That is, identity of types ought to have been defined as the mutual inclusion of the types in question. This has, however, not been made explicit in our explanation. Defining type identity as mu- tual inclusion can be defended on the grounds that type inclusion should be understood as intentional, i.e. as having to follow generically from the explanations of what an ob- ject is and what identical objects are of the types in question. Then the mutual inclusion of two types and i would be nothing more than the identity of meaning of i and as well as of the corresponding judgements of identity of objects. That is, it would just coincide with the identity of the two types. So we have two alternatives here. The corresponding formal systems will differ only in the presence of the rules above and therefore in the judgements of the forms and -+type that are derivable. But they will not differ in the judgements of the forms : type and i that can be derived. This follows from the observation made above about the rules available for making typing judgements and the fact that, clearly, exactly the same judgements of type inclusion can be derived in both systems. We shall consider the theory in which identity of types is not identified with mutual inclusion, which then turns out to be expressive enough for representing (informal) theorems in spite of its weakness in connection with the judgements of identity of types and of families of types that can be proved. 3.2.3 Families of types and function types Now we give the rules for using and forming families of types. First we give the rules of application, which just express the definition of the notion of family of types: Similarly, the following express the meaning of identity and inclusion of type families: 32 G. Betarte and A. Tasistro Families of types can be formed by abstraction, which is defined by the $-rule. We have a rule of extensionality that is immediately justified from the explanation of what it is for two families of types to be the same: We now introduce the function types. These are explained in an obvious way. We give the rules for proving identity and inclusion of two function types: By virtue of the first rule we have that is a type if is a type depending on . This type is usually written . We will explain the rule of inclusion of function types. The explanation reduces eventually to that of the case in which the judgements involved are categorical, so we only consider this case. The same will be done for all the rules to be explained in the sequel. Now to see that the conclusion is valid we have first to note that. for given . For this, in turn, we have to note that for and that : for any objects a and b of type such thai . We show only the first of these two parts, the other following in a totally analogous manner. Now if _ then i by virtue of the first premiss. And, since , we have that . But then, by virtue of the second premiss, Also in an analogous way one can see that „ for given and L such that . Then the rule is correct. In a similar way to that of the case of families of types we formulate the rules of function application, formation of functions by abstraction, the -rule and the rule of extensionality of functions. 3.2.4 Sets The ground types are the types of sets and of the elements of a given set, as declared by the rules: We also have the rule that equal sets give rise to equal types. There are no inclusions between ground types, except for the trivial ones following from the reflexivity of type inclusion. Extension ofMartin- Lof's type theory with record types and subtyping 33 3.2.5 Record types and families of record types We now finally turn to formulating the rules of record types and record objects. The first rules to be given are those of formation of (primitive) record types. These have to be introduced as types and further as record types. So the following four rules have to be understood simultaneously. From now on we omit side conditions of rules to the effect that labels are declared at most once in record types. The justification for the rules in the second line above follows immediately from the explanation of the form of judgement that p : record-type. To justify the rules in the first line we have to explain what an object is and what identical objects are of each of the primitive record types. Let us now make some preliminary remarks that may help to understand the explanations given below. One can interpret the fields that compose a record type as constraints that the objects of the record type must satisfy. More precisely, given a record type p, to know r : p requires one to know that, for every label L declared in p, the selection r.L of L out of r is defined as of a type that respects the declaration of the label. Based on this observation, one first concludes that the record type with no labels {} then imposes no constraints on its objects, i.e. there are no conditions that have to be satisfied in order to assert r : () for any expression r. On the other hand, to assert r : (p, L:/3) requires one to know first that rip. Further, the selection r.L must be defined as of appropriate type. This type depends on the values assigned in r to the labels declared in p. Formally, this dependence is expressed in the declaration of L by associating the latter to the family of types ft over p. Correspondingly, the type of r.L is specified as fir. Thus we arrive at the following explanations: r : {) is vacuously satisfied. r\\=ri: {) is vacuously satisfied forri : () and ri : {). And, under the premisses of the second rule of record type formation: means that r : p and that r.L : fir. , where and, means that r\\ =ri : p and thatri.L=r2-L : fi r Record types can also be obtained by applying families of record types. Here are the rules governing these families. Finally, we can also introduce record types by explicit definition. If in an explicit definition of a type R, the definiens is a record type p, then we are justified in stating the 34 G. Betarte and A. Tasistro axiom R : record-type. Also, if in the definition of a family of types F over a type a the definiens of Fx is a record type p depending on , we are allowed to state the axiom '.-^•record-type. We will later refer to the construction of a record type, meaning the process of its generation by using the rules for forming primitive record types. The construction of a defined record type is then to be understood as the construction of its definiens. The same is the case with respect to the conditions of a field being in a record type and a label being fresh in a record type. Identical (primitive) record types are constructed by the following rules: These rules serve only to express that definitional identity is preserved by substitution in record types. Recall that we have chosen a system that is weak in proving definitional identity of types. The expressiveness in typing objects is obtained by the rules of inclu- sion of record types. Before displaying these, it is convenient to consider the following rules: Only the latter two require explanation. We refer to them below as the rules of fields. They are explained similarly. The condition that , is in p means that, at one point during the construction of p, another record type p' was enlarged with the field L:/3. Then it must be the case that -+type. Also, by repeated use of the rule (1) and transitivity of type inclusion, we conclude that and, further, From the latter and -*type we conclude that -^-type thereby justifying the first rule of fields. As to the second, its conclusion follows from which is in turn a consequence of the premiss r : p and The second rule of fields serves as a precise direct explanation of the meaning of r : p for record type p. The three rules just considered are going to be used to explain the rules of inclusion of record types that we now formulate: 01)- The rules state that if pl contains a field for each label declared in p2 and the (families of) types of the corresponding declarations are in the inclusion relation. The order of the fields within each record type is not relevant for determining whether they are in the inclusion relation. Only the second rule needs to be explained in de- tail. Assume then the premisses and the side condition. Notice that the condition that L is fresh in p 2 has been omitted. This condition is necessary to guarantee the well- formedness of { ) and hence that of the conclusion of the rule. What has to be Extension of Martin-Lofs type theory with record types and subtyping 35 shown is that every object of type p j is an object of type ) and that equal record objects of type PI are equal objects of type We will now show the first of these; the other one requires essentially the same reasoning. Assume then that r : p\\. To know that is to know that r : p^ and that . Now, from the as- sumption r : p\\ and the premiss it follows that r : p2. On the other hand, using the rules of fields and the side condition that is in pj, we see that \\-^>-type and that Finally, from the latter and the premiss p\\~+type , we know that The next rule is justified in the same manner as the second rule of fields: Record objects are formed as sequences of assignments of objects of appropriate types to labels. We call each of these assignments a field of the record object. Notice that there is no restriction on labels occurring more than once in record objects. This, however, is inessential in the sense that it does not provide any additional expressivity. The first of these rules requires no justification. To justify the second rule, we have to define the selections from (r, L = a) of all the labels in ~ >. For the labels in p, this is done by defining (r, L = a) to be the same record object of type p as r, which was given. On the other hand, the selection (r, L = d).L is defined in an obvious way, i.e. as a. Thus we arrive at the rules below. Notice that the condition that L is fresh in p has been omitted in the rule of extension of record objects. For the sake of clarity, we make it explicit now: L fresh in p) (L fresh in p) • The second of these two definitions implies that the rightmost assignment to a label in a record object overrides the preceding ones. Finally, equality of record objects is based on a kind of extensionality principle. That is, the two rules below can be understood as stating that two objects of a given record type are equal if the selections of every label of the record type in question from the objects are equal. Notice that the type in which two record objects are compared is relevant: suppose that r and s are of type pj and that . Then it may well be the case that r= s : p% but not r=s : pj,. To understand the second of these rules it might be useful to note that the premisses that both r and s are of type have been omitted. 36 G. BetarteandA. Tasistro 4 Conclusions We have formulated and explained an extension of type theory with dependent record types and subtyping. We have shown that dependent record types constitute a general mechanism for the formalization of types of structures such as algebraic structures or abstract data types. In particular, they make it possible to form types of tuples in such a way that any arbitrary set is allowed to be a component of tuples of the types in question while the possibility is still retained of extending the theory at any time with further set formers. Moreover, the relation of subtyping between record types allows direct representation of the informal principle that every structure of a type T is itself also of type S provided T is defined as an enrichment of S with additional structure. Type checking in the extended theory is still decidable and has been implemented on machines. In addition to the formalization presented in this paper, the implementation has also been used to verify an abstract version of sorting by insertion in Tasistro (1997). In this latter work, dependent record types are used to express specifications of abstract data types. The theory developed here is a direct successor of the calculus of substitutions for type theory (Martin-Lof 1992; Tasistro 1997) in the sense that record types can be seen as type constructions corresponding to contexts of variables—record objects then becoming counterpart substitutions. Several theories of records have been developed in the context of systems without dependent types, mainly with the motivation of providing foundations for concepts that appear in object-oriented programming. Then, for instance, there is a standard way of encoding objects in the sense of object-oriented programming as recursively defined records. The general motivation mentioned departs from ours, which, as far as the theory of programming is concerned, is limited to that of providing a basic means that allows the use of dependent types for expressing specifications of abstract data types and modules in a general way. The problem of formulating a type system for object- oriented programming raises a number of questions that are simply not relevant to our purposes. As to dependent record types, they have been implemented in PVS (Owre et al. 1993), which is a theorem proving system based on classical higher order logic. The subtyping that record types induce is, however, not a part of this implementation. In the original type theory, it is possible to encode each particular instance of inclu- sion between types a and ft by using a coercion function that injects the objects of type a into the type ft. In Barthe (1996), Bailey (1996), Sa'ibi (1997) different mechanisms are developed that allow the declaration of coercions between types or classes of types, which can later be left implicit in expressions. This provides in principle a limited form of the subtyping mechanism that we have formulated here, since only those inclusions hold that can be derived from the explicitly declared coercions. However, the use of coercions allows even further convenient ways of expression, which are not captured by our mechanism of subtyping. One case is the possibility of writing fa when / is not itself a function but from which a function can be obtained in a standard manner. For in- stance, / could be any structure morphism. Moreover, in principle coercions allow the representation of proper inclusions between sets, which has not been considered in this paper. To extract useful conclusions from a comparison between the two approaches Extension ofMartin-Lof's type theory with record types and subtyping 37 requires testing in extensive case studies. This has not yet been done in the case of the theory that w e have formulated here. 5 Appendix We present here code as accepted by a type checker that has been implemented for type theory extended with record types and subtyping. The script for the type checker looks very much like one for a functional programming lan- guage, say ML. The type checker reads declarations of various forms. These are type declarations (command type) , type family declarations (command typef) , value declarations (command val ) and function declarations (command fun). The notation [x , .. . , z] e stands for the abstraction of the variables x , .. . , z in the expression e. The notation let { .. . } e has the usual meaning of a let expression. We distinguish labels from constants or variables by writing labels of a record type, when used in subsequent fields of the same record type, preceded by a dot. 5.1 Definition of group type BinRel = <S:Set,R:(x:.S,y:.S)Set>; type Setoid = <BinRel, ref:(x:.S).R x x, symm : (x:.S,y:.S,p:.Rxy).Ryx, trans : (x:.S,y:.S,z:.S,p:.R x y,q:.R y z).R x z>; type EqToEq = (Sd:Setoid,x:Sd.S,y:Sd.S,z:Sd.S,w:Sd.S, p:Sd.R x y, q:Sd.R x z, rrSd.R y w) Sd.R z w; val eqtoeq = [Sd, x,y,z,w,p,q,r]Sd.trans z y w (Sd.trans z x y (Sd.symm x z q) p) r : EqToEq; type Groupoid = <Setoid, op: (x:.S,y:.S).S, opcong : (x:.S,y:.S,z:.S,w:.S,p:.R x y,q:.R z w) .R (.op x z) (.op y w)>; type Semigroup = <Groupoid, assoc:(x:.S,y:.S,z:.S) .R (.op (.op x y) z) (.op x (.op y z))>; fun symmAssoc(Sg:Semigroup) = [x,y,z]Sg.symm (Sg.op (Sg.op x y) z) (Sg.op x (Sg.op y z)) (Sg.assoc x y z) : (x:Sg.S,y:Sg.S,z:Sg.S) Sg.R (Sg.op x (Sg.op y z)) (Sg.op (Sg.op x y) z) ; type Monoid = <Semigroup, e: .S, id:(x:.S).R (.op x (.e)) x>; type Group = <Monoid, inv:(x:.S).S, invcong:(x:.S,y:.S,p:.Rxy) .R (.inv x) (.inv y), invprop:(x:.S).R (.op x (.inv x)) (.e)>; t 38 G. BetarteandA. Tasistro 5.2 Proof of the lemma and unicity of the right identity The statement of the lemma used in the proof of unicity of the right identity of groups and the corresponding proof are as follows: type LemmUniq = (G:Group,x:G.S,p:G.R (G.op x x) x) G.R x (G.e); val lemmuniq = [G,x,p] let {val lemma = G.trans (G.o p x (G.e)) (G.op (G.o p x x) (G.inv x)) (G.op x (G.inv x)) (G.trans (G.o p x (G.e)) (G.op x (G.op x (G.inv x))) (G.op (G.o p x x) (G.inv x)) (G.opcong x x (G.e ) (G.o p x (G.inv x)) (G.ref x) (G.symm (G.op x (G.inv x)) (G.e) (G.invprop x))) (symmAssoc G x x (G.inv x))) (G.opcong (G.o p x x) x (G.inv x) (G.inv x) P (G.ref (G.inv x))) : G.R (G.o p x (G.e)) (G.o p x (G.inv x)) } eqtoeq G (G.op x (G.e)) (G.op x (G.inv x)) x (G.e) lemma (G.id x) (G.invprop x) : LemmUniq; We use le t expressions for local lemmas. In this case, the local lemma lemma represents the proof that x o e = x o x~ l , as is revealed by its type. It is in this proof that the main function's argument p, which represents the assumption that x o x = x, is used. Notice the application in the main function of eqtoe q to G, which is correct owing to the subtyping rules. Finally, as for the proof of the unicity of the right identity of a group, we get a representation that is a straightforward encoding of the informal argument: fu n uniqunit(G:Group ) = [el,id2 ] lemmuniq G e l (id 2 el ) : (el:G.S , id2:(x:G.S ) G. R (G.opxel ) x ) G.R e l (G.e) ; Bibliography Bailey, A. (1996). LEGO with implicit coercions. Available at ftp.cs.man.ac.uk/pub/baileya/Coercions . Barthe, G. (1996). Implicit coercions in type systems. In Selected Papers from the In- ternational Workshop TYPES '95, Torino, Italy, June 1995. LNCS 1158. Betarte, G. (1998). Dependent Record Types and Algebraic Structures in Type The- ory. Ph.D thesis, Department of Computing Science, University of Goteborg and Chalmers University of Technology, Goteborg, Sweden. Extension ofMartin-Lof's type theory with record types and subtyping 39 Dahl, O. and Nygaard K. (1966). Simula, an Algol-based simulation language. Com- mun. ACM 9, 671-678. Martin-L6f, P. (1984). Intuitionistic Type Theory. Bibliopolis, Napoli. Martin-L6f, P. (1987). Philosophical Implications of Type Theory. Lectures given at the Facolta di Lettere e Filosofia, Universita degli Studi di Firenze. Privately circulated notes. Martin-L6f, P. (1992). Substitution calculus. Talks given in Goteborg. Nordstrom, B., Petersson, K. and Smith, J. (1990). Programming in Martin-Lof's type theory. An introduction. Oxford University Press. Owre, S., Shankar, N. and Rushby, J. M. (1993). User guide for the PVS specification and verification system (Beta release). Computer Science Laboratory, SRI Interna- tional. Sa'ibi, A. (1997). Typing algorithm in type theory with inheritance. 24th Annual SIGPLAN-SIGACT Symposium on Principles of Programming Languages. Tasistro, A. (1997). Substitution, record types and subtyping in type theory, with ap- plications to the theory of programming. PhD thesis, Dept. of Computing Science, Chalmers University of Technology and University of Gothenburg. This page intentionally left blank Type-theoretical checking and philosophy of mathematics Nicolaas Govert de Bruijn Department of Mathematics and Computing Science, Eindhoven University of Technology 1 Introduction After millennia of mathematics we have reached a level of understanding that can be represented physically. Humankind has managed to disentangle the intricate mixture of language, metalanguage and interpretation, isolating a body of formal, abstract mathe- matics that can be completely verified by machines. Systems for computer-aided verification have philosophical aspects. The design and usage of such systems are influenced by the way we think about mathematics, but it also works the other way. A number of aspects of this mutual influence will be discussed in this paper. In particular, attention will be given to philosophical aspects of type- theoretical systems. These definitely call for new attitudes: throughout the twentieth century most mathematicians had been trained to think in terms of untyped sets. The word \"philosophy\" will be used lightheartedly. It does not refer to serious professional philosophy, but just to meditation about the way one does one's job. What used to be called philosophy of mathematics in the past was for a large part subject oriented. Most people characterized mathematics by its subject matter, classify- ing it as the science of space and number. From the verification system's point of view, however, subject matter is irrelevant. Verification is involved with the rules of mathe- matical reasoning, not with the subject. The picture may be a bit confused, however, by the fact that so many people consider set theory, in particular untyped set theory, as part of the language and foundation of mathematics, rather than as a particular subject treated by mathematics. The views expressed in this paper are quite personal, and can mainly be carried back to the author's design of the Automath system in the late 1960s, where the way to look upon the meaning (philosophy) of mathematics is inspired by the usage of the unification system and vice versa. See de Bruijn 1994b for various philosophical items concerning Automath, and Nederpelt et al. 1994, de Bruin 1980, de Bruijn 1991a for general information about the Automath project. Some of the points of view given in this paper are matters of taste, but most of them were imposed by the task of letting a machine follow what we say, a machine without any knowledge of our mathematical culture and without any knowledge of physical laws. 3 42 N. G. de Bruijn 2 Predominance of language If a computer has to check mathematics, one has to feed it with texts and to request it to check correctness. It has to be understood that this means more than syntactic correct- ness of sentences: it also matters whether the general rules for handling the language are obeyed. These rules include that the correctness of a piece of text is seen in the light of the texts accepted before: it is the matter of correctness of a complete book. In our relation with the machine there is language and nothing but language. There is no concern for meaning in the usual philosophical sense, relating words to things in the real world. For our machines the word \"meaning\" cannot refer to anything else other than to a mapping from one language system into another one. This is similar to how an English person may give the meaning of the French word \"femme\". The meaning is not something of flesh and blood but just the English word \"woman\". Instead of saying that \"femme\" and \"woman\" have the same flesh-and-blood meaning, one just says that \"femme\" means \"woman\" and \"woman\" means \"femme\". Mathematical language was not given such a predominant position before the year 1900. At the beginning of the twentieth century mathematical language had reached an absolute level of precision, and in the last few decades it has become possible to let computers check such precise language efficiently. This increases the power of language and settles its predominant role. The language of mathematics is a living organism. There have been many cases in the history of mathematics where people began to make and prove statements about the mathematical text itself, which often led to essential changes in the rules of the lan- guage. The discussion about the language is kept in what can be called metalanguage, so the changes meant that pieces of metalanguage were pushed into the language. Some- times this was a slow process. As an example it can be mentioned that it took the whole of the nineteenth century for the notion of a function to pass from metalanguage to language. Such transitions change the borderline between language and metalanguage. The paradigm of \"proofs as objects\" is a recent case that has by no means been settled yet in the general mathematical community. 3 Formalization levels The world of mathematics can be subdivided in many different ways; here we are mainly involved with the levels of formalization, or rather with the spectrum ranging from discovery to complete formal verification. It seems that Aristotle was one of the first to remark that proofs can be checked more or less mechanically but that there is no general routine for finding proofs. Once a text is composed, correctness checking is a routine affair. It may require skill and knowledge, but no inventiveness. Verification is mechanistic, by definition, and it is a matter of efficient programming to delegate it to a computer. But we can notice a finer subdivision of mathematical activity, comparable with the annual rings we see in a cross-section of the trunk of a tree. They reveal the history. New rings begin at the inside, the other rings get bigger in the course of time but produce no Type-theoretical checking and philosophy of mathematics 43 new rings themselves. The outer ring, the bark, is the frontier where mathematics is discovered. In the second ring it is written up for the first time. Then comes a ring where it is presented very precisely, even pedantically. In the next ring things are written in logical formulas, hardly using natural language any more. Finally there is the core; at present this can be seen as the level of machine-verifiable mathematics. This new layer is there to stay. It will support the growth of the other layers but will never replace them. Some mathematicians fear that the proof-checking community claims power over the mathematical world, forcing all mathematicians to work to their system. There should not be any fear of this. As in the tree analogy, outer rings will grow, possibly pushed by the growth of inner rings, but will never be overtaken by them. The ring of logical formalization has never obstructed discovery in any way, and neither will the recent ring of machine-assisted verification. Proof checking is a modest task which claims to be able to serve the community, not to become its ruler. If we look at one particular piece of mathematics, we observe a radius from the bark to the core, showing a cross-section of the layers. The mathematical task moves from outside to inside, as on a conveyor belt. The material is discovered by a genius, and written up in journal publications after some time. Later it falls into the hands of expositors who work on out in greater detail. Before the computer age, that was the end of the belt, but now it goes on, through one or more stages of formalization, until it reaches that point where a machine can do the final checking. This conveyor belt may employ various kinds of people. Towards the end of the belt, the workers have to be more meticulous, more bureaucratic, and hardly need to \"understand\" what they are working on. Do there always have to be different people at different stations along the belt? One can learn from the area of mathematics publishing, which has rapidly changed over the last few decades. Instead of using assistants, typists and professional printers, many creative mathematicians nowadays do almost complete desk-top publishing themselves. This happens wherever text-editing systems are so user-friendly that it is more conve- nient to do it oneself than to explain to others how it is to be done (and check whether they did it right). If the theorem-proving community and the proof-checking community do their work well, one might get a similar situation for the conveyor belt. The belt might be handled by the creative mathematicians all by themselves. Automated theorem provers may do useful work at several places of the belt, in particular at the far end (the proof-checking station), where it may be left to a machine to fill in all sorts of trivial little gaps. Indeed, the desk-top publishing situation may foreshadow a future when creative mathematicians will find that their work progresses better, safer and faster when assisted by proof checkers all the time. But in order to reach that stage, a lot of hard work has to be done, by both the theorem-proving and the proof-checking community. 4 Teaching mathematics Teaching is an essential part of the mathematician's trade, because of the central role of proving. To prove means to explain and to convince. 44 N. G. de Bruijn But is teaching always completely convincing? It has often been said that mathe- matics is taught by intimidation, and learned by imitation. There is certainly some truth in this, in particular as far as the structure and basic rules of mathematics are concerned. Teaching hardly ever specified what is a definition, an assumption, an axiom, a theorem, a proof. It did not display basic rules by which such things can be formed, neither how they are to be handled. It seldom said explicitly what variables are, how formulas are structured and how substitution is handled. It may be quite true that it is better to postpone these things, rather than burden a first introduction to mathematics with them. But would mathematics teachers be able to explain these fundamentals later? Would they be able to explain them to themselves? Most teachers have not been equipped for this. And in contrast to what outsiders might expect, university education in mathematics rarely starts with a discourse on the lan- guage and structure of mathematics. If we require a machine to check all our mathematics, we of course have to indoctri- nate it with knowledge about the structure. Part of that basic knowledge will go into the program that instructs the machine how to check, part may go into the beginning of the mathematics texts we feed into the machine at the time it starts checking what we say. The designers of a computer verification system have to have insight in this prerequisite knowledge and have to structure it. If such a system is structured well, it may be natural in the sense that it corresponds to what we might use to instruct a student about the basic structure of mathematics. Consequently, satisfactory verification systems may have a positive influence on the teaching of mathematics. Admittedly, a student is not a machine, but if we fail to explain the basis of mathematics to a machine then it is an illusion to think that we can explain it to a student, other than by intimidation. We descend from a past where the structure of mathematics was handled intuitively. That will not go on for ever: computer verification will have its influence. 5 Influences of system efficiency The development of a verification system requires some efficiency in order to cope with limited resources, in particular with restricted hardware and software (Automath was implemented and extensively used in the early 1970s). This has a danger: the urge for speed and efficiency at an early stage can lead to a structure one might deplore later on. But it can have very positive effects as well. The need for efficiency may reveal similarities, suggesting ways to treat similar things alike, making them even more similar than they were. This is illustrated by the discovery of the \"proofs as objects\" paradigm. If we want a machine to accept a particular application of a theorem, we have to feed it with object expressions for the variables as well as with proofs (or references to proofs) for the up- dated assumptions, and these two kinds of things are interwoven. In both cases we have a similar dependency on parameters and a similar substitution mechanism. Attitudes with respect to objects and proofs are very different at the start, but change under the attempts to draw full profit from the similarity. This leads to two things at a time. In the first place, proofs are treated the same way as objects, and proof classes the same way Type-theoretical checking and philosophy of mathematics 45 as object types. Secondly, we notice that the proof classes depend on parameters, so they require dependent types, and the natural step is to allow dependent types for object types as well. The urge for speed may be a bad thing in the first design of a verification system. The most essential thing is to prevent exponential growth and even quadratic growth of the time a machine needs for checking what we write. In order to keep in pace with the ordinary presentation of mathematics, we have to require linear time, and that means feasibility. The success of mathematics largely depends on its use of abbreviations and definitions, lemmas and theorems. That success should not be jeopardized by poor im- plementation which thinks in terms of simple examples only. In the case of Automath this feasibility requirement led to the concept of the book structure, with all the defi- nitions in the book, rather than somewhere in a margin. The checker has to check the book as a whole, and does not handle separate lists of abbreviations, definitions and theorems. All this was about changes of attitude caused by efficiency in system design, but such changes can also be found in the usage of a system, i.e. the style of writing, in particular in the organization of definitions. This happened long before the advent of machine verification. A famous slogan of Wittgenstein was: \"Don't ask for the meaning, ask for the use.\" Accordingly, it is efficient to define mathematical notions as closely as possible to their use. Particular examples are second-order definitions, like Leibniz's definition of equality. Such second-order definitions may require language extensions. It is open to discussion whether that is a drawback or a gain, but anyway it is caused by the urge for efficiency in formal verification. 6 Influences of systematic notation If we want a machine to digest our mathematical material, we have to revise our nota- tional habits here and there. As we know from the history of mathematics, the influence of notation is considerable. Poor notation can obstruct insight and development, good notation can be a stimulus for discovery, in particular since it can promote ideas on the level of metalanguages. Lambda notation is an example. If it had not existed before, it would have been discovered at once in the first attempts to make mathematical contact with a machine; it is indispensable there. Formal presentation of modern mathematics is not possible without the notation of lambda calculus. It is very remarkable, however, that the general mathematical community does not use it. One writes: \"let / be the function defined, for all x, by /(* ) = * 3 — 5x\", and then talks about the function /, instead of talking directly about the function Xx(x^ — 5x) (introducing a shorter name only if necessary). That is, one still needs a piece of plain natural language in order to connect formulas. Lambda notation should have been promoted by Frege and Peano and used ever since, certainly by Bourbaki. But Bourbaki did not do it, and that may be the main reason why nobody does today. In spite of the general modern attitude that functions are elements of function spaces, one keeps using archaic notations. A typical leftover 46 N. G. de Bruijn from ancient times is the notation f(x) for function values, a notation requiring that the function / is denoted by a single symbol, an identifier. Anywhere else in mathematics the objects can be denoted by composite expressions too. But even in the lambda calculus community there are remnants of ancient notation. Long before the advent of lambda calculus various quantifiers were used, all written on the left. Accordingly, standard lambda calculus writes abstraction (the basic quantifica- tion) on the left, but application on the right (as a heritage of the function value notation /(*)) , in spite of the fact that abstraction and application belong closely together. In complicated expressions it is inconvenient to have them far apart; it can even prevent us from making discoveries, in particular when we have to handle pairs consisting of an abstractor and an applicator. Having them far apart is reminiscent of the traditional no- tation for integrals, with the integral sign as a kind of quantifier on the left, a differential on the far right, and a long expression, often containing further integrals, in between. 7 Natural deduction One of the pillars of Automath was what is sometimes called the Fitch style of natural deduction. It fully deserves to be called \"natural\" since it was used by mathematicians long before it was ever formally described: namely, the presentation of mathematics in the form of nested blocks, where blocks are opened either by making an assumption or by introducing a (possibly typed) variable (but it should be admitted that the action of closing a block was usually not mentioned explicitly, just suggested by the subdivision of texts into sentences, paragraphs, sections, etc.). So natural deduction is by no means a new idea. On the contrary, it follows the way people reasoned before it was tried to explain logic by means of an algebra of truth values. Such Boolean logic is the metatheory of classical reasoning. It does not show what that reasoning is. It is silly that education in elementary logic so often takes truth values as the point of departure. The idea that truth values are the basis of logic may have been one of the reasons why Brouwer's rejection of the law of the excluded middle was so little understood in his time. If one starts from Boolean logic instead of from natural deduction it is impossible to understand what that rejection means. In natural deduction it is clear that for standard classical reasoning one has to in- troduce negation as a primitive, and to take the law of excluded middle (or the double negation rule) as an axiom. At the beginning of the twentieth century mathematicians had begun to like the game of trying to live with fewer axioms, so it might have appealed to them. It is doubtful whether Brouwer himself thought like that. It is not clear why he stopped half way, instead of trying to get rid of the falsum rule too, and even get rid of falsum (and therefore negation) itself. He might have tried to make mathematics negation free. The idea of negation somehow acknowledges the platonistic idea that there is truth beyond provability. Type-theoretical checking and philosophy of mathematics 47 8 Types Having types is not a new idea either. On the contrary, it was the standard idea before the doctrine \"everything is a set\" emerged. In that doctrine \"set\" means \"untyped set\", and from the point of view of type theory it is mathematics with a single object type, namely the type \"untyped set\". It is mere speculation to say that before the general acceptance of untyped set theory one thought in terms of objects having a type, where things of different type were never collected into sets. It is speculation, since there was no tradition of saying those things explicitly and formally at that time. Around 1900 Hilbert did a more formal thing in his foundation of elementary geometry. He started by saying that there are things called points and things called lines, not attempting to describe lines as sets of points. Hilbert's approach is just what type theory can do by creating two primitive and completely independent types, \"point\" and \"line\". It seems that most mathematicians still think in terms of types today; they may preach that everything is a set, but believing is a different matter. A typical symptom is that many have learned a definition of real numbers in terms of sets of rational num- bers, with several different definitions around. When talking to one another about real numbers, people are not embarrassed by having different definitions. It appears they do not mind talking about things which are entirely different from the point of view of set theory. They completely agree on the basic properties of real numbers, and behave as if \"real number\" were a primitive type. In many cases they may think as platonists, having the feeling that they are talking in different words about exactly the same things. One can get a feeling for the meaning of \"type\" by inspecting English sentences containing the word group \"is a\". The sentence \"The capital of Italy is a big city\" expresses that \"the capital of Italy\" has the type \"big city\". On the left of the group \"is a\" we have a string of words that has the form of a name: an accurate description of something, describing it uniquely; on the right we have a substantive group or a single substantive. With this natural language interpretation in mind, one can find all sorts of opportuni- ties to introduce types, thereby enriching the scope of formal mathematics. Once a ver- ification system is ready for attaching types to things, types can be used in many ways, even simultaneously. An expression representing a particular proof of some proposition Q can be given the type \"proof of Q\", an expression describing the construction of the centre of a circle c can be given the type \"construction for the centre of c\". This can amalgamate three worlds: the world of objects, of proofs and of geometrical construc- tions; in each one of these worlds things from the other worlds can be parameters (see de Bruijn 1984). Types are essentially the same things as substantives in natural language. They were used on a large scale in mathematics, but there was no tradition to express them in terms of mathematical symbols. From antiquity one used symbols and composite expressions as names of objects (Leibniz and Boole expressed sentences by means of symbols), but for substantives such a thing was not done. It may have been one of the reasons why people liked to express so many things by means of sets, which were felt to be objects for which the use of symbols was accepted. Another reason for liking sets is that people 48 N. G. de Bruijn had trouble with predicates too: those would require something like lambda calculus over sentences. With sets one felt on safe ground. A description of the syntax of natural mathematical language on the basis of sen- tences, substantives and names can be found in de Bruijn 1994a. A plea for working with typed sets was given in de Bruijn 1975, and an extensive discussion on the roles of types in de Bruijn 1995. 9 Proofs as objects The \"proofs as objects\" paradigm has philosophical consequences: it is a quite revolu- tionary change in the borderline between language and metalanguage. The sentence \"p is a proof of Q\" (where Q is some proposition and p is a proof) used to be metalan- guage, but in a type-oriented verification system it belongs to the mathematical language itself, just like \"x + y is a rational number\". The word group \"proof of Q\" is used in the same way as the group \"rational number\"; both can be called types. The principle that proofs can be treated as objects has been given various names. It was sometimes called \"formulas as types\", which is not very appropriate: for the general public the word \"formula\" is too general. The term \"propositions as types\" is misleading. In \"p is a proof of Q\" the type is not the proposition Q but something derived from Q, i.e. the substantive group \"proof of Q\". This substantive group might be called a proof type, but that phrase cannot be used: \"proof types as types\" would sound like an empty statement. It seems better to characterize the principle by what we have on the left of the group \"is a\", rather than by what we have on the right. This leads to the phrase \"proofs as objects\". There is still an objection, however. The word \"proof\" means something in the syntax: it is a string of text. Syntactically it is on the level of names. A \"name\" is any symbol or composite expression that denotes something. The expressions 2 + 4, 3 + 3 and 6 are all names for one and the same object (as even non-platonists would say). A proof is an expression too, but there is no mathematical tradition of seeing it as a name for some abstract thing. This might be connected with the fact that we have never felt the need to define equality between proofs. The best wording for the principle might be \"proofs as names\", but few people would appreciate that. Most outsiders would not be aware of the fact that verification systems handle object names only, not objects themselves. 10 Constructivity What is constructive mathematics? Different people will give different answers. Some will say that it just means the rejection of the axiom of choice; others will say that the use of classical logic is already non-constructive. It seems to be entirely a matter of which school one belongs to. If for some real world problem the solution is expected in the form of a single in- teger, most people would not be satisfied with the answer that a solution exists. One wants to have a construction, but what is accepted as a construction? Whatever is ex- pressed in a language can be called a construction, so that does not help us. If one uses a system that contains the Hilbert operator (claiming to select a definite element from any Type-theoretical checking and philosophy of mathematics 49 non-empty set) then the existence of a solution leads immediately to a construction, but it might be useless for real world applications. On the other hand, everybody would call an answer like \"th e smallest positive integer m such that io 100000000 0 + m is a prime\" constructive; nevertheless it might be useless too . Constructivity is a point of view that accepts a particular language and a particu- lar set of axioms, but refuses language extensions as well as further axioms or further primitive notions. It is unreasonable to ban extra axioms if one is liberal about language extensions at the same time. One can easily fool oneself: if one allows quantification over all propositions, it is possible to introduce the proposition that all propositions are true, and to use that as a definition of falsum. That gives the falsum rule as a theorem, and one does not have to call it an axiom any more. Nevertheless one has introduced the same non-constructivity, and possibly more, without knowing it. A constructivist uses constructions in the language, talks about them in the meta- language, but should not extend the language by internalizing pieces of metalanguage. Quantifying over all constructions that might ever arise is not constructive. Just by collecting them and quantifying over them, new constructions can be formed that had not been there in the first place. It is platonistic to appeal to a finished collection of constructions, closed under quantification. Automath tried to be as weak as possible, and therefore as constructive as possible. It leaves it to the user to decide on the introduction of axioms for classical logic and classical mathematics. Nevertheless Automath has a feature that was built in mainly for efficiency reasons: the so-called type inclusion, more or less equivalent to admitting the Pi-operator. It might be better to discard that feature, mimicking its effect by means of axioms (se e de Bruijn 1991b). That puts the responsibility as well as the freedom in the hands of the user. In particular the user gets the right to experiment with weaker forms of those axioms. 11 The scope of mathematics Mathematics is not just the study of numbers and geometrical figures, as used to be stated in the past. And it is not just set theory, as many still say (but do not believe) today. The point of view of verification systems is different. For them, mathematics is, primarily, anything they can verify. This is still very flexible, since languages can be extended, in particular by importing pieces of metalanguage. It is not the last word, of course, but typed lambda calculus is capable of handling almost anything we call mathematics. It can handle types of objects, of proofs, of geometrical constructions, of computer programs, and whatever else might come up in the abstract sciences. Therefore it seems attractive to turn the tables around and claim it as a definition: mathematics is anything that can be handled by typed lambda calculus. But we can go beyond this. Lambda calculus can be extended in many ways. We can have extensions by which it is possible to use large pieces of text (like theories) as objects. And typing can be used for doing mathematics simultaneously on more than 50 N. G. de Bruijn one level, i.e. language and metalanguage amalgamated, which is what many mathe- maticians seem to like. One might try to say that mathematics is anything that can be checked by a machine. Unfortunately this is a bit too vague, for the time being. 12 Platonism A historian writes about things that happened in the past, a journalist writes about what is happening today, but a novelist gets everything from his or her imagination. The first two write non-fiction, the novelist writes fiction, but all use the same language; there are no separate languages for fiction and non-fiction. Mathematics seems to talk about things, but do these really exist? We seem to have no way to find out, and, worse, we have no way to express what we mean by existence. It is called mathematical platonism to consider the mathematician as a journalist, and anti-platonism to consider him or her as a novelist. Verification systems definitely put an end to platonism. The only things these sys- tems deal with are texts in a language. These texts themselves have a certain physical existence: they can be represented by means of ink on paper and by electric or magnetic charges in computer hardware. But the things discussed by the texts usually lack physi- cal existence. Moreover, from the point of view of the verification system it is entirely irrelevant whether such physical existence exists. It is instructive to compare a mathematics verification system with a machine that simply verifies whether a given list of chess moves represents a legitimate game. Any sensible program achieves this by building the chessboard positions in the machine's memory, checking whether in each one of those positions the next move in the list is admitted by the rules of chess, and then updating the board accordingly. In this example we can say that the list of moves talks about the sequence of posi- tions, and that both the list and the positions are physically represented. In a mathemat- ics verification system, however, this is different. Even if mathematical objects might be represented physically, the system does not do it. The mathematical text is to be judged by its internal coherence, irrespective of interpretations or meanings. But it should be admitted that anti-platonists can have platonistic feelings too. Both the author and the reader of a novel know very well that all is fiction; nevertheless they try to imagine the story as a kind of reality. The mathematical anti-platonist may have platonistic feelings when thinking of the number 37 as a prime, recalling that from memory. According to anti-platonist principles he or she should have remembered an occasion in the past when the primality of 37 was established, but he or she thinks differently, preferring to remember the primality of 37 as a fact. A verification system would search for the previous proof, not for the fact. Platonists show some hypocrisy too: assuming a certain mathematical situation, they may give a long argument finally leading to a contradiction. So after all, the situa- tion was false, but all the time they had behaved as if it were as real as the truly existing mathematical objects. Another case of hypocrisy lies in elementary geometry, where it is hard to believe that platonists stick to their convictions. The euclidean plane was given no fixed origin, no fixed orientation, no fixed unit of length. If two platonists Type-theoretical checking and philosophy of mathematics 51 claim to talk about the same geometrical figure, the only thing they do is compare lan- guage. They have no way to find out or to express whether they are talking about the same objects. Referring to a drawing on paper may help them to understand each other better, but they will directly admit that the figure is not the mathematical situation itself. Platonists and anti-platonists are alike when it comes to forming mental images, possibly suggesting connections with older statements having the same or similar im- ages. It is the general technique of forming a body of associations for what we want to memorize. Any kind of imagination about mathematical situations can be helpful and stimulating; it does not matter whether it is considered fact or fiction. As long as no use is made of the claimed existence of mathematical objects, platon- ism does no harm at all; it is just irrelevant. It can be dangerous when used improperly. It may lull people into believing that they can get away with sloppy definitions of ob- jects, in the hope that those objects exist anyway, and that one can just approach then for a closer study if difficulties arise. Platonism is certainly confusing for beginning mathematics students in the matter of the existence quantifier, where the notion of existence is handled quite differently. It seems that platonism has left its mark even on the anti-platonistic world. All math- ematicians who handle classical logic accept that any statement is either true or false. Their confidence was not even shaken by the discovery of undecidable propositions. It is still legal to define a number C by saying that it is 1 if the continuum hypothesis is true, and 0 if it is false. Most of us will feel that C is not properly defined at all; yet it is within the rules of the game. It seems to do no harm: we have just built a number C for which the proposition C = 1 is undecidable. Does C exist in the sense of the platonists? Let us leave it to them to decide. The old question of whether mathematical situations are discovered or created is entirely a platonist's problem. Discovery means seeing an existing thing for the first time, creation means making a thing that was not there before, but will be there for ever after. In both cases it is about platonistic existence. The anti-platonist discovers the possibility to say something, and then says it. He or she forms a successful language text, and can make no distinction between discovery and creation: it is a single act. In most cases platonists will agree with this: many discoveries are not objects, but things like efficient definitions, useful notation, promising conjectures, and, above all, proofs (which were never seen as objects before the advent of type-theoretical verification). 13 Mathematics and the real world The well-known physicist E. Wigner made a famous statement about the incredible and undeserved success of mathematics in explaining the real world. A pure mathematician might find it even more remarkable that it holds in spite of the fact that a large part of that successful mathematics was always immature, incomplete, unfinished and partially incorrect. The relations between mathematics and the real world are both important and mys- terious. Wigner pointed at the success of mathematics in describing the physical world, but instead one might see it as a mysterious property of that world to behave in a way that can be described so adequately by mathematics. 52 N. G. de Bruijn The human race managed to extend the real world, creating new structures, new materials. After being invented they just became part of that real world. And because of modern technology, mathematical language has become a part of the real world too. There can be a machine that observes real physical phenomena, makes calculations on the basis of its findings, arrives at decisions and takes action. One may think of a tennis ball, flying through a room, bouncing on the walls, floor and ceiling. A machine can observe it and try to catch it with its limited possibilities of arm length and speed. It might have to apply artificial intelligence in order to cope with some extra conditions. Once this machine is programmed it can work as a tennis-ball-catching contraption for ever. It has become part of the real world, and mathematical language is part of its life, without any further human interference. One has to admit that the birth of the contraption required human intelligence in the first place, but that is also true of so many other things, like new materials and new species of flowers. Once they are there, they are part of reality. The language of mathematics is a physical reality, and that might be the root of its success. 14 Changing roles This section concerns attitudes about mathematics, and about changes of attitude under the influence of the possibility of mechanistic verification. To start with, there is the old chicken-and-egg problem of mathematics and logic. Which comes first? Is mathematics based on logic or is logic a particular branch of mathematics? In a verification system that handles proofs as objects, the difference between logic and mathematics vanishes almost entirely. Logical derivation rules can be derived, sometimes using mathematics. Such rules can be applied, both to logic and to math- ematics. Logical fundamentals have the same form as mathematical axioms. One might say that the difference between logic and mathematics is only traditional. Traditionally, logic is just the part of mathematics that is not taught explicitly at the time it should be, but studied later as a kind of metatheory. Verification systems definitely change our attitudes in this matter. The attitudes of today's mathematicians might be vaguely sketched by the roles of what shall be called M, P, F and L here. M is the body of all mathematical truth, i.e. mathematical objects and their relations. The question of whether this M might be a platonistic reality is presently irrelevant. P is the real physical world. All sorts of events in P seem to be reflected by objects and relations in M. F is a formal system, meticulously expressing the foundations for the establishment of truth in M. For most people, it contains logic and the foundations of formal set theory. L is the discussion language in which we think, write and talk. It is a mixture of words and formulas, and usually not very formal. The standard attitude seems to be that L talks about that in M, and that F provides the authority. The role of this authority is like the one of the legal system in our society: Type-theoretical checking and philosophy of mathematics 53 most people behave more or less within the limits set by that system, but rarely go to court. Manipulating the law is for specialists. Similarly, mathematicians believe that F is the office that gives them the right to work the way they do. F does not provide rules for handling the physical world. There is a discussion language that talks about the relation between M and P, but that is what most people call the physicist's language. Under the influence of verification systems the roles can change. The verifying computer does not handle mathematical objects and mathematical truth, but just the language that claimed to talk about them. That language plays the role of L. One might even say that by purification L itself becomes the language the machine can understand and verify. Then L is the only authority. It may be stimulating to use M as a kind of imagined reality, giving direction and even sense when we talk L, but all the authority is carried by L. It should be remarked that L talks about logic too, partly in order to support its work in general, partly as a mathematical subject just like any other. And if we need mathematics in studying the real world, L can talk directly about P, without interference by M. So L serves as the physicist's language too. What about Ff It becomes metatheory, not necessary for L's authority, but possibly useful for studying the limits of what L can achieve. It might give good clues for improving L, and within the reign of L it may give hints about where not to spend one's time. Metatheory may teach us not to waste our time on efforts to trisect angles by means of ruler and compass. In this picture the mathematician becomes a formalist, but there is nothing against this. Formalism is the essence of mathematics, as all non-mathematicians know. Over the years the word \"formalist\" acquired a negative connotation, and even became an insult. Wrongly, as it happens: the emotional dividing line should not be drawn between formalism and non-formalism, but between formalism and bureaucratic formalism. A bureaucratic formalist is someone who applies rules meticulously without ever thinking of higher motives like \"imagination\", \"meaning\", \"sense\" and \"beauty\". In that sense the machine is a bureaucratic formalist, and we are usually not. Quite honestly, we would not want our machines to have feelings like love. We know very well that \"love is blind\" holds in mathematics too. 15 Absolute safety? Claims that formal verification lead to absolute safety have no leg to stand on. Who checks the checker and the checking program? The program may be compared with its specifications, but who checks the specifications? For a part of the problem there is an obvious way out: one can take a verification program itself as the definition of correctness. That is about the same as what seems to have been the general norm in the past: a thing was correct if and only if meticulous human verification found no flaws. But there is an important difference: in the human case there used to be no explicitly stated rules for such verification. If we work on the principle that a verification program provides the only norm for correctness, it becomes a social problem to agree on a particular system. Such agree- ment can only be reached if the system is exceedingly simple and transparent. Typed 54 N. G. de Bruijn lambda calculus seems to be a good candidate, but still leaves a number of decisions to be taken. We were really much happier in the days when we had human verification only. We believed that different mathematicians handled the same norms for establishing correct- ness. We were in the fortunate position of being unable to specify this exactly. With computer programs we can, and therefore we have to. The confidence in human verifi- cation by serious mathematicians was based on experimental evidence, but in the case of computer software we know only too well that experimental evidence means enough for incorrectness but nothing for correctness. We have to be modest; nevertheless we can claim that a simple and transparent computerized verification system can check human-made mathematics much better than humans themselves could ever do. Quite another matter is what we should do when arguments are not produced by humans but by machines, and if those arguments are so big, ugly, boring or artificial that people would never be able to verify them. If a verification system accepts such machine-made proofs, should we really trust them? There is the possibility that our mathematical foundations might allow some bizarre paradox in a far-fetched situation that we would never encounter on our own. A machine that arrives there would be able to prove anything it liked, the automated verifier would find it correct, and the human user would remain unaware of the paradox. Such a bizarre paradox would of course invalidate our foundations of mathematics, and therefore all material based on them. Nevertheless business would go on as usual in \"ordinary\" mathematics. Indeed, we usually claim to work in foundational systems which are much stronger than we actually need, mainly because life seems to be so much easier, or so much more elegant, in stronger systems. But when really necessary, we can try to retreat to a weaker system of fundamentals. If, for example, our only interest lies infinite mathematics, it is reasonable to try to live entirely without infinity, in spite of the fact that life with infinity is so much easier. Similarly, if we note that all our real world applications of real numbers take place with rational approximations, we might try to live with rational numbers only. Alternatively, we might try to give an entirely different interpretation of our ordinary work with real numbers. We have to accept the possibility that our present system of mathematics is good enough for everyday use, but not arbitrarily far beyond that. Seen in that light it is dangerous to leave everything to machines. From a pragmatic point of view it is better to say that machines can be most helpful if they treat material produced in the style of human mathematicians and check it in a style that humans would accept as being essentially the same as what they would do themselves (if they had the energy, the time and the patience). In other words, in order that producing as well as checking mathematical material gets the confidence of the mathematical community, it should all be natural. This does not necessarily mean that we have confidence in reasonably short proofs only. A verification system might handle long proofs in such a way that we can read them at various levels of completeness. It might enable us to get a general outline as well as to read in more detail, and in such a way that at every moment we are able to Type-theoretical checking and philosophy of mathematics 55 inspect subdetails at various levels, zooming in and out whenever we please. This is about the same as what we expect from a well-organized human-produced proof. 16 Epilogue Verification systems insist on formal proofs. It is reasonable to ask whether this is really the only thing there is. What one often expects from a proof is that it gives confidence, not necessarily in an absolute sense. As an example we can take a theorem like the four-colour theorem for which it is claimed there is a proof based on a considerable amount of computer work. It cannot be called a formal proof. Even if there were a formal correctness proof for the semantics of the program, it would not be a proof of the colour theorem. At its best it would have proved the following theorem: if the program P is presented to a computer C that satisfies the specifications S, and if execution of P by C leads to the printed answer \"yes\", then the four-colour theorem is true. Now let three different people buy different computers for which the specification S is claimed in the supplementary booklet (an ideal situation!); they run the program P and they all get the answer \"yes\". This gives a tremendous feeling of confidence in the four-colour theorem. The feeling is good enough for deciding not to spend time and research money in attempts to disprove the four-colour theorem, but it cannot possibly be called a proof. The problem is not just the technological question of whether the computers do their work well. There would be exactly the same problem if all program steps were carried out by hand. This would prove a theorem which is not the four-colour theorem. It seems to be a fundamental difficulty; one might only hope that it could be overcome by extensions of the proof rules of mathematics. It would be quite different if the machines were to be programmed to do more than just say \"yes\", and produce a proof in our own language, much too long to read, but well structured in the sense that we can read it at every level we wish. This would give more than the confidence in the truth of the four-colour statement: we would be confident that we have a proof. We are left with the question: is our highest goal knowing truths or is it knowing proofs! Or should we say that the only royal way to truth is proof? The real anti-platonist would shrug his or her shoulders and say that there is no notion of mathematical truth beyond provability. Bibliography de Bruijn, N. G. (1975). Set theory with type restrictions. In \"Infinite and Finite Sets\", A. Hajnal, R. Rado and Vera T. Sos, eds, vol. I, Coll. Math. Soc. J. Bolyai, vol. 10, pp. 205-314. Reprinted in \"Selected Papers on Automath\", R. P. Nederpelt, J. H. Geuvers and R. C. de Vrijer, eds, Studies in Logic, vol. 133, North-Holland 1994, pp. 841-847. de Bruijn, N. G. (1980). A survey of the project Automath. In \"To H.B. Curry: Essays in combinatory logic, lambda calculus and formalism\", J. P. Seldin and J. R. Hindley, eds, Academic Press 1980, pp. 579-606. 56 N. G. de Bruijn Reprinted in \"Selected Papers on Automath\", R. P. Nederpelt, J. H. Geuvers and R. C. de Vrijer, eds, Studies in Logic, vol. 133, North-Holland 1994, pp. 141-161. de Bruijn, N. G. (1984). Formalization of constructivity in Automath. In \"Papers dedi- cated to J.J. Seidel\", P. J. de Doelder, J. de Graaf and J. H. van Lint, eds, EUT-Report 84-WSK-03, ISSN 0167-9708, Department of Mathematics and Computing Science, Eindhoven University of Technology, pp. 76-101. Reprinted in \"Selected Papers on Automath\", R. P. Nederpelt, J. H. Geuvers and R. C. de Vrijer, eds, Studies in Logic, vol. 133, North-Holland 1994, pp. 849-864. de Bruijn, N. G. (1991a). Checking mathematics with computer assistance, Not. Am. Math. Soc. vol. 38(1), Jan. 1991, pp. 8-15. de Bruijn, N. G. (1991b). A plea for weaker frameworks. In \"Logical Frameworks\", G. Huet and G. Plotkin, eds, Cambridge University Press, pp. 40-67. de Bruijn, N. G. (1994a). The Mathematical Vernacular, a language for mathematics with typed sets. In \"Selected Papers on Automath\", R. P. Nederpelt, J. H. Geuvers and R. C. de Vrijer, eds, Studies in Logic, vol. 133, North-Holland, pp. 865-935. de Bruijn, N. G. (1994b). Reflections on Automath. In \"Selected Papers on Automath\", R. P. Nederpelt, J. H. Geuvers and R. C. de Vrijer, eds, Studies in Logic, vol. 133, North-Holland pp. 201-228. de Bruijn, N. G. (1995). On the roles of types in mathematics. In \"The Curry-Howard Isomorphism\", Ph. de Groote, ed., Cahiers du Centre de Logique, vol. 8, Academia, Louvain-la-Neuve (Belgique), pp. 27-54. Nederpelt, R. P., Geuvers, J. H. and de Vrijer, R. C. (eds) \"Selected Papers on Au- tomath\", Studies in Logic, vol. 133, North-Holland. 4 The Hahn-Banach theorem in type theory Jan Cederquist and Thierry Coquand Department of Computing Science, Chalmers University of Technology and University ofGoteborg and Sara Negri Department of Philosophy, University of Helsinki 1 Introduction We present the basic concepts and definitions needed in a pointfree approach to func- tional analysis via formal topology. Our main results are the constructive proofs of localic formulations of the Alaoglu and Helly-Hahn-Banach1 theorems. Earlier pointfree formulations of the Hahn-Banach theorem, in a topos-theoretic setting, were presented by Mulvey and Pelletier (1987,1991) and by Vermeulen (1986). A constructive proof based on points was given by Bishop (1967). In the formulation of his proof, the norm of the linear functional is preserved to an arbitrary degree by the extension and a counterexample shows that the norm, in general, is not preserved exactly. As usual in pointfree topology, our guideline is to define the objects under analysis as formal points of a suitable formal space. After this has been accomplished for the reals, we consider the formal topology £(A) obtained as follows. To the formal space of mappings from a normed vector space A to the reals, we add the linearity and norm conditions in the form of covering axioms. The linear functional of norm from A to the reals then correspond to the formal points of this formal topology. Given a subspace M of A, the classical Helly-Hahn-Banach theorem states that the restriction mapping from the linear functionals on A of norm to those on M is sur- jective. In terms of covers, conceived as deductive systems, it becomes a conservativity statement (cf. Mulvey and Pelletier 1991): whenever a is an element and U is a subset of the base of the formal space £(M ) and we have a derivation in £(A) of , then we can find a derivation in £(M ) with the same conclusion. 1 As explained by Hochstad (1980), the main idea in the usual proof of what is called the Hahn-Banach theorem is due to Helly. Since this is also the key idea in our derivation, we here rename the theorem in this way. 58 J. Cederquist, T. CoquandandS. Negri With this formulation it is quite natural to look for a proof by induction on covers. Moreover, as already pointed out by Mulvey and Pelletier (1991), it is possible to sim- plify the problem greatly, since it is enough to prove it for coherent spaces of which C.(A) and C,(M) are retracts. Then, in a derivation of a cover, we can assume that only finite subsets occur on the right-hand side of the cover relation. A global proof trans- formation makes it possible to change a derivation in C(A) into a derivation in L(M), since only a finite-dimensional extension of the space M has to be taken into account. In consequence, as in the case for the classical proof for the one-dimensional extension, no use of Zorn's lemma is needed. Of the earlier two pointfree proofs of the Hahn-B anach theorem, that of Mulvey and Pelletier (1991) shows the Hahn-Banach theorem in any Grothendieck topos. However, the argument relies on Barr's theorem, for which no constructive justification has been given so far. The proof of Vermeulen (1986) is done in the framework of topos the- ory with a natural number object, and thus, a priori, relies on the use of impredicative quantification. Here as elsewhere (cf. Cederquist and Negri 1996; Coquand 1992, 1997; Negri and Valentini 1997) the use of formal topology allows for elementary and constructive proofs of pointfree formulations of classical results. The two main contributions of this paper are the following: (1) Our proof of the pointfree version of the Hahn-Banach theorem, following rather closely the original proof by Helly. (2) This proof can actually be expressed in Martin-Lof 's type theory (cf. Martin-Lof 1972). In fact, on the basis of our proof, the first author has done a formalization of the Hahn-Banach theorem in an implementation of the intensional version of type theory with one universe and finitary inductive definitions (see Cederquist 1997). 2 Preliminaries We recall here the definition of formal topology introduced by Per Martin-Lof and Gio- vanni Sambin (see Sambin 1987). We remark that, in contrast to the definition given by Sambin and without any substantial difference in the development of the theory, we do not require the base monoid to have a unit. Nor do we have the positivity predicate used by Sambin. Definition 2.1 (Formal topology) A formal topology over a set S is a structure where is a commutative monoid,\\ is a relation, called cover, between elements and subsets of S such that, for any ' ~ and , the following conditions hold: (reflexivity) (transitivity) where The Hahn-Banach theorem in type theory 59 (dot-left) (dot-right) where For readability reasons, when a singleton set occurs we will sometimes omit the curly brackets, and write for , and U • b for U • {b}. Since we dropped the unit element and the positivity predicate in the definition of formal topology, the definition of formal points given by Sambin (1987) has to be revised as follows: Definition 2.2 Let \\ ) be a formal topology. A subset a ofS is said to be a formal point if for all S the following conditions hold: (1) (2) (3) In order to maintain the usual intuition on points, in the sequel we will write a. \\\\- a (a forces a, or a is a point in a) in place of i As an instance of the abstract definition of formal topology the continuum can be defined as a formal space. The proofs that this definition satisfies the rules of a formal topology can all be found in Cederquist and Negri (1996). Further properties of the continuum as a formal space can also be found in Negri and Soravia (1996), where a slightly different definition adopting the unit is given. Definition 2.3 The formal topology of formal reals is the structure where Q is the set of rational numbers. The monoid operation is defined by (p, q) • (r, s) = (max(p, r), min(q, s)), and the cover \\ by where the relation . is inductively defined by (1) (2) (3) (4) 60 J. Cederquist, T. Coquand and S. Negri We denote by Pt(R) the collection of formal points of \"K,, called formal reals. In Cederquist and Negri (1996) it is proved that and are cover relations. Moreover, . is a Stone cover, since we have: Proposition 2.4 If (p, q) U, then there exists a finite subset t/o of U such that Proof See Cederquist and Negri (1996). D In Cederquist and Negri (1996) it is also proved that whenever and U is finite then I and therefore . is the Stone compactification (cf. Sambin 1987; Negri 1996) of \" but this stronger result will not be used in the sequel. With / = (p, q) and J = (r, s), we write (resp. ) to express that (resp. . Thus / j U means J • U for all Moreover, we use the notations I + J for (p + r, q + s), and / / for (tp, tq) when and for (tq, tp) when The following lemma will be used in section 3. Lemma 2.5 // , and , then there exists a subset V of such that andJ< ,f V. Proof Straightforward by induction on the derivation of I • U. D 3 Formal linear functional In this section we define the space of linear functionals of norm _ from a seminormed space to the reals. This space is obtained by means of an inductive definition giving rise to a formal topology: basic neighbourhoods correspond to basic opens in the weak* topology (Brezis 1983) and formal points correspond to the linear functionals of norm _ from the given seminormed space to the space of formal reals. Moreover, the formal cover for this space is defined explicitly from a Stone cover, and therefore a simple proof of Alaoglu's theorem is obtained. 3.1 The dual of a seminormed space as a formal space We start by defining a seminormed space as in Mulvey and Pelletier (1991). The semi- norm is defined by means of formal open balls centred around the origin. Definition 3.1 A seminormed space A on the rationals Q is a linear space A on Q together with a mapping from the positive rationals to the subsets of A satisfying the following conditions for The Hahn-Banach theorem in type theory 61 We limit ourselves to the presentation of the formal space C(A) of linear functionals of norm The basic opens are finite sets of the form where and are rational intervals. The intuitive reading of a basic open is that of a neighbourhood of functionals in the weak* topology. In the sequel we will use the notation for We obtain with the operation a commutative and idempotent monoid with unit given by the empty set. We will denote such a base of t Let then define and Then, without assuming decidability of equality in A, is a reflexive and transitive relation. Equality between basic neighbourhoods is subset equality Note that i implies This defines an equivalence relation on the type of basic neighbourhoods. We follow Bishop (1967) in working systematically with types with an equivalence relation. Whenever we define a predicate, we have to be careful to check that this predicate respects the equivalence relation. The finitary cover for £(A ) is inductively defined as follows: Cl C2 C3 C4 C5 62 J. Cederquist, T. Coquand and S. Negri A motivation for the above definition can be given as follows: conditions C1-C 3 define formal functional from A to the formal reals, C4 and C5 impose linearity and C6 says that we only consider functionals of norm Note that, by C2, we have w f whenever and i In order to get a finitary inductive definition, the subset V in clause C3 has to be finite. This, however, is not a restriction since is a Stone cover and such a finite set can always be found. We have: Proposition 3.2 The relation is a cover. Proof Reflexivity holds by definition, dot-left follows from C2 since transitivity and localization are straightforward by induction on the derivation of i Then is defined by Next, we prove that is a cover, but before that some lemmas are needed. Lemma 3.3 and , then ( ). Proof Starting from the hypotheses ...) and , the intervals . ' _ _ ) are constructed in the following way. By definition, for each _ i there exists such that and j . Since . ' n we have . Thus we put I ' ~ jk. D The following lemma makes the definition of legitimate. Lemma 3.4 The relation • respects equality between basic neighbourhoods. Proof We will show that C2 also holds for . The conclusion then follows since implies _ Suppose I and . Let . Then, by Lemma 3.3, there exist : such that i . For such we have \"' \"' ~ f and, by Therefore D Lemma 3.5 Ifw U then i Proof Suppose and let. . Then so, by C2, Therefore ' D The Hahn-Banach theorem in type theory 63 The following lemma is used in the proof of transitivity for < Lemma 3.6 and ( then Proof By induction on the derivation of then thus by1. If . definition 2. IJ is derived by C2 from and then by Lemma 3.3 there exist such thai For such by induction hypothesis Then 3. Let be derived by C3 from and where V is finite. Since anc , by Lemma 2.5, we can construct a finite subset V\" such that and Then, by induction hypothesis and, b\\ 4. Let be derived by C4 frorr Then so, by induction hypothesis. and, by 5. Similar to 4. o. Let be derived by C6 from and. there exists a such thai For such an r, by induction hypothesis, the claim follows by C6. Now We are now ready to prove: Proposition 3.7 The relation is a cover. Proof Reflexivity: Immediate from the reflexivity of • and Lemma 3.5. Dot-left, dot-right: Immediate from the definition of and the corresponding prop- erties of • Transitivity: Suppose ( and I /„, then we can find , „ such that , and, by definition of , we get Lemma 3.6 now gives . Thus { '. O Finally, the following lemma will be useful in section 4. Lemma 3.8 The axioms for are valid rules for Proof 1: Given is immediate from C l and Lemma 3.5. 2: See the proof of Lemma 3.4. 3: Suppose and Let . Then there exists such that . For such an 64 J. Cederquist, T. Coquand and S. Negri V, so by Lemma 2.5 there exists a subset V' such that and v - - ,v ^)- But then, since • f is a Stone cover, there exists a finite subset u _ ' such that i . _, 'o an(^ ( „- - - - ')• Now, by definition of ) and, by C3, . Therefore 4 and 5 follow easily from the definition of , C4 and C5, respectively. 6: Suppose and Let By AH, there exists i 1 such that I. For such an N(l). Now, by C5 and the definition of and, by C6, . Therefore > D 3.2 Linear functionals as formal points In this section, which is not needed for the proof of the Hahn-Banach theorem, we will show how linear functionals of norm from A to the formal space of reals are obtained in our setting. We denote the collection of formal points of C(A) by Pt (£(A)). Given and; , let The following propositions are easily proved from the definitions (see also Mulvey and Pelletier 1987): Proposition 3.9 F* is a linear functional from A to Pt(R) of norm , that is: (1) For all (2) (3) (4) Conversely, given a linear functional / from A to Pt(K), that is a map satisfying 1-4 as in Proposition 3.9, let _ ' be the subset of S^(A) defined by Then we have: Proposition 3.10 The correspondence stated above is bijective since we have, with the notation used above, and 3.3 Alaoglu's theorem The cover is a Stone cover, since we have: Proposition 3.11 If then there exists a finite subset such that \\ Proof The proof is straightforward by induction on the derivation of . We will only consider the case when is obtained by C3 from i . V The Hahn-Banach theorem in type theory 65 and , for a finite subset V. By induction hypothesis, given an element. _ . , there exists a finite subset Uj of U such that . Let f/0 be the union of all such Uj. Then by C3, i D As an immediate consequence of the definition of the cover for £(A), we obtain Alaoglu's theorem, asserting that the unit ball of the space of linear and continuous functionals is compact in the weak* topology. Corollary 3.12 The formal space £(A ) is compact. Proof Given , by definition of • _, Then, since • is a Stone cover, ) for some finite subset i of U. Therefore, by Lemma 3.5, • r o- n 4 The Helly-Hahn-Banach theorem In this section we prove the localic version of the Helly-Hahn-Banach theorem in the form of a conservativity result of the theory for the cover in £(A ) over that in £(Af). At the end of the section we also provide an informal motivation why this result is the localic statement of the usual point-set theorem. The definition of in terms of allows us to replace with for proving conservativity. If M is a linear subspace of A, we say that r for £(A ) is conservative over for £(M ) if, whenever w is an element and U is a subset of the base of £(M ) and w U in £(A), then in £(M). Conservativity of for £(A ) over i for £(M ) is defined in the same way. Then we have: Proposition 4.1 If for L(A) is conservative over for £(M), then \\forC(A) is conservative over for £(M). Proof If in £(A), then, for all ; hence by conservativity for , for all. , i U in £(M ) and hence D The localic statement of the Helly-Hahn-Banach theorem in the framework of for- mal topologies is \"• for £(A) is conservative over • for £(M)\". By the above propo- sition it thus reduces to the following: Theorem 4.2 for C(A) is conservative over • for C(M). Since is a Stone cover, we can transform any derivation of a U in £(A ) into one in which only finite subsets occur on the right-hand side of the cover relation. Therefore we can assume that only a finite number of elements not belonging to the base of £(M ) are involved. Thus, arguing by induction, the problem is reduced to showing that if a U is derived in £(M'), where and x is an element in the base of £(A), then there also exists a derivation of a U in £(M). The claim of Theorem 4.2 thus becomes: Proposition 4.3 for C(M') is conservative over for £(M). We will use the notations and \\ to express that f in £(M ) j and £(M'), respectively. Before proving the proposition, some auxiliary lemmas will be needed. 66 J. Cederquist, T. Coquand and S. Negri Lemma 4.4 Proof Since'.. i implies that we have by definition of that By N2 and 3.8(6) we have and similarly so by stability Since every interval can be covered by arbitrarily small intervals, using 3.8(3), we get and by 3.8(4) Now, if then and, by 3.8(2), Then, since the right-hand side is covered by anything, in particular the empty set. If < •' we obtain symmetrically \" ), where . We thus obtain The Hahn-Banach theorem in type theory 67 Let / be a finite index set, , .,, and sequences of A and Q, respectively, such that . Then, for rational q, define The following lemma is the core of our proof. Intuitively it says that we can find a rational approximation for the value of u(x), where u is a generic linear functional. We observe that the argument is similar to the one used by Helly. Lemma 4.5 Proof First observe that for all such that ?,• = 0, we can apply C6 and dot-right. So, in the rest of this proof, we can assume that i ' for all i. For any , by the rules of N we have By the rules for we get and by Lemmas 3.5 and 4.4 From the definition of we obtain the same for , and by dot-right Now there are two cases depending on whether ?,• is positive or negative; we only con- sider the case when ?,• is positive: If then because, |, so we get and a fortiori ( 68 /. Cederquist, T. Coquand and S. Negri Let / be a finite set as above. We define as where the axiom C6 is replaced by Let be an element in the base of M' and let q be a rational number. Then define Note that lepends on the proof of and if. there are many ways of writing and thus many proofs of i . We have: Lemma 4.6 // U, then v Proof By induction on the derivation of U . We only consider the cases C\\' and C6'. Cl': Given 1 since we have two proofs of and two possibly different values of and i Then there are two cases: if < ), then and; r, and thus ; if then. C6': By the inductive hypothesis we have which gives, since D Observe here that we do not require decidability of membership of M. In Lemma 4.6 a large part of the effort is devoted to the possibility of different values of for different proofs of i. This problem only occurs when . So decidability would simplify the proof; if j then M' = M and there is nothing to prove, and if then the formulation and the proof of Lemma 4.6 are easier. If ID is an element and U is a subset of the base of C(M), then and so as a corollary to Lemma 4.6 we obtain: Corollary 4.7 Let w be an element, U a subset of the base of C(M), and suppose Then. The Hahn-Banach theorem in type theory 69 Proof of Proposition 4.3: Suppose ', where w is an element and U a subset in the base of £(M). First, by examining the axioms of the form C6 in the proof of , we can find finite sequences and in A and in Q, respectively, such that (Then , th e proof o f ca n b e converted j into a proof of , U. By Corollary 4.7 we have If and there is nothing to prove. If then / and, since (Lemma 4.5), we obtain U by localization and transitivity. D We include a proof in this setting of the following application of the Helly-Hahn- Banach theorem (which is proved indirectly by Mulvey and Pelletier (1987), whereas Vermeulen (1986) gives a direct proof). Proposition 4.8 If { , then The above proposition is proved by interpreting the neighbourhoods of as subsets of First we define, for and / = (p, q), Then we put otherwise and let be the union of all such that Then we have: Lemma 4.9 If- in ,then Proof The proof is by induction on the derivation of w < / U. 1.Let w U be derived by C l from . Then, by the definition, i so By N2, i and for such an . Thus ( ~ J For 2-6 below we argue by case analysis on the way i ' is constructed. The cases and i are easy, so below we only consider the third case for which 2. Let be derived by C2 from and From the definition of ind and , for some , thus -By induction 70 J. Cederquist, T. Coquand and S. Negri hypothesis . For such an 2 so, by transitivity, ''. Hence the claim. 3.Supposei s derived by C3 from V finite,and i Here also we only consider the case for which w' is a singleton set of an interval, the other cases being easy. By induction hypothesis and since V is finite we can take the smallest such r and obtain. i. We assume V to be non-empty, since if V is empty, / is negative and the claim follows easily. Since i . Moreover, so, by transitivity, ( ?'. Hence the claim. 4.Supposei s derived b y C 4 from By induction hypothesis i '). Then we just notice that { and hence the claim. 5. Similar to 4. 6. Suppose is derived by C6 from and { Again, we only consider the case in which w' is a singleton set of an interval. By N4 and i i, and by induction hypothesis, We have then and therefore we have and the claim follows from i. Thus ( D Proof of Proposition 4.8 Suppose Then, by the (localic) Helly-Hahn-Banach theorem, we have ) and, by definition of . Thus, by Lemma 4.9, there exists an such that and . Therefore (cf. Cederquist and Negri 1996, Lemma 10) ( ), that is 1, and thus. D The usual Hahn-Banach theorem states that the restriction mapping is surjective. We can obtain this result from ours plus an assumption of extensionality, up to an arbitrarily good approximation. That is, we can prove that given g in Pt(C(M)) and given r there exists such that . By contradiction, suppose that no such / exists. Then by extensionality and therefore, by conservativity, which contradicts. The Hahn-Banach theorem in type theory 11 5 Conclusion The basic problem of the Helly-Hahn-Banach theorem can be formulated as follows. We have a normed vector space M, a linear functional u on M of norm : 1, and we want to extend M to |. For this we consider two families We have . for all _ and the core of the question is to find a real number r such that 'v for all x and y. Classically this is possible by taking ). Intuitionistically, there is no reason why Ax should have a supremum. There are then two alternatives: Bishop (1967); Bridges and Richman (1987): One finds instead an extension u' of u of norm 'or any given For this, given we change Ax and By into We still have , , but the difference is that now sup(A'x) exists, because A'x goes to when x is big, and we can, in the finite-dimensional case, restrict sup(A'x) to a compact subset of M. So here we build a linear functional that extends the given one, but with norm _ instead of Formal topology: One reduces the problem to a finite collection of x and y. We can then take supA x, over a finite subset of M. We never build a functional, only a finite approximation. From this analysis, it is quite unlikely that one can easily deduce the Bishop version from the formal one, nor do we think that the proof in formal topology follows from Bishop's formulation. On the other hand, the formal one may be as good as Bishop's result for applications, since in an application one will only need finite approximations of a functional. As we said, our proof can be represented in Martin-L6f's type theory, and indeed, proof-theoretically, we use only the notion of finitary inductive definition. An interest- ing question at this point is the connection of our work to the work of Brown and Simp- son (1986). For instance, our spaces are absolute (see Fourman and Grayson 1982) only for separable vector spaces, which explains the separability restriction, in Brown and Simpson (1986), that does not appear here. One aim of this approach is to provide an alternative to Bishop's treatment of func- tional analysis in constructive mathematics. For this, it will be important to find concrete instances of the use of the Alaoglu and Hahn-Banach theorems, for which our proof can help to extract their computational content. 72 J. Cederquist, T. Coquand and S. Negri Bibliography Aczel, P. (1977). An introduction to inductive definitions, in \"Handbook of Mathemati- cal Logic\", J. Barwise ed., pp. 739-782, North-Holland, Amsterdam. Bishop, E. (1967). \"Foundations of Constructive Analysis\", McGraw-Hill, New York. Brezis, H. (1983). \"Analyse fonctionelle - Theorie et applications\", Masson Editeur, Paris. Bridges, D. and Richman, F. (1987). \"Varieties of Constructive Mathematics\", London Mathematical Society Lecture Notes Series 97, Cambridge University Press. Brown, D. K. and Simpson, S. G. (1986). Which set existence axioms are needed to prove the separable Hahn-Banach theorem?, Annals of Pure and Applied Logic 31, pp. 123-144. Cederquist, J. (1997). A Machine Assisted Proof of the Hahn-Banach Theorem, sub- mitted for publication. Cederquist, J. and Negri, S. (1996). A constructive proof of the Heine-Borel cover- ing theorem for formal reals, in \"Types for Proofs and Programs\", S. Berardi and M. Coppo eds, Lecture Notes in Computer Science 1158, pp. 62-75, Springer. Coquand, T. (1992). Constructive topology and combinatorics, Lecture Notes in Com- puter Science 613, pp. 159-164, Springer. Coquand, T. (1997). Minimal invariant spaces informal topology, Journal of Symbolic Logic 62, pp. 689-698. Fourman, M. P. and Grayson, R. J. (1982). Formal spaces, in \"The L. E. J. Brouwer Centenary Symposium\", A. S. Troelstra and D. van Dalen eds, pp. 107-122, North- Holland, Amsterdam. Hochstad, H. (1980). Eduard Hetty, Father of the Hahn-Banach theorem, Mathematical Intelligencer, 2, no. 3, pp. 123-125. Martin-L6f, P. (1972). An Intuitionistic Theory of Types, University of Stockholm, Stockholm, this volume. Mulvey, C. J. and Pelletier, J. W. (1987). The dual locale of a seminormed space, Cahiers de topologie et geometric differentielle, 23, no. 1, pp. 73-92. Mulvey, C. J. and Pelletier, J. W. (1991). A globalization of the Hahn-Banach theorem, Advances in Mathematics 89, pp. 1-60. Negri, S. (1996). Stone bases, alias the constructive content of Stone representation, in \"Logic and Algebra\", A. Ursini and P. Agliano eds., pp. 617-636, Dekker, New York. Negri, S. and Soravia, D. (1996). The continuum as a formal space, Archive for Math- ematical Logic, in press. Negri, S. and Valentini, S. (1997). Tychonoff's theorem in the framework of formal topologies, Journal of Symbolic Logic 62, pp. 1315-1332. Sambin, G. (1987). Intuitionistic formal spaces - a first communication, in \"Mathe- matical Logic and its Applications\", D. Skordev ed., pp. 187-204, Plenum Press, New York. Vermeulen, J. J. C. (1986). \"Constructive Techniques in Functional Analysis\", Ph.D. Thesis, University of Sussex. A realizability interpretation of Martin-Lof s type theory Catarina Coquand Department of Computing Science, Chalmers University of Technology and University ofGoteborg 1 Introduction The notion of computability predicate developed by Tail gives a powerful method for proving normalization for various A,-calculi. There are actually two versions of this method: a typed and an untyped approach. In the former approach we define a com- putability predicate over well-typed terms. This technique was developed by Tail (1967) in order to prove normalization for Godel's system T. His method was extended by Gi- rard (1971) for his System F and by Martin-Lof (1971) for his type theory. The second approach is similar to Kleene's realizability interpretation (Kleene 1945), but in this ap- proach formulas are realized by (not necessarily well-typed) A.-terms rather than Godel numbers. This technique was developed by Tail (1975) where he uses this method to obtain a simplified proof of normalization for Girard's system F. The method was later rediscovered independently by several others, for instance Mitchell (1986). There are two ways of defining typed X-calculus: we have either equality as con- version (on raw terms) or equality as judgments. It is more difficult to show in the theory with equality as judgments that every well-typed term has a normal form of the same type. We can find different approaches to how to solve this problem in Altenkirch (1993), Coquand (1991), Goguen (1994) and Martin-Lof (1975). There are several papers addressing normalization for calculi with equality as untyped conversion; two relevant papers showing normalization are Altenkirch's (1994) proof for system F using the untyped method and Werner's (1994) proof for the calculus of constructions with inductive types using the other method. Another difference is the predicative and im- predicative formulations of A.-calculi where it is more intricate to prove normalization for the impredicative ones. The aim of this paper is to give a simple argument of normalization for a theory with \"real\" dependent types, i.e. a theory in which we can define types by recursion on the natural numbers (like N\"). For this we choose to study the simplest theory that has such types, namely the N, II, U-fragment of Martin-Lof's polymorphic type theory (Martin-Lof 1972) which contains the natural numbers, dependent functions and one universe. This theory has equality as conversion and is predicative. Martin-Lof gives in this paper a normalization proof based on a typed computability predicate. This 5 74 C. Coquand paper illustrates the simplicity of Tail's untyped method. One advantage of building an untyped realizability model is that we can separate the definition of the theory and the definition of the model. The problem when building a realizability model for theories with dependent types is that we can no longer define the realizability predicate by induction on the type. We will instead build a realizability model that captures the idea that types (formulas) and terms depend on each other. To do this, we give mutually dependent definitions of what expressions are to be realized and by what. 2 The set of expressions The set,. , of expressions that we will consider is: Definition 2.1 where V is a set of variables. We use the notation for apply(... apply . We also use the notation i for ), and for the case when x does not occur freely in B. An expression is non-canonical if it is a variable or if it starts with natrec or apply. 2.1 Untyped reduction Parallel substitution, , is defined as usual where name clashes when substituting under A are avoided by a-conversion. Equality on expression is up to a- equivalence. The definition of contraction gives the computation rules of the non-canonical ex- pressions. Definition 2.2 Contraction, >, is defined by: natrec (0 , b , c) b natrec(succ(a), b , c) c a natrec(a, b , c ) app\\y(Xx.b,a) b{a/x}. Definition 2.3 We define reduction, ->, as the least reflexive, transitive congruence containing >. We also say that a converts with b, denoted by a = b, if a and b have a common reduct. An expression is irreducible or normal if it does not contain any subexpression that can be contracted, or normalizable if it can be reduced to a normal expression. Lemma 2.4 The reduction defined above has the Church-Rosser property; that is, if a —> b and a —> c then there exists an expression, d, such that b —> d and c —>• d. The proof of this lemma is similar to the proof of Church-Rosser in (Martin-L6f 1971). A realizability interpretation of Martin-Lof's type theory 75 As consequences of the Church-Rosser lemma we have the following two corollaries: Corollary 2.5 If an expression has a normal form, then this normal form is unique. Corollary 2.6 The relation = is an equivalence relation. 3 The syntactic model A problem when defining a realizability interpretation is that types may depend on terms. We can, for example, define natrec which describes the type . We will therefore simultaneously define what are the expressions to be realized and by what they are realized. The construction of the model will be in two steps. First we build the model for expressions that intuitively correspond to small types (i.e. types that do not contain U). From this model we then build the model for large types. 3.1 Definition of the realizability predicate We will give an inductive definition of a predicate over ^ (the set of syntactic expres- sions), which intuitively holds for the types to be realized, although , j might hold even if A is not a type. Simultaneously we define a function, , that given an expression A and a proof of returns a predicate over £ which should hold for the expressions that realize A. We will denote the predicate we obtain by applying to A and a proof of' i by , letting the proof of \\) be implicit. Furthermore means a satisfies the predicate Let F be the set of normal and non-canonical expressions and let M be the induc- tively given set that contains 0, succ(«) if i and a if < Definition 3.1 Definition of and (1) is inductively given by: (a) holds, (b) 0) holds, if' I, and if for all expressions, a, such that we have ), (c ) holds, if'an d (d) ' ) holds, if there exists an expression, B, such that A B and (2) The predicate is defined by induction on the proof that holds, as follows: (a) If a b and b A/\", then i holds. (b) //> 1)) holds by Ib, then . ^ , , ),b) holds if- holds for all expressions, a, such that (c) If\\ ) holds by Ic, then if there exists an expression, b, such that a b and b (d) If * holds by Id, i.e. there exists an expression, B, such that. and' then • holds if 76 C. Coquand We can now define and in the same way for expressions that intuitively cor- respond to the big sets by changing for and for ' in the definition above and adding: l(e) . ) holds. 2(e) holds if i . In appendix B a simplified implementation of these predicates is given where the proof objects are made explicit. For justifications that these predicates are correct in- ductive definitions see Aczel (1980), Allen (1987), Dybjer (1997) and Scott (1975). Martin-Lof's first version of type theory (1971) was based on an impredicative ax- iom which expresses that there is a type of all types. In the same paper he also gives a normalization proof for the theory. We could try to do something similar by defining i I as \"The predicate i is defined as ', but this is not a correct inductive definition. However, it was later shown by Girard that this theory was inconsistent. 3.2 Some properties of the readability predicates Lemma 3.2 If holds, then has the following properties: (1) If then (2) If and ifb is a term such that a = b, then (3) If then a is normalizable. Proof The proof is by induction on the proof of . We only present the case when A is . By induction hypothesis we then know that 1-3 hold for and if c is an expression such that , then 1-3 hold for (1) We have to show that if i \", then . Take an arbitrary expression c and assume I. Let c' be the normal form of c (we know that it exists by induction hypothesis); then . By induction hypothesis (using 1 and 2) we get and we are done. (2) By induction hypothesis and definition of i (3) We must show that implies a is normalizable. Let x be an arbi- trary variable. By induction hypothesis we know that ) since . By definition of' we get . By induction hypothesis a x is normalizable and then so is a (by a direct combinatorial reasoning). D We define equality on predicates, by j if for all a, P(a) if and only if Q(a). Lemma 3.3 If^ holds and A = B, then holds and Proof By induction on the proof of D Lemma 3.4 If ) holds, then A is normalizable. Proof By induction on the proof that holds, using similar techniques as in the proof of 3.2. D The properties for ind stated above also hold for and . They are proved in A readability interpretation ofMartin-Lof's type theory 77 the same way. In what follows we use the same reference for the properties of and as for. and ' As a direct consequence of these lemmas we get: Corollary 3.5 If \\ holds, A = B and a = b, then Lemma 3.6 If holds, then holds and Proof By induction on the proof of D 4 The theory The theory that we will be concerned with is the fragment of the polymorphic theory with intensional equality presented in Martin-L6f (1972). All the rules are given in appendix A and we will only present here the type equality rule. In Martin-Lof's type theory (1972) the type equality is stated as: In this way an arbitrary judgement, , implies that C is a type. Another way is: With this formulation c e C does not imply C is a type, only that it is equal to one. The proof of normalization works for both formulations. Lemma 4.1 If and a b, then Proof The proof is similar to the one in Martin-L6f (1971). D This lemma also holds if the judgements are made in a non-empty context. Lemma 4.2 If A type and, , then B type. As an easy consequence we get the following corollary. Corollary 4.3 If , i and > , then , 5 The interpretation We will now define an interpretation of types and objects of a type into the syntactic model. We do this by proving that if A type, then i and if hen This will be done in a context and the precise formulation is as follows. Lemma 5.1 (1) If we have a derivation of anda\\, ... ,a n are expressions such that $(Ai), ... , $>(A n{ai/xi,..., a n -i/x n -i}) 78 C. Coquand and then ' (2) If we have a derivation of and i are expressions such that and then and To make the proof easier to read we will leave out all the free variables except the eigenvariables. Proof The proof is rather straightforward by induction on the proof of the judgements. We will only mention a few here. N - elimination By induction hypothesis we know that: (1)fo r all expressions m such that i (2) (3) 0 and (4) Since , we know that there exists an expression, a', such that and . By corollary 3.5 it is enough to prove that :)). We do this by induction on the proof of A readability interpretation ofMartin-Lof's type theory 79 (1) If By (3) and (4) we get that b and c are normalizable. Hence natrec(a', b, c) can be reduced to natrec Since, by Iemma3.2,i , natrec i)weget(j }, natrec( I)by corollary 3.5. (2) If a' is 0, then it is immediate by induction hypothesis and corollary 3.5. (3) If a' is succ(m) and , we get by induc- tion hypothesis. From the definition of and (4) we get \\, c m r\\a\\rec(m,b,c)). Since natrec(succ(m), b, c) = cmnatrec(m,£,c) we get , natrec(succ(m), b, c)) and we are done. U-introduction: By induction hypothesis we know that holds and that for all a such that. we have Since we have that holds and by lemma 3.6, we then get that' holds and , ^ , , x-i). Suppose that ', , , ) holds for arbitrary a; then we also have that ). By assumption we then know that and then we must have -By definition of we get i and hence Type-formation: By induction hypothesis we know that < and we must then have By lemma 3.6 we then have that holds. D As a direct consequence of this lemma we get that the theory considered in this paper has the normalization property. Theorem 5.2. (The normalization theorem) If we have a derivation of then a is normalizable. Proof Since we can only introduce a variable in one way, we must have that A \\ type, A 2 type and so on. Lemma 5.1 then gives that < I holds, lemma 3.2 gives lemma 5.1 gives and so on. Hence we can apply lemma 5.1 and obtain c . By the third part of lemma 3.2 we get that a is normalizable. O As a consequence we get: Lemma 5.3 Convertibility is decidablefor well-typed terms. Proof By the normalization theorem we know that well-typed terms are normalizable, so to check convertibility we verify that the normal forms are the same. Q 80 C. Coquand 6 Conclusion The results and definitions presented in this paper should be so precise that they can be implemented in a proof-checker. That this is feasible has been shown by Barras (1996). He has developed, in Coq, a correctness proof for a part of the implementation of Coq. In particular he shows strong normalization for a theory without recursive (inductive) types. The model and the proof of normalization can easily be extended to, for example, the , tree- and well-ordering type. We can also add the U-elimination rule to our theory and prove normalization in the same way (Coquand 1996). 7 Acknowledgements I want to thank Thierry Coquand for many discussions and ideas on this subject. Appendix A. For an explanation of these rules, see (Martin-L6f 1972). Appendix B The definition of and . is a simultaneous inductive-recursive definition, see Dybjer (1997); likewise the definition of and A realizability interpretation of Martin-Lof's type theory 81 Bibliography P. Aczel. Frege structures and the notions of proposition, truth and set. In The Kleene Symposium, pages 31-59. North-Holland, 1980. S. Allen. A non-type-theoretic definition of Martin-L6f's types. In Proceedings, Sym- posium on Logic in Computer Science, pages 215-221, Ithaca, New York, 1987. IEEE, Computer Society Press of the IEEE. T. Altenkirch. Constructions, Inductive Types and Strong Normalization. PhD thesis, University of Edinburgh, November, 1993. T. Altenkirch. Proving Strong Normalization of CC by Modifying Realizability Seman- tics. In H. Barendregt and T. Nipkow editors, Proceedings of Types for Proofs and Programs, pages 3-18, LNCS 806, 1994. 82 C. Coquand B. Barras. Coq en Coq. Rapport de Recherche 3026, INRIA, October 1996. C. Coquand. Computation in Type Theory. PhD thesis, Department of Computing Sci- ence, Goteborg University, 1996. T. Coquand. An algorithm for testing conversion in type theory. In Logical Frameworks. Cambridge University Press, 1991. P. Dybjer. A General Formulation of Simultaneous Inductive-Recursive Definitions in Type Theory. Journal of Symbolic Logic. Written 1997. To appear. J. Y. Girard. Une extension de 1'interpretation de Godel a 1'analyse, et son application a ['elimination des coupures dans 1'analyse et la theorie des types. In J. E. Fenstad, edi- tor, Proceedings of the Second Scandinavian Logic Symposium, pages 63-92. North- Holland, 1971. H. Goguen. A Typed Operational Semantics for Type Theory. PhD thesis, University of Edinburgh, 1994. S. C. Kleene. On the interpretation of intuitionistic number theory. Journal of Symbolic Logic, 10:109-124,1945. P. Martin-L6f. A Theory of Types. Technical Report 71-3, University of Stockholm, 1971. P. Martin-Lof. An Intuitionistic Theory of Types: Predicative Part. In H. E. Rose and J. C. Shepherdson, editors, Logic Colloquium 1973, pages 73-118. North-Holland, 1975. P. Martin-Lof. An Intuitionistic Theory of Types. Written 1972. Published in this vol- ume. J. C. Mitchell. A type inference approach to reduction properties and semantics of poly- morphic expressions. In Proceedings ACM Lisp and Functional Programming Conf., pages 308-319,1986. D. Scott. Combinators and Classes. In G. Goos and J. Hartmanis editors, Proceedings of k-Calculus and Computer Science Theory, pages 1-12, LNCS 37, 1975. W. W. Tait. Intensional interpretation of functionals of finite type I. Journal of Symbolic Logic, 32:2:198-212,1967. W. W. Tait. A realizability interpretation of the theory of species. In A. Dold and B. Eck- man, editors, Logic Colloquium 1972-73, volume 453 of Lecture Notes in Mathemat- ics, pages 240-251. Springer-Verlag, 1975. B. Werner. Une Theorie des Constructions Inductives. PhD thesis, Universite Paris, 1994. 6 The groupoid interpretation of type theory Martin Hofmann and Thomas Streicher Fachbereich Mathematik, Technische Hochschule Darmstadt 1 Introduction Many will agree that identity sets are the most intriguing concept of intensional Martin- Lof type theory. For instance, it may appear surprising that their axiomatisation as an inductive family allows one to deduce the usual properties of equality, notably the replacement rule (Leibniz's principle) which gives P(a') from P(a) and a proof that a equals a!. This holds for arbitrary families of sets P, not only those corresponding to a predicate. This is not in conflict with decidability of type checking since if a equals a' and p : P(a) then one does not in general have p : P(a'), but only subst(s, p) : P(a'~) where s is the proof that a equals a' and subst is defined from the eliminator for identity sets. It is a natural question to ask whether these translation functions subst(s, _) actu- ally depend upon the nature of the proof s or, more generally, the question whether any two elements of an identity set are equal. We will call UIP(A) (t/niqueness of Identity Proofs) the following property. If a\\, ai are objects of type A then for any two proofs p and q of the proposition \"GI equals a^' we can prove that p and q are equal. More generally, UIP will stand for UIP(A) for all types A. Note that in traditional logical formalism a principle like UIP cannot even be expressed sensibly as proofs cannot be referred to by terms of the object language and thus are not within the scope of prepo- sitional equality. The question of whether UIP is valid in intensional Martin-L6f type theory was open for a while, though it was commonly believed that UIP is underivable as any attempt for constructing a proof has failed (Coquand 1992; Streicher 1993; Altenkirch 1992). On the other hand, the intuition that a type is determined by its canonical objects might be seen as evidence for the validity of UIP as the identity sets have at most one canonical element corresponding to an instance of reflexivity. Indeed, UIP is derivable in an extension of type theory based on this intuition, namely type theory augmented with pattern matching as implemented in the ALF system (Coquand 1992; Altenkirch etal. 1994). In this paper we answer the question of derivability of UIP in pure type theory in the negative by exhibiting a countermodel. By the above, this model does not vali- date pattern matching thereby providing a proof that the latter is not conservative over traditional type theory. 84 M. Hofmann and T. Stretcher The model we give stands in sharp contrast to the above-mentioned intuition of types being determined by their canonical inhabitants. In the model a type A will consist of a set | A | of objects together with (possibly empty) sets A (a\\, ai) of \"proofs\" that i are propositionally equal. Although a closed term of type A will be modelled as an object of | A | an open term will map not only objects to objects but also equality proofs to equality proofs. Thus, an open term is not fully determined by its behaviour on closed terms. The principle UIP can then be refuted by including a type in which the set A(a\\, 02) has more than one element for some The technical work consists of demonstrating that these mathematical objects can indeed interpret all of Martin-LQf's type theory. It turns out that various additional structure has to be imposed for that purpose. In particular, for each type we need a composition, identities, and inverses; that is to say, functions for all objects a\\, 02, «3 witnessing that propositional equality is an equivalence rela- tion. In order to interpret the various type and term formers certain equations must be imposed on these operations. That is, composition must be an associative operation with neutral element id and with inverses given by In other words, every type will be a groupoid, i.e. a category with isomorphisms only. Open terms and dependent types will then be interpreted as certain functors taking account of the fact that propositional equality is preserved by function application. A posteriori, this justifies a view of propositional equality in type theory as a notion of isomorphism. We exploit this view by exhibiting non-standard axioms for proposi- tional equality on universes which contradict UIP and pattern matching. These axioms are put to use in a new formalisation of basic category theory in type theory in which isomorphic objects are propositionally equal. Independently, Frangois Lamarche (1991) has investigated the logical structure of the category of groupoids with the motivation of finding a logical system in which classes of mathematical structures appear as types. He observed that a theory with type dependency arises as a natural candidate for an internal language of the category of groupoids. He gives interpretations of dependent function spaces and sums which agree essentially with ours. Parts of the material presented in this article have already been published by the authors in 1993, 1994 and 1997. The main purpose of the current version is to make the material accessible to a wider audience and to serve as future reference. As opposed to the extended abstract (Hofmann and Streicher 1994) the model construction is de- scribed here in full detail and also in more elementary terms. Furthermore, the syntactic extensions (functional extensionality and universe extensionality) of pure type theory which have been sketched in Hofmann (1997b) are worked out here in detail. The ap- plication to the formalisation of basic category theory and the analysis of interpretations of universes are altogether new. The groupoid interpretation of type theory 85 1.1 Acknowledgements We are indebted to Thorsten Altenkirch, Thierry Coquand, Peter Dybjer, and Per Martin- Lof for numerous discussions on equality in type theory and to Frangois Lamarche for explanations and discussions about the groupoid model. The diagrams below have been typeset using Paul Taylor's LaTeX package. 2 Syntax We work in Martin-L6f's type theory formulated inside a logical framework as defined in Chapters 19 and 20 of Nordstrom et al. (1990). However, we will use a slightly different notation as will be explained below. This type theory derives judgements of the following forms: (1) A type to mean that A is a type, (2) a : A to mean that a is an object of type A, (3) A = B to mean that types A and B are definitionally equal, (4) a = a' : A to mean that a and a' are definitionally equal objects of type A. All judgements are relative to a list of variable declarations of the form n where the variables are distinct and A, type holds under the assump- tion . . Such lists of assumptions are called contexts and are ranged over by capital Greek letters One writes (alternatively I to indi- cate that judgement J7 holds in context P. In the formal presentation (which we include as an appendix) the valid judgements in context, i.e. under assumptions, are defined inductively; context validity is included as an auxiliary judgement. In the informal pre- sentation below we only indicate the relevant part of a context. If A type and B type under then the dependent function space is a type. If then '. Conversely, if ! and a:A then . This typed abstraction constitutes the main difference to the presentation in Nordstrom et al. (1990). We have ^-equality and also »?-equality provided x is not free in b. Iterated applications of the form are written as where we take the freedom of omitting arguments which can be inferred from later ones. There is a special type Set containing names for certain types, the so-called sets, as objects. Whenever A : Set then we have El(A) type; in particular, we can form the \"generic\" family El(A) type [A:Set]. It is common to omit the El operator, thus writing a:A instead of a:El(A). Nordstrom et al. (1990)writei fora : El(A). We want to reserve the -symbol for membership in the metatheory. 86 M. Hofmann and T. Stretcher The formalism derived so far allows one to introduce set formers and term form- ing operations (be they constructors or eliminators) simply as constants together with their definitional equalities. For example, the intensional identity sets are given by the following constants: In addition, we impose the definitional equality for A, C, d, a of appropriate type. Note that J is called idpeel in Nordstrom et al. (1990). According to our convention on omitting redundant arguments we will usually write Id(a\\, #2) and refl(a) instead of ld(A, a\\, 0.2) and refl(A, a), respectively. In addition to identity sets we also use Fl-sets, S-sets, disjoint union, natural num- bers, empty type, and a universe. See the appendix for their formal definition. Following common practice, we write ' ~ for (x: A)B and as well as , for I if A and B are types or sets. The notion of equality induced by identity sets is called prepositional equality (as opposed to definitional equality). That is to say, two objects a\\, ai : A are proposi- tionally equal if Id(a\\,ai) is inhabited. The main purpose of prepositional equality is that it can be assumed in contexts and thus allows for hypothetical equality reason- ing. In particular, prepositional equality can be established by induction, i.e., using the eliminator R. Definitional equality, on the other hand, can only be established by pure equational reasoning, i.e. it corresponds to the equational theory generated by the postulated equal- ity judgements. Accordingly, definitional equality is (at least in traditional cases) decidable, whereas propositional equality is not, as soon as one includes natural numbers and Fl-sets. By the congruence rules for definitional equality the latter always entails the propo- sitional one, but not necessarily vice versa. 3 Syntactic considerations on identity sets The elimination operator J is motivated by the view of Id(A, _, _) as an inductively defined family with constructor refl. Accordingly, J permits one to define an object of type (QI, a2'.A)(s:Id(A, a\\, ai))C(a\\, ai, s) by prescribing its behaviour for arguments of canonical form, i.e. a\\ = ai = a and s = refl(A, a). In the presence of Fl-sets, this elimination operation J allows one to derive the following replacement rule: subst: The groupoid interpretation of type theory 87 satisfying See Nordstrom et al. (1990) for the definition of subst. From subst one easily derives symmetry and transitivity of prepositional equality as well as congruence with respect to function application: Notice that we supply arguments to trans in the applicative order. We also have the following dependent version of resp: To derive resp' the full power of J is needed; subst alone does not suffice. 3.1 Uniqueness of identity proofs (VIP) For most inductive sets it is possible to show that arbitrary objects are propositionally equal to canonical ones. For example, the following types are inhabited: There are several ways of stating an analogous property for identity sets. We introduce the following abbreviations: Using 7, one can show that UlPJuple is inhabited and that UIP-refl(A) and UIP(A) are equivalent for each A:Set. See Streicher (1993) for the proofs. He also explains that in the presence of UIP the eliminator 7 can be defined in terms of the derived opera- tor subst thereby allowing for a very intuitive axiomatisation of propositional equality 88 M. Hofrnann and T. Stretcher in terms of a uniqueness property of identity proofs and a type-theoretic pendant of Leibniz's principle stating that replacement of equal objects preserves validity. It is known (Coquand 1992) that an object of UIP can be constructed by pattern matching. The main result of this paper consists of an interpretation of type theory in which UIP (Uniqueness of Identity Proofs) is not inhabited. A fortiori, UIP is not derivable and, therefore, pattern matching is not a conservative extension of Martin-L6f type theory. 3.2 Definability of instances of UIP Although UIP is not derivable in general, instances UIP(A) for certain sets A are inhabited. Hedberg (1995) has shown that this is particularly the case if A admits a decidable equality, i.e. the type is inhabited by some object dec. The proof of this is not trivial; roughly speaking the idea is to construct a constant function can A '• ' '\" from dec using D and RQ. One can show using J that any function with the type of can& satisfies a certain naturality condition with respect to substitution of equals for equals. This, together with the groupoid laws spelled out in Proposition 3.1 below, can be used to express p : ld(a\\, a'l) in terms o^can^(a\\, ai, p) from which the result follows as can^(a\\, a-i) is constant. One can also show that UIP is preserved by the set formers £ and disjoint union. It is also preserved by the identity set former itself, provided one further assumes that UIP applied to proofs by reflexivity gives back a proof by reflexivity. Below we will demonstrate that UIP(U(A, B)) follows from UIP(A) and (a:A)UIP(B(a)) under the assumption of an extensionality axiom. This gives UIP for all sets definable without universes. 3.3 Alternatives to UIP Streicher (1993) gives another principle equivalent to UIP which in its formulation does not mention propositional equality of identity proofs: He also introduces an eliminator K for the family Id(A,a, a) [a:A]: satisfying K(d, refl(a)) = d(a). Using K an inhabitant of UIP may be constructed. Both alternatives can be directly defined using pattern matching. It is an open prob- lem whether the converse is also true, i.e. whether pattern matching forms a conservative extension of type theory augmented by K (or a constant of type UIP together with an appropriate conversion rule). The groupoid interpretation of type theory 89 3.4 Groupoid laws for identity sets Although the principle UIP turns out as being non-derivable, certain prepositional equal- ities between objects of identity sets can be established using J. If A : Set and a\\,ai : A and then we write to mean that ) is inhabited. Proposition 3.1 (1) Ifa\\, a-i : A ands : Id(ai, ai) then (2) Ifai, 02,0.3, d4 : A and s\\ : Id(a\\, ai) andsi : Id(ai, 03) ands?, : Id(a^, 04) then (3) If A,B : Set and a\\, ai, 03 : A and f : (a:A)B and s\\^ : Id(a\\,ai) and s^ : ld(ai, 03) then Proof All of these follow straightforwardly using J. As an example we derive where s : Id(A,a\\,ai). We put We have where The object d(a) has the required type C(a, a, refl(A,a)) because both sym(refl(a)) and trans(refl(a), refl(a)) are definitionally equal to refl(a). This in turn follows from the definition of sym and trans in terms of subst. D These prepositional equalities suggest that one can view a set as a category having as objects the objects of A and in which a morphism from a\\ to ai is an object of Id(A, a\\, U2), or rather an equivalence class of such objects by prepositional equality. 90 M. Hofmann and T. Stretcher Composition is then given by transitivity and reflexivity gives the identities. Symmetry, on the other hand, establishes that every such morphism is actually an isomorphism. A category in which every morphism is an isomorphism is called a groupoid. So the identity sets endow every set with a groupoid structure in a natural way. Furthermore, the equations under 3.1(3) establish that a function / from A to B extends to a functor from A to B with morphism part given by resp(f, _). Under this view the principle UIP translates into the statement that every such groupoid is in fact a trivial one with at most one morphism between any two objects. This suggests that a refutation of the principle UIP can be obtained by way of an inter- pretation of type theory in which types are interpreted as arbitrary groupoids, provided one succeeds in ascribing appropriate meaning to the type and set formers. We will do exactly this in the following section. 4 The groupoid interpretation Our metalanguage for the construction of the interpretation is informal set theory aug- mented with Grothendieck universes or inaccessible cardinals. We use set theory merely for convenience; all our definitions can also be carried out in extensional Martin-L6f type theory with universes which shows that our constructions do not depend upon the consistency of large cardinals. We assume some basic knowledge of category the- ory, notably the concepts of category, functor, and natural transformation, see MacLane (1971). 4.1 Groupoids A groupoid 1 is a category P where all morphisms are isomorphisms. The groupoids together with functors between them form a (large) category GPD. 4.1.1 Examples The products and exponentials of groupoids qua categories are groupoids again so that GPD is cartesian closed. Recall that the objects of are pairs __ where and and that the objects of are functors from F to A. For every set X the discrete category A(X) with only identities as morphisms is a groupoid—the discrete groupoid over X. If . we write * rather than idx for the A(X)-morphism from x to x. Note that we have iff x = y. We remark that A{{)) is a terminal object in GPD denoted by []. More generally, a groupoid will be called discrete if all its morphisms are identities. Note that up to isomorphism discrete groupoids are of the form A(X). Every group G can be viewed as a one-object groupoid in the obvious way. Non-dependent types will be interpreted as groupoids, their closed terms as objects of groupoids. The role of the morphisms in a groupoid is to give meaning to prepo- sitional equality. Composition of these morphisms accounts for transitivity, identity corresponds to reflexivity, and the inverses to symmetry. 1 In universal algebra the term groupoid is sometimes used for a set with a binary operation. Our use of the term groupoid is in accordance with that in category theory and homotopy theory, cf. Brown (1988). The groupoid interpretation of type theory 91 Open terms are interpreted as functors between groupoids where the morphism part witnesses the preservation of prepositional equality. 4.1.2 Notation We notationally identify a groupoid with its underlying set of objects thereby writing to mean that y is an object of F. We write p~ l for the inverse of morphism p. 4.2 Families of groupoids To obtain a fully fledged interpretation of type theory we need to account for type de- pendency; that is, we have to define a notion of a family of groupoids indexed over a groupoid. This notion should be such that the usual type formers can receive appropriate meaning and in particular such that the homset F(—, —) arises as a family of groupoids indexed over F x F thus providing meaning for the identity types. Fortunately, category theory provides us with such a notion of dependency. A family of groupoids indexed over groupoid F is a functor Note that such a functor yields a groupoid A(y) for each , _ and, moreover, a functor ) whenever This will serve as an interpretation of replacement and more generally of identity elimination. The fact that A itself is a functor ensures that the functors A(p) are compatible with the groupoid structure of F. In particular, we have . i and , ; thus all the functors A(p) are actually isomorphisms of groupoids. 4.2.1 Notation If md then we write ) for the functor A (p). We write 7y(F) for the collection of families of groupoids indexed over F. When is a morphism in GPD and t then the composition A o / is an element of 7>>(A). We use the notation A{/} for this family. In this way Ty extends to a contravariant \"collection-valued\" functor on GPD. 4.2.2 Example If F is a groupoid then a family of groupoids 7p indexed over F x F is defined by and where and This family 7p will be the interpretation of the family of identity set when F is the interpretation of a closed type. Below, we will generalise / r to families of groupoids. 4.3 Objects of families Let A 6 7y(F) be a family of groupoids over F. A (dependent) object M of A consists of the following data: (1) an A(y)-object M(y) for each (2) for each morphism in '-morphism !\\ such that 92 M. Hofmann and T. Stretcher and Apart from the \"adjustment\" p' • _ in the second equation required to make the right- hand side typecheck these laws express functoriality of M. After having defined the semantic counterpart of context formation we will be able to identify dependent objects as corresponding to certain functors. We write Tm(A) for the collection of dependent objects of A. For functor / : A —>• F the operation extends to dependent objects. If A e 7y(T) and ) then is given by composing the components of a with / in the obvious way. 4.4 Category-theoretic semantics Our plan is to organise groupoids and families of groupoids into a model of dependent type theory, namely a category with families (CwF). This notion of model was invented by Dybjer (1996), and subsequently used by Martin-L6f, e.g. in his talk at this congress. Our reference for CwFs is the survey article by Hofmann (1997a). Let us review here that a CwF consists of the following data: (1) A category C of contexts and substitutions with terminal object [] corresponding to the empty context. (2) A collection-valued functor associating with each context F the collection of types depending on it. If ^ ' and i one writes for The type A{f] corresponds to the substitution of / into A. (3) For each nd i a collection of terms together with a substitution function 1 ) functorial in / : A ->• F in the obvious sense. We abbreviate j ,_ (4) For each a so-called context extension V.A which has the property that the homset ( ) and and are isomorphic naturally in A. (5) Operations corresponding to the desired type, set, and term formers. We have already defined the category of contexts, namely GPD, and the collections Ty and Tm together with the required substitution operations. 4.5 Context extension If A e 7y(F) is a family of groupoids the context extension F.A is the total category of the co-fibration obtained by applying the Grothendieck construction to A. In more explicit terms the groupoid V.A takes the following form. The objects of F. A are pairs where and . A morphismin F.A from (y, a) to (y', a') is a pair (p, q) where ~ ' \" and The composition of I > and is defined as . The identity at (y,a) is (idy, ida). The inverse of is i . The verifications The groupoid interpretation of type theory 93 are left to the reader. More details on this construction can be found in Barr and Wells (1990). The projection sending (y, a) to y and (p, q) to p is a morphism of groupoids from F.A to F. It is called the canonical projection associated to A and is denoted by Pxi : r.A ->- T. In order that F.A indeed captures context extension we need a bijective correspon- dence between the set and the homset GP£>(A, F.A). Given and. we define by To obtain an inverse we first define a semantic analogue of the sequent as follows. A dependent object is given by Note that, Now, if h : A -> F.A then we have It is routine that these data establish the required bijective correspondence natural in A. We have now established that groupoids and families of groupoids form an instance ofaCwF. 4.6 Dependent function space To each dependent object i we can associate a functor A by and We have . Conversely, given a section •, then we have )) and f(p) — (p, M(p)) for a uniquely determined This correspondence enables us to view Tm(A) (for not merely as a set, but as a groupoid. A morphism T from term M to term N is an assignment of an A(y)-morphism such that the family is a natural transformation from M to N, i.e. for every p : y —> y' the following diagram commutes: 94 M. Hofrnann and T. Stretcher Now suppose that. and We wish to define a family ) ) together with additional structure to interpret application and abstraction. In or- der to avoid lengthy and rather unreadable calculations we will only give the definitions and leave the verifications to the reader. If ; be the family of groupoids over the groupoid A(y) given by Note that where A is the functor sending a to i and Now we put considered as a groupoid If i and i then ) is given by If ) and is a natural transformation then , p • M' is defined by i for 4.6.1 Abstraction and application Suppose that We define it s abstraction ) o n objects by If ' then we need a natural transformation At object it is given by Conversely, if \"\" ~ ' ~ \" we define a dependent object Its object part is given by For the morphism part assume and . We define The groupoid interpretation of type theory 95 We claim that as required. To see this, first note that because ( . On the other hand thus as The claim follows by Note that we can define the application of as Rather than defining an object of a family we will often define an object of B instead. This will be referred to as \"definition by currying\". 4.7 The universe of sets Let V be a universe in the metalanguage which is closed under dependent function space, dependent sum, and inductive definitions. If our metalanguage is chosen to be axiomatic set theory such a universe may be chosen either as a Grothendieck universe (MacLane 1971) or as VK for K a strongly inaccessible cardinal (Luo 1994). If we use extensional Martin-L6f type theory as a metalanguage then V will be a type-theoretic universe with the required closure properties. A groupoid F is called V-small, or small for short, if both its collection of objects and its homsets lie in V. Let us write Gpd for the groupoid which has as objects the small groupoids and only isomorphisms of groupoids as morphisms. The (non-full) inclusion from Gpd to GPD defines a family The groupoid Gpd together with its associated family El serves as the interpretation of the type Set and its associated \"invisible\" El operator. Note that, if A : F -> Gpd then El{A} is actually equal to A. Therefore, it is appropriate to introduce the notation Se(F) for the homset GPD(T, Gpd) where 4.8 Interpretation of the syntax The structure exhibited so far is sufficient to interpret the logical framework, i.e. the dependent function spaces and the universe Set. This means that we have a unique compositional assignment which maps (1) a well-formed contexts F to a groupoid (2) a type , to a family of groupoids (3) an object i ] to a dependent object in such a way that derivable equality judgements are validated. More explicitly, this means that (1) whenever is derivable, as 96 M. Hofmann and T. Stretcher (2) whenever Compositionality means that the universe Set is interpreted as GPD and that dependent function spaces, abstraction, and application are interpreted by \\ and semantic abstraction and application. This implies in particular that if A : Set [T] then the interpretation lies in In order to extend this interpretation to a hierarchically 2 structured equational theory such as, in particular, Martin-L6f set theory, we have to assign to each constant of type A an element of in such a way that the required definitional equalities are validated. In defining these semantic constants we will use type-theoretic syntax to denote semantic entities, thereby omitting semantic brackets. 4.9 Dependent function spaces and sums Since the dependent function space of a small family of groupoids over a small groupoid is again small, we immediately obtain an interpretation of El-sets. To interpret E-sets we need an element By currying, this amounts to defining a small family over the groupoid We will use T as a black box and only use the fact that its two components arise as small families , and by projection. We have to define a small family be defined as in section 4.6. The family is now defined as follows: In order to give meaning to pairing and elimination it is sufficient, albeit not necessary, to exhibit an isomorphism between r.E(A , B) and Y.A.B. But these two groupoids are identical up to restructuring of parentheses. That is to say, the isomorphism sends (y, a, b) to (y, (a, b)) and vice versa, and similarly for morphisms. 4.10 Identity sets Before embarking on the precise definition of identity sets we motivate the main idea by assuming that the ambient context is empty. So let A be a groupoid. The interpre- tation of Id(A) arises as the family as defined in 4.2.2. Recall that and ,_. . . _, • Reflexivity is interpreted as the dependent object which sends i then Therefore, reft is indeed a dependent object of the family IA(U, a) [a: A]. 2The type of a constant may depend on previously declared constants. The groupoid interpretation of type theory 97 For identity elimination let C be a family over the groupoid The groupoid has as objects triples (a\\, a^, s) where , -morphism from (0.1,02, s) to (<3p Oj,.?') amounts to a pair (91,^2) where #,- : a; —»• a( with Note that, therefore, & is (isomorphic to) the arrow category A~*. In order to interpret J(A, C) one has to provide a uniform way of extending an object d of (a: A)C(a, a, refl(a)) to a dependent object J(A, C, d) of C such that The key to the interpretation of J(A, C) is the observation that for any object (a\\, 02, s) we have because commutes. Therefore, we can put The morphism part of J is defined analogously. For those familiar with fibrations we remark that the extension J(A, C, d) depends crucially on the morphism part of C, i.e. on the choice of a splitting of C when viewed as a fibration of groupoids. Therefore, it is unlikely that it can be characterised by a universal property. 4.10.1 The identity set former To interpret identity sets in full generality we need an element By currying this amounts to defining a small family over the groupoid [A:Set, a\\:A, a2'-A}. This groupoid has as objects triples (A,a\\,ai) where A is a small groupoid and a\\, aj, are objects of A. A morphism from (A, a\\, 02) to (A',a\\, a'^) is a triple (p, q\\, q2) where p : A -> A' is an isomorphism of groupoids, i.e. p e Gpd(A, A'), 98 M. Hofmann and T. Stretcher and , in A'. Note that El(p)(ai) = p(ai), thus permitting us to write also p(x) instead of p • x. The family Id over is now given by where p : A -> A' and i and 4.10.2 Reftexivity We define a dependent object Again, by currying this amounts to giving a dependent object of the family Iddiag := Id(A,a) [A:&/,a:A] (over the groupoid [A:Set,a:A]). Let us make the involved groupoids explicit. The groupoid [A:Set, a:A] has as objects pairs (A, a) where A is a small groupoid and A morphism from (A, a) to (A', a') is a pair (p, q) where and i. Furthermore, we have, and if then The object part of refl is now given by Now since Id^iag is discrete the definition of the morphism part of refl, reduces to check- ing that This in turn is immediate by functoriality of p and the fact that q~ l is an inverse of q. 4.10.3 Identity elimination We seek a global element of the following groupoid: By currying this amounts to defining a dependent object where and A, C, d refer to the respective components of P. Note that we have , a family i, and a dependent object d of The groupoid interpretation of type theory 99 The object part of J is given as follows. Let u = (y, a\\,ai, s) be an object of Put Note that as ( Now recall that i, so we are led to define We now come to the morphism part. Let u = (y, a\\, ai, s) and I be objects of and let In other words, ind < ' and c ' or equivalently (4.1) We have to define a morphism . . We claim that has the required property. To see this, first observe that I and therefore (4.2) as . Note that Applying the operation f(u') • _ to (4.2) and using functoriality yields Now we calculate as follows: ai = ida> So and therefore ) as required. The verification of the functor laws for J is tedious but straight- forward. =by Equation (4.1) 100 M. Hofmann and T. Stretcher Notice that for all and < we have Therefore and whenever This establishes the validity of the definitional equality required for J. 4.11 Other set formers The natural numbers are given as the discrete groupoid over the set of natural numbers. We omit the definition of the associated operations. The disjoint union set A + B is interpreted as the co-product of groupoids, which is constructed as the disjoint union of the underlying sets of objects and morphisms. In a similar way, we can interpret lists, trees, unit set, empty set, and other data types. 4.12 Universes Let V be a metatheoretic universe contained in V. We write Gpd(V) for the groupoid of V-small groupoids with isomorphisms as morphisms. Provided V has appropriate metatheoretic closure properties the groupoid Gpd(V) can serve as the interpretation of a universe closed under the usual set forming opera- tions. We call a metatheoretic universe V impredicative, if it is closed under impredicative universal quantification, i.e. for ' and the dependent function space n as/ifi(a ) is in V. Of course, non-trivial instances of such V are possible only in an intuitionistic metatheory such as an extensional variant of Luo's ECC (1994) whose consistency is established by various realisability models. If V is impredicative (and has the usual closure properties) then Gpd(V) is closed under impredicative quantification as well. That is to say, if and B : A -> Gpd(V) then ). This is immediate from the definition of depen- dent function spaces in the groupoid model. For subsequent applications it is useful to have universes of small discrete groupoids available. We write Gpd&(V) for the groupoid consisting of V-small discrete groupoids with isomorphisms (or rather bijections) as morphisms, owing to the fact that discrete groupoids are closed under all set forming operations and so will be a universe of the form Gpd&(V). Moreover, since identity sets (even of non-discrete groupoids) are dis- crete, the family of groupoids Id(A) lives in Gpd&(V) provided the groupoid A has V-small homsets. Of particular interest is the situation where V is impredicative and Set is confined to groupoids with V-small homsets. Owing to the impredicativity of V this interpretation The groupoid interpretation of type theory 101 of Set is still closed under dependent function space as well as the remaining set form- ing operations. Now, Gpd(V) and Gpd&(V) are impredicativeuniverses (still contained in Set) which, moreover, contain all identity sets. We thus obtain an interpretation of a version of impredicative higher-order logic (a la Church (1940)) in which preposi- tional equality is proof relevant, but equivalent propositions are not necessarily equal. Isomorphic ones, however, are equal. Note that since universes of the above form are not discrete they cannot be contained in a universe of the form Gpd&(V). Nevertheless, if V is a metatheoretic universe contained in V then Gpd&(V) contains the discrete groupoid consisting of V'-small groupoids. Universes obtained in this way are still closed under all set formers, but do not contain identity sets of non-discrete groupoids. We have not checked whether these universes can be sufficiently narrowed down so as to validate universe elimination, cf. Chapter 14 of Nordstrom et al. (1990), but we do not see any principal obstacle. Our investigations have shown that the above building blocks can be used to con- struct groupoid interpretations of every combination of universes considered in the lit- erature, in particular for the type theories in Barendregt's \"lambda cube\" (1992). 5 Applications and extension In this section we will exploit the benefits of the model construction carried out. We derive the promised independence results and investigate some extensions validated by the groupoid model, in particular a set of axioms expressing that equality on certain universes is an isomorphism. These extensions are put to use in a new type-theoretic formalisation of basic category theory in which isomorphic objects are propositionally equal. 5.1 Independence of UIP Since for a groupoid A the identity set Id(A, a\\,ai) is interpreted as A(A(ai, a^}) it will contain more than one object if there is more than one A-morphism from a\\ to 0.2- Owing to discreteness of identity sets these objects are then not even propositionally equal as propositional and definitional equality coincide for discrete groupoids. More formally, we have the following theorem. Theorem 5.1 The type UIP is empty. Proof Suppose that u e Tm(UIP). Let A be the (additive) group Za viewed as a one-object groupoid. That is to say, we have a single object * 6 A and two distinct morphisms 0, 1 e A(*, *) where 1 o p = 0 and 0 is the identity. Then u(A, *, *, 1,0) would be an element of Id(Id(A, *, *), 1,0). However, the latter set is empty as 1 ^ 0 and identity sets are discrete. D By soundness of the interpretation the following is now immediate. Corollary 5.2 There is no syntactically definable closed term of type UIP. 102 M. Hofmann and T. Stretcher 5.1.1 Non-definability of K As UIP can be proved using the eliminator K for the family Id(A,a,a) [a:A] as given in section 3.3 it follows that the latter cannot be interpreted in the groupoid model. It is, however, instructive to see directly why an attempt of interpreting K in the same way as / fails. Let A be a groupoid and < and . In order to construct a dependent object of C extending d in the same way as we did in the case of J we would have to come up with a morphism in from for arbitrary_ . .. ... Now such a morphism would amount to a morphism c i satisfying; But this implies So no such morphism exists if , ). More generally, for the particular case where A is as in the proof of Theorem 5.1 there is an object of type ( whereas Tm(C) is empty, thus showing that K cannot be defined by other means either. 5.1.2 Non-definability of congjsnd Finally, let us look at the congruence property cong-snd. If A is a groupoid and B e Se(A) and a : A and b, b': B(a) then whereas So the two groupoids are different and one can easily construct a situation in which the first one is inhabited and the second one is empty (e.g. let A be Z2 and fi(*) = &({b, b'}) and 1 • b = b'). 5.2 Canonicity of identity types Unlike ri-sets with ^-equality or extensional identity sets, the intensional identity sets are not defined by a universal property. Therefore, it is natural to ask how interpretations of identity sets in the groupoid model look in general. To answer this question, assume for the moment that we enrich our type theory by another set former Id' : (A:Set)A -» A —> Set together with appropriately typed constants re/I' and J' satisfying the corresponding definitional equalities. Then using J and / ' one can exhibit terms in such a way that, moreover, the following two types are inhabited: It follows that UIP holds with respect to Id' if and only if it holds w.r.t. Id because the property of having at most one element is stable under prepositional isomorphism. It The groupoid interpretation of type theory 103 follows that no interpretation of identity sets satisfying UIP is possible in the groupoid model, and thus in particular extensional identity sets cannot be interpreted. A more refined analysis shows that i and j establish an equivalence in the category- theoretic sense and therefore any possible interpretation of the identity set Id( A ,a\\, a-i) must be a posetal groupoid whose connected components are in a one-to-one correspon- dence with A (a i, ai). 5.3 Functional extensionality Despite the intensional character of the groupoid model propositional equality on func- tion spaces is pointwise in the sense that the following type is inhabited in the model: To see this, let F denote the groupoid and i denote the family i Let '. The groupoid Id(f, g)(y) is the discrete groupoid with objects the natu- ral transformations in the sense of section 4.6. More precisely, an object of Id(f, g)(y) is an assignment T mapping objects c \\ to )-morphisms g(Y)(a) such that whenever q : a —> a! then the following diagram commutes: Now let M be an object of PE(y). By definition of dependent function space M(a) is a morphism from f(y)(a) to g(y)(a) for every a e A(y). Furthermore, if q : a —> a' then (5.1) where • refers to the identity set i. By discreteness of identity sets (5.1) means that (id, q) • M(a) and M(a'} are actually equal. Now, by definition of reindexing for identity sets the left-hand side (id, q) • M(a) equals 104 M. Hofmann and T. Stretcher where this time • refers to the morphism part of reindexing in B. By \"multiplying\" both sides with f(q) from the right, we obtain the following diagram: This means that the objects of Id(f, g)(y) and PE(y) are the same! Being a dependent function space of a discrete family, PE is itself discrete. So Id(f, g)(y) and PE(y) are isomorphic. One can also show that this isomorphism is natural in y thus establishing an isomorphism between the families PE and Id(f, g). A more refined analysis shows that one direction of this isomorphism arises as the interpretation of the following proof that equal functions are pointwise equal: This allows us to interpret the following extension of Martin-Lb'f's type theory: The special case of fun-ext-axl where ^ is an instance of reflexivity was proposed by Turner (1989) as a possible axiomatisation of functional extensionality. It is easy to see that this special case is equivalent to the general fun^extjaxl using J. Apparently, fun~extMx2 is independent of fun-extMxl (and Turner's axiom). Note that our two axioms determine the postulated object fun,ext uniquely up to prepositional equality. Obviously, the axioms fun.extjaxl/2 are derivable from VIP. An application of functional extensionality is that it allows one to derive UIP (n(A, B)) from (a:A)UIP(B(a)). Assuming fun^ext alone does not seem to suffice for that purpose. Note that functional extensionality allows us to express an identity set of the form Id(Yl (A, B)) in terms of identity sets of the form Id(B(a)). A similar decomposition is The groupoid interpretation of type theory 105 possible for E-sets without any extension of the syntax. Indeed, using E-elimination we can establish a canonical isomorphism between and See Streicher (1993) for a formal proof. Analogously, we can decompose identity sets at disjoint unions and natural num- bers. 5.4 Universe extensionality In this section we want to make an extension of type theory taking account of the fact that propositional equality on a universe is an isomorphism. To make this more precise we need some notation. We write Iso(A, B) for the set where composition (o) and identities (id) are defined as usual in terms of abstraction and application. If h : Iso(A, B) we abbreviate its first component by h and its second component by Conversely, if and it is clear from the context that / has an inverse in the sense of propositional equality then we may write Now let U be a universe of discrete groupoids, i.e. of the form Gpd&(V). It is then clear that if A, B : U then the interpretations of Iso(A, B) and Id(U, A, B) are isomorphic. One direction of the isomorphism is syntactically definable as Note that Iso(A, fi) and Id(A, B) are not isomorphic if U is Gpd(V) rather than Gpd&(V) because then Iso(A, B) is in one-to-one correspondence with equivalences between A and B. Thus Iso(A, B) may be inhabited even if A and B are not isomor- phic. As in the case of functional extensionality we can now syntactically postulate an inverse to the function idJso: By analogy to functional extensionality we refer to this extension as universe extension- ality. We remark that universe extensionality is inconsistent with UIP(U) if U contains the natural numbers. This is so because the set Iso(N, N) contains two different definable elements / and g. UIP together with the above constants would identify / and g and therefore two different natural numbers. 106 M. Hofmann and T. Stretcher 5.5 A new formalisatioii of category theory An application of the above extension is as a new formalisation of category theory where isomorphic objects are propositionally equal. Let U be a universe of discrete groupoids. We capture this axiomatically by assuming a constant of type (A:U)UIP(A). A category with isomorphism as equality then consists of the following data: (1) a set Ob : Set of objects, (2) a family of sets Mor : Ob —> Ob —> U of morphisms, (3) objects id and comp of the obvious types corresponding to identity and composi- tion, (4) proofs of the traditional axioms stated in terms of propositional equality, (5) a proof that for each A, B: Ob the sets Id( Ob, A, B) and!so(A, B) are canonically isomorphic. This definition deserves some explanation. The set Iso(A, B) for A, B:Ob is denned analogously to Iso for members of a universe. More precisely, Iso(A, B) is This set being \"canonically isomorphic\" to Id(A, B) means that the canonical (and de- finable) function is bijective. The fact that the homsets Mor(A, B) are discrete enables us to do without further axioms qualifying the behaviour of the assumed proofs of the category equations. In other words, there is only one reason for morphisms to be equal. If we want to consider the collections of categories as objects of Set then we have to restrict Ob to be a member of a certain (not necessarily discrete) universe. Of course, this formalisation of categories does not per se require universe exten- sionality, it just is not very useful without it, as then U itself (with function spaces as morphisms) would not fall under the definition. However, using universe extension- ality we do obtain a category with isomorphism as equality by putting Ob = U and Mor This formalisation of categories can be used to obtain a new proof and a generali- sation of P. Freyd's (1976) result stating that a property of categories expressed in the first-order language of categories with equality on morphisms (but not on objects) as the predicate symbol is stable under equivalence of categories. Define a small category to be a category in the above sense where in addition Ob : U. We can now define a type CAT of small categories using E-sets. One can now show that every small category C in the usual set-theoretic sense gives rise to an element r C n of the interpretation of CAT in the groupoid model. Moreover, two categories C and D are equivalent iff (the inter- pretation in the groupoid model of) is inhabited. Now, since every The groupoid interpretation of type theory 107 first-order property of categories can be expressed in Martin-L6f type theory such prop- erties are preserved under propositional equality using subst and thus under equivalence of categories. This argument extends to all properties formalisable in the language of Martin-L6f type theory, in particular those which involve propositional equality of ob- jects. This is possible simply because propositional equality of objects corresponds to isomorphism from an external point of view. External set-theoretic equality of objects cannot even be expressed. Functor categories. Using functional extensionality in an essential way, we can show that categories with isomorphism as equality are closed under formation of functor categories. The crucial point here is to establish a one-to-one correspondence be- tween natural isomorphisms between functors F and G (between categories C and D) and proofs that F and G are equal. This is achieved by decomposing the set Id(FUNC(C, D), F, G) according to the rules set out at the end of section 5.3. Here the set of functors FUNC(C, D) is defined as usual by grouping together the object and morphism part as an object of a I!-set. The components of a natural isomorphism now correspond to a proof that the object parts of F and G are pointwise equal, and thus equal by functional extensionality. The naturality condition, on the other hand, corresponds to the proof that the two morphism parts are propositionally equal. The details are messy, but have been machine checked using a proof assistant (LEGO). Note that UIP(FUNC(C, £>)) is not valid as there is in general more than one natural isomorphism between any two functors. This implies that categories and functors do not form a category with equality as isomorphism since its homsets are not discrete. Of course, categories and functors can still be organised into a category in the traditional sense. However, it might be interesting to view equivalent categories as propositionally equal. This, however, would require \"2-level groupoids\" in which we have morphisms between morphisms and accordingly the identity sets are not necessarily discrete. We do not know whether such structures (or even infinite-level generalisations thereof) can be sensibly organised into a model of type theory. 6 Syntax of type theory 6.1 General rules In rule COMPR x is a fresh variable. Rules expressing that definitional equality is a congruence relation with respect to all subsequent type and term forming operations. 6.2 Rules for the logical framework We henceforth omit the ^/-operator and use the conventions on abstraction, application, and omission of redundant arguments set out in section 2. We abbreviate (x:A)B by A -> Bif x does not occur in B. 6.3 Martin-L6f's set theory Martin-Lof's set theory is defined as an extension of the logical framework by the following constants and definitional equations understood in every valid context. The definitional equalities hold under the proviso that their components are well-typed. 6.4 n-sets Alternatively, we can replace app by the so-called funsplit operator (Nordstrom et al. 1990). Then the second ^-like equality only holds propositionally. We take the liberty of writing /(a ) for app(f, a). 108 M. Hofmann and T. StretcherThe groupoid interpretation of type theory 109 6.5 S-sets When A, B : Set then we abbreviate by A x B. We also write (a, b) for pair(a, b). 6.6 Identity sets 6.7 Natural numbers, disjoint unions, and empty set 6.8 Universes A universe U in Set is defined by two constants U : Set and T : U —*• Set. Closure properties of the universe under certain type and term formers are expressed by reintroducing them with Set replaced by U. If the desired type former is available for Set as well then it suffices to reintroduce the type former for U and relate it to the 110 M. Hofmann and T. Stretcher corresponding type former on the level of Set by an appropriate equality axiom for T. The associated term formers can then be inherited from Set. For example, closure under impredicative universal quantification is defined by If we have Fl-sets then : and c together with their equations can be replaced by the single set equation Bibliography Altenkirch, T. (1992). An open question concerning inductive equality. E-mail message to the Edinburgh LEGO club. Altenkirch, T., V. Gaspes, B. Nordstrom, and B. von Sydow (1994). A User's Guide to ALF. Sweden: Chalmers University of Technology. Available under ftp ://ftp .cs .Chalmers. se/pub/users/alti/alf .ps .Z. Barendregt, H. P. (1992). Lambda calculi with types. In S. Abramsky, D. M. Gabbay, and T. S. E. Maibaum (Eds), Handbook of Logic in Computer Science, Volume 2, pp. 118-309. Clarendon Press. Barr, M. and C. Wells (1990). Category Theory for Computing Science. International Series in Computer Science. Prentice Hall. Brown, R. (1988). Topology. Ellis Horwood. Church, A. (1940). A formulation of the simple theory of types. Journal of Symbolic Logic 5, 56-68. Coquand, T. (1992). Pattern matching with dependent types. In Workshop on Logical Frameworks, Bastad. Preliminary Proceedings. Dybjer, P. (1996). Internal type theory. In Proc. BRA TYPES workshop, Torino, June 1995 Springer LNCS 1158. Freyd, P. (1976). Properties invariant within equivalence types of categories. In Algebra, topology, and category theory (a collection of papers in honor of Samuel Eilenberg). Academic Press, New York. Hedberg, M. (1995). Uniqueness and internal decidability in type theory. Manuscript, Chalmers University, Gothenburg. Hofmann, M. (1993). A model of intensional Martin-L6f type theory in which unicity of identity proofs does not hold. Unpublished note, available on e-mail request. Hofmann, M. (1997a). Syntax and semantics of dependent types. In A. M. Pitts and P. Dybjer (Eds), Semantics and Logics of Computation, Publications of the Newton Institute, pp. 79-130. Cambridge University Press. The groupoid interpretation of type theory 111 Hofmann, M. (1997b). Extensional Constructs in Intensional Type Theory. CPHC/BCS Distinguished Dissertations. Springer 1997. Hofmann, M. and T. Streicher (1994). A groupoid model refutes uniqueness of identity proofs. In Proceedings of the 9th Symposium on Logic in Computer Science (LICS), Paris. Lamarche, F. (1991). A Proposal about Foundations I. Manuscript. Luo, Z. (1994). Computation and Reasoning. Oxford University Press. MacLane, S. (1971). Categories for the Working Mathematician. Springer. Martin-L6f, Per (1995). Tarskian semantics for type theory. Talk given at this congress, Nordstrom, B., K. Petersson, and J. M. Smith (1990). Programming in Martin-Lof's Type Theory, An Introduction. Clarendon Press, Oxford. Streicher, T. (1993). Semantical Investigations into Intensional Type Theory. Habilita- tionsschrift, LMU Miinchen. Turner, D. (1989). A new formulation of constructive type theory. In P. Dybjer (Ed.), Proceedings of the Workshop on Programming Logic, pp. 258-294. Programming Methodology Group, University of Goteborg. This page intentionally left blank 7 Analytic program derivation in type theory Petri Maenpaa Department of Philosophy, University of Helsinki 1 Introduction and historical background This work proposes a new method of deriving programs from their specifications in constructive type theory: the method of analysis-synthesis. It is new as a mathematical method only in the area of programming methodology, as it is modelled upon the most successful and widespread method in the history of exact sciences. The method of analysis-synthesis, also known as the method of analysis, was de- vised by Ancient Greek mathematicians for solving geometric construction problems with ruler and compass. Its most important subsequent elaboration is Descartes's alge- braic method of analysis, which pervades all exact sciences today. The present work expands this method further into one that aims at systematizing program derivation in a heuristically useful way, analogously to the way Descartes's method systematized the solution of geometric and arithmetical problems. To illustrate the method, we derive the Boyer-Moore algorithm for finding an element that has a majority of occurrences in a given list. It turns out that solving programming problems need not be too different from solv- ing mathematical problems in general. This point of view has been emphasized in particular by Martin-L6f (1982) and Dijkstra (1986). The idea of a logic of problem solving originates in Kolmogorov (1932). We aim to refine the analogy between pro- gramming and mathematical problem solving by investigating the mathematical method of analysis in the context of programming. The central idea of the analytic method, in modern terms, is to analyze the functional dependencies between the constituents of a geometric configuration. The aim is to determine how the sought constituents depend on the given ones. A Greek analysis starts by drawing a diagram with the sought constructions drawn on the given ones, in the relation required by the problem specification. Then the sought constituents of the configuration are determined in terms of the given ones. Analysis was the Greeks' method of discovering solutions to problems. Their method of justification was synthesis, which cast analysis into standard deductive form. First it constructed the sought objects from the given ones, and then demonstrated that they relate as required to the given ones. In his Geometry, Descartes developed Greek geometric analysis-synthesis into the modern algebraic method of analysis. He formalized the specified relation between 114 P Maenpaa the given and sought constructions in terms of the language of algebraic equations that he introduced. Then he transformed these equations into a normal form, such as a quadratic equation, which could be solved directly. See Maenpaa (1993, 1997) for further historical information. Let us now turn to programming by analysis. We employ constructive type theory, as developed by Martin-L6f (1984) (from now on: type theory), as our formalism for program derivation. It serves as a programming language as well as a logical language (Martin-L6f 1982). This discovery has made it one of the main approaches to the foun- dations of computing science and to program derivation (Nordstrom et al. 1990). We aim to show here how the use of type theory instead of Descartes's language of algebraic equations allows the method of analysis-synthesis to be generalized so that it applies to programming problems. This requires the capacity to analyze and synthe- size mathematical constructions of any type. The problem-solving power of algebraic analysis is uncontestable and unsurpassed, so we use it as a prototype and attempt to generalize it in a way that preserves its desirable heuristic properties. Cartesian algebra is a good prototype for programming methodology also in the sense that it is really a formalism for problem solving, modulo logical and set-theoretical operators for specifying problems, and variable abstraction for binding together prob- lems and solutions into composite ones. Type theory provides these enhancements in a uniform setting. We also want to show how solving programming problems is methodologically like problem solving in any other field of mathematics that employs the analytic method, and benefits from being treated as one. Programming just requires greater formality, with explicit formal notation for constructs that Cartesian algebraic notation lacks. This is because programs should be executable on a machine, and also because machine- assisted derivations of programs are desirable at least in applications where correctness is vital. In principle, it should of course be vital in all applications, if programming is regarded as an exact science. We would like to argue that programming is essentially mathematics in a sufficiently formal setting, with concerns of computational efficiency made prominent. The present work develops further the methodology and treatment of the majority problem presented in Maenpaa (1993). This earlier treatment cast the derivation of Backhouse et al. (1989) into analytic-synthetic form. They derived in type theory the Boyer-Moore (1991) majority algorithm, invented in 1980, and first published by Misra and Gries (1982), along with a generalization. We chose this example because it is a standard one in program derivation. Also Mohring (1986) studied it in the calculus of constructions on the basis of an earlier formulation of Backhouse in type theory. She had implemented it in 1986 as early implementation of the calculus of constructions. After the presentation of the present derivation in the Venice meeting of October 1995, she redid her derivation in the new implementation Coq V5.10 of the calculus of constructions, making effective use of the new possibility of defining constructions inductively. Thanks to the new, powerful features of Coq, her machine-assisted formal derivation is decisively shorter than ours. Our derivation has been completely formalized in the ALF proof editor (Altenkirch Analytic program derivation in type theory 115 et al. 1994) for type theory. We do not present our program derivation in complete formal detail, but instead on the level of formality of algebraic analysis. Ideally, a proof editor should be able to provide the rest of the details automatically. We suggest that this level of formality is just right for carrying out derivations and presenting them to others. 2 Algebraic analysis Let us now consider the prototype of formal analysis-synthesis, Cartesian algebraic analysis. We are all familiar with it, so it serves well to illustrate the method. Consider the elementary problem for reals, assuming we know the standard solution to a quadratic equation. A mathematical problem has the type-theoretical form where a : A are the given objects, x : B(a) are the sought objects, and C(a,x) is the condition that relates them. The present problem has the following parts: given sought condition i The solution by analysis starts with a transformation. First, substitute the fresh variable z for ax 2 in the condition. This reduces the condition to the equivalent one Then transform this further into the equivalent condition We have now hit upon the transformed condition, because this equation can be solved by the known solution to a quadratic equation. Then comes the second part of analysis, resolution. It first applies the known solu- tion to a quadratic equation, which yields the value There is a condition of solvability for z, a diorism in Greek terms, 116 PMaenpaa The second step of resolution determines x in -terms of z as by means of the known solution for x in terms of z from the equation z = ax 2 : R corresponding to the substitution. Any value of x is a solution if a = c = 0 : R. Here, too, we have diorisms, This algebraic example illustrates the heuristically crucial features of analysis: per- forming the transformation before the resolution, and finding the right auxiliary con- structions. Auxiliary constructions are introduced by substitution. We substituted the fresh variable z for the expression ax 2 in order to find a solution for x in terms of a, b, and c. The auxiliary constructions enable us to see the condition in a normal form, which has a known solution, or in a form to which previously proved propositions apply in order to proceed towards a normal form. Any mathematical problem can be regarded as a programming problem by taking the given objects to be the inputs of the program and the sought objects its outputs. Thus the analytic solution to our algebraic example problem gives rise to the synthesis of the program f(a, b, c, h(a, b, c)) whose definition is the value derived for x in terms of z. The value derived for z is synthesized as the auxiliary program h(a, b, c). That is, auxiliary constructions are auxiliary programs in programming terms. Although this simple algebraic problem is not typical of a programming problem in the sense that its solution is not a recursive function, it illustrates well the analytic method in program derivation and the way auxiliary programs are introduced. Besides, many standard programming problems are defined in algebraic terms, for instance divi- sion and maximum segment sum. 3 Type-theoretical form of analysis-synthesis As the Greeks conceived it, analysis served as a method of finding a solution to a prob- lem by reducing it to ones whose solutions are known. Synthesis served to justify the analysis by casting it into ordinary deductive form. More specifically, the first part of synthesis, construction, deduced the sought constructions from the given ones. The second part, demonstration, showed that the given and sought constructions satisfy the condition of the problem, by deducing the condition from the transformed condition found in transformation. From Descartes on, synthesis has not been presented with solutions to mathematical problems derived by analysis. Analysis has been regarded as sufficient justification of the solution in itself. When analysis-synthesis is applied to programming problems, on the other hand, synthesis is useful, because it serves to put together the parts of a program determined Analytic program derivation in type theory 117 in the analyses of the various subproblems that arise from the decomposition of the original problem. In particular, steps of induction break up a problem into subproblems, corresponding to the base and step cases of the inductions. We discern the following type-theoretical form of an analysis-synthesis. Analysis Synthesis Transformation Resolution Construction Demonstration Analysis starts with a reductive transformation of the condition C(a, x) to a trans- formed condition T(a,x,z), which manifests a directly constructible functional de- pendency of the sought object x : B(d) on the given object a : A. Then resolution determines x i n terms o f a . Th e symbol | stands for deduction, an d t for reduction. If a step of transformation is a deduction at the same time as a reduction, we use the equivalence symbol $. Synthesis proceeds conversely to analysis by first constructing the sought object from the given, and then deducing the condition from the transformed condition. Analysis introduces the auxiliary constructions z : G(a) by substituting g(a, x) for them reductively in the transformation. (Here a, x, z, h(a) and g(a, x) denote vectors of objects.) The original configuration, which consists of x dependent on a, is thereby amplified by z that may depend on both x and a. Resolution determines z in terms of a alone. This is why the type of z must not depend on x, in contrast to the expression g(a, x) substituted reductively for z in trans- formation. Analysis uncovers the functional dependencies z = h(a) : G(a) and x = f(a,z) = f(a,h(a)) : B(a) that are then constructed in synthesis. The determination of x in terms of z and a in resolution must respect the equation z = g(a,x) : G(a) that corresponds to the substitutions in transformation. Intuitively, auxiliary constructions are constructions that are constituents of neither the given nor the sought constructions, but are needed in order to construct the latter from the former. The type-theoretical rule of substitution accounts for the introduction of auxiliary constructions in formal terms. It can also been seen as a cut rule in sequent calculus terms. Cut is usually considered to operate on the level of propositions rather than individuals. But the present type-theoretical rule 118 PMdenpOa accounts for individuals as well as propositions: to prove a proposition C, we have to find an individual u : C. To aid this, the cut rule can be used reductively to introduce the auxiliary construction z : A. The insight required in introducing an auxiliary construction is to see C in the form of a substitution instance B(a/z), to which a known proposition applies. This applica- tion transforms C into another condition. In the algebraic example, C is an equation on which we perform reductive substitution. The premisses of the cut rule generate the subgoals b : B, which may depend on z : A, and a : A. In terms of our scheme for analysis-synthesis, the former premise is for transforming the condition further, and the latter premise is for determining in resolution the auxiliary constructions, intro- duced in transformation, in terms of the given constructions alone. Then we may put u = b(a/z) '• C, where C is the same proposition as B(a/z). For instance, the algebraic example introduces z by substituting ax 2 reductively for it. This expression depends on the given object a as well as the sought object x. Yet resolution determines z in terms of the given objects alone. Then it determines x in terms of the given objects and z, respecting the equation z = ax 2 : R corresponding to the substitution. Finding the right auxiliary constructions is the key to finding a solution, as the al- gebraic example illustrates. Analysis aids this systematically, because it allows treating sought constructions on a par with given ones. Thus one may carry out auxiliary con- structions based on both sought and given objects. Synthesis does not allow this, so auxiliary constructions are primarily an analytic tool. Our formal scheme allows substituting new variables z reductively by constructions g(a, x) that can depend on x as well as a. Analysis allows making maximal use of the problem specification. Synthesis, in contrast, allows only constructions that depend on the given objects so that systematic use can be made of neither sought objects nor their specified relation to given objects. This explains the heuristic usefulness of analysis as a method of solving problems, as compared with synthesis. To make full use of the problem-solving power of analysis, one should perform transformation prior to resolution. This gives the analyst systematic access to the in- formation provided by the condition of the problem. Transformation serves to indicate how resolution should proceed, by determining a sought construction in terms a given one. Resolution is usually easy after that. In terms of proof editors, those without 'metavariables', also known as 'existential variables', are not capable of transformation before resolution. Sought objects must be represented as existential variables in transformation, because the point is that they are not yet determined there. An alternative methodology is to perform resolution before transformation. It is far less powerful than the other way around, as one can easily see by trying to solve our algebraic problem thus. One would first have to introduce the sought for object, out of the blue, without making use of the system of equations that specifies the condition of the problem, and only then verify that the found object satisfies the equations in relation to the given objects. Analytic program derivation in type theory 119 4 Generalization of analysis-synthesis to inductively denned configurations If a configuration u : (3* : B(a))C(a,x), where a : A, is defined inductively, the method of analysis-synthesis needs to be generalized in the following way. This is because the scheme above applies only to the base cases of inductions as it stands. First, analyze the configuration into base and step cases according to the induction rule for the given object that the induction is performed on. Let us call the configurations of the base cases base configurations and the configurations of the step cases inductive configurations with predecessor configurations specified by the respective induction hypotheses. Second, analyze the base configurations according to the scheme of the previous section. Third, analyze the inductive configurations, making use of the respective induction hypotheses. Resolution is to determine each sought inductive configuration in terms of its predecessor configuration, given by the induction hypothesis. Instead of trying to capture this method of analyzing an inductively defined configu- ration into a general scheme, we illustrate it for a paradigmatic case, lists. Our example of program derivation uses them, along with natural numbers. We use the notations [] for constructing the empty list and a.m. for constructing a list from an element a and a list m. An inductively defined list configuration has the form for A : set and / : List(A). The base configuration is analyzed in the form Transformation Resolution The step case analyzes the inductive configuration in terms of its predecessor configuration h : (Bx : B(m))C(m,x), 120 PMaenpaa where a : Aandm : List(A). The analysis has the form Transformation Resolution Here h is the induction hypothesis. An important special case of this scheme is when the transformed condition is the condition of the induction hypothesis, i.e. T(a.m,x,z) = C(m, x) for lists. This occurs repeatedly in our program derivation example. Then the condition of the induction hypothesis has the role of a normal form to which the transformation aims, like a quadratic equation, say, in Cartesian algebraic analysis. We use a modern notion of synthesis in program derivation. This is why we do not need synthesis in the original sense of our schemes. Analysis suffices as a logic of discovery and justification on its own. Synthesis is used to extract the computational content of a type-theoretical proof and generate the corresponding program code. The next section uses such synthesis in an informal way. For a complete, formal account, see the companion work (Maenpaa 1996). 5 Analytic-synthetic program derivation Consider the Boyer-Moore solution to the majority problem. Informally, the problem is to find an element that has a majority of occurrences in a list or to determine that the list contains no such element. Cast in type-theoretical terms, the problem is Classical mathematics regards this specification as trivial, because it is an instance of the law of the excluded middle. But in the constructive setting of solving program- ming problems, a program that meets this specification does not actually exist unless it is constructed. This form of specification is indeed quite common for programming problems. It is not of the general form of a problem, but it reduces to that form as follows. The solution strategy is first to generate a possible majority element, i.e. an element such that if it does not have majority in the given list, then no element does. Second, the possible majority element is tested for actual majority simply by counting its occur- rences in the list. If there are more occurrences than half the length of the list, then the possible majority element is also an actual majority element; otherwise no element has majority. The majority problem thus reduces to generating a possible majority element, which is then tested for actual majority. This test can be specified as Analytic program derivation in type theory 121 The solution is not difficult and is left to the reader. Finding a possible majority element has the required general form of a problem. It has methodological interest, because it does not lend itself to direct solution by induction on the structure of the given list. The resulting induction hypothesis would be too weak. We are not able to determine the possible majority element of a list a.m on the basis of knowing that of the list m. This illustrates one of the main heuristic features of analyzing an inductively de- fined configuration: discovering which constituents to eliminate from a configuration in order to specify the predecessor configuration. To do this, one has to invent a suitable induction hypothesis. If it is too weak, the analysis does not succeed, and if it is too strong, the resulting solution is not efficient enough from the computational point of view. From the purely mathematical point of view, an induction hypothesis that is too strong is not a concern to worry about. In programming, an induction hypothesis is strengthened by adding information in the form of new variables. This generalizes the problem, which may make it easier to solve. There is no mechanical way to do this—genuine creativity may be needed. Let us carry out an initial exploration of the problem with a view to generalizing it. The analysis of the base case, where / is the empty list, is Transformation Resolution Here the condition is itself the transformed condition, and the trivial solution is x = c : A, where c is some constant value. In the step case / is a.k. Let us try to add information to the induction hypothesis by carrying out another induction, now on the list k. The base case, where k is the empty list, is again trivial. Transformation Resolution In the step case k is b.m. It can be treated in two cases, according to whether a = b or a =£ b, and assuming that equality on A is decidable. Consider the analysis of the case a ^ b first. Transformation Resolution 122 PMaenpda There are two induction hypotheses h and h', corresponding to the two inductions. Observe that x is the only element that can have majority in a.b.m, provided that it is the only element that can have majority in m, and that a is distinct from b. The trans- formation uses this as a lemma, whose proof can be found in Backhouse et al. (1989). The transformed condition is the same as the condition of the induction hypothesis h, so x can be determined as p(h). Now consider the analysis of the case a = b. Transformation Resolution PMaj(a.b.m,x) $ {Leibniz} PMaj(a.a.m, x) $ {form exponent} PMaj(a 2.m, x) t (21 n) PMn)(a n.m,x) Here a\".m stands for the list consisting of n consecutive occurrences of the element a concatenated to the list m, formally rec(«, m, (b, h)a.h). At the stage of transformation PMaj(a 2.m, x) we notice that the desired stronger induction hypothesis can be obtained by substituting the constant exponent 2 by a vari- able n. The succession of inductions manifests a recurrent pattern. Each induction yields a new element, which either can be removed together with the previous element of the list by applying the lemma, or increments by one the exponent n of the condi- tion PMaj(a\".m, x). Thus we introduce the auxiliary construction z, which generalizes the problem so that the increasing exponents can be solved. The transformation does not display z, because it is not substituted into the conditions. Nevertheless, it occurs in the proof object of the transformed condition. The other auxiliary construction n is determined trivially in resolution, because it is substituted by the constant 2. The resolution determines the sought object x in terms of the auxiliary construction z, but leaves the latter undetermined. Hence the notation z = ?. Determining z from m requires a separate analysis. This is in contrast to our algebraic example, where the auxiliary construction was simple enough to be determined directly in the main analysis. We have thus discovered the auxiliary construction which generalizes the original problem (3* : A)PMaj(/, *) (I : List(A)). The anal- yses of our initial exploration, which led us to discover z, can clearly be discarded because z(c, 0) solves the original problem directly. Nevertheless, the actual derivation makes essential use of their main ideas. It now remains to solve the generalized problem by determining z. Let us rename the given list m as / and start again with an induction on /. In the base case of the Analytic program derivation in type theory 123 analysis / is the empty list. Transformation Resolution PMaj(<z\".[],x) The step case is an analysis where / is b.m. It is solved by an induction on n. Here the base case, where n is 0, is solved by the analysis Transformation Resolution VMaj $ PMaj *PMaj To solve the step case of the induction on n, where n is k + 1, we carry out a case analysis on a = b v a jt b, as in the initial exploration. Considering the case a = b first, we carry out the analysis Transformation Resolution PMaj $ {Leibniz} PMaj $ PMaj( Now there is one more case left for the entire majority problem, namely the one for a ^= b. The corresponding subproblem is the same as in the previous case, of course, and its analysis runs as follows. Transformation Resolution PMaj < $ {split exponent} PMaj( $ {permute} PMaj i t {lemma} PMaj( This completes the analysis. Completing the analytic-synthetic program derivation requires a synthesis of the program from its constituents, which were determined in the analyses of the subproblems. Synthesizing programs from proofs does not belong within the scope of the present work, but the reader is referred to Paulin-Mohring (1989) and Paulin-Mohring and Werner (1993) for a treatment in the calculus of constructions and to (Maenpaa 1996) for one in type theory. 124 PMaenpaa Returning to the original majority problem, the functional ML program that solves it isfun maj (/} = testjna j (pmaj (/),/ ) where fun pmaj (/) = pmaj_aux (/, c, 0) . Here c is some constant of type A, testjna j tests for majority, pmaj is the pro- gram that finds a possible majority element, and pma j _aux is the auxiliary construction that solves the generalized problem. fun pmaj _aux ( [ ] , a, n) = a | pmaj.au x (b : :m,a, 0) = pmaj_aux(m,b, 1) | pmaj_aux(b: :m,a,n) = if a = b then pmaj_aux(m,a, n + 1) else pmaj_aux(/n, a,«-l ) For simplicity, n ranges over ML's built-in integers instead of natural numbers. The structure of the synthesized program follows the structure of the derivation: the first line corresponds to the base case of the list induction; the rest to its step case; the second line to the base case of the induction on natural numbers; and the rest to its step case. This synthesis carries out informally the program extraction of taking the left pro- jection p of the pair form solution to every subproblem of the form which we identified for mathematical problems in general. In decomposing the original problem into subproblems, we always resorted to this form. We regard the element of B(a) as computational, but the proof of C(a, x) as logical and thus delete it in synthe- sis. The if-then-els e structure in the synthesized program results from the case analysis in the derivation on a = b v a ^ b. The decision procedure employed here yields the boolean-valued equality function on integers in the ML program. In sum, the heuristically crucial parts of the solution were reducing the original problem to the more general one by means of an auxiliary construction, and performing transformations of subproblems before resolutions. The rest was quite straightforward. No auxiliary constructions were needed that depend on the given and sought objects, but our algebraic example illustrates them clearly enough. Recall that mathematical prob- lems do not differ formally from programming problems. Further research is needed to discern the role of such auxiliary constructions in derivations of standard programs. 6 Conclusion We are now in a position to see how the method of analysis-synthesis aids solving programming problems. It systematizes the solution process in a manner analogous to Cartesian algebraic analysis, but accounting also for inductively defined configurations. The transformation of an analysis reduces the condition of a problem systematically to a normal form. Inductive configurations are reduced to their predecessor configurations. Furthermore, type theory allows problems and their solutions to be expressed uni- formly in the same language, just like Descartes's algebraic analysis. The analyst can Analytic program derivation in type theory 125 make systematic use of this uniformity. Traditional methods of deriving programs in imperative languages, where the pro- gramming and specification languages are distinct, do not meet Cartesian standards in this respect. Neither do imperative languages meet Cartesian standards in respect of formality of transformation, which is a powerful calculational technique for systematic reduction of the condition of a problem into a normal form. Recent developments in proof editors for type theory, e.g. ALF, have sought to make programming in type theory not too different from ordinary programming. They provide facilities such as case expressions and the definition of programs by pattern equations, as in ordinary functional programming languages. The motivation of the present work has been to make programming in type theory not too different from ordinary mathematical problem solving. The case analyses of program derivations, like the one on a = b v a ^fri n our example, are readily expressed in ALF by case expressions, and the analysis of an in- ductively defined configuration into base and step cases by pattern equations. The resolution of an analysis is directly expressible by pattern equations, but the calculational transformation of the condition of a problem is beyond natural expression in ALF. Thus the present method gives rise to a proposal to extend the facilities of ALF and related systems with one for the natural expression of the transformation of an analysis. At present, transformation must be expressed with pattern equations like resolution, which makes it difficult for the user to perceive a transformation clearly and distinctly as a whole. The analyst would benefit from the possibility of inspecting the whole chain of conditions in a transformation at the same time, as in standard Cartesian algebraic practice. Then the deductive links between them and hence the unifying idea of the transformation would appear more readily. As our examples manifest, and as already recognized by Greek mathematicians and Descartes, transformation is clearly the more challenging part of analysis. Mathematics does not seem to contain fields where problem specification and so- lution languages are distinct—Cartesian uniform algebraic language pervades. Indeed, Descartes's algebraic analysis deserves a significant position in the history of logic in view of introducing a systematic method and uniform formal language for mathemat- ical problems and their solutions, with symbols for given and sought objects. Its lack of logical operators should not obscure this fact. It is the first proper mathematical problem-solving formalism. Type theory can be seen as its descendant, extended with logical and set-theoretical operators and lambda abstraction. Bibliography Altenkirch, T., Gaspes, V., Nordstrom, B. and von Sydow, B. (1994). A user's guide to ALF. Available electronically at www.cs.chalmers.se/ComputingScience/Research/Logic/alf/guide.html. Backhouse, R., Chisholm, P., Malcolm, G. and Saaman, E. (1989). Do-it-yourself type theory. Formal Aspects of Computing, 1, 19-84. 126 PMaenpaa Boyer, R. and Moore, J. (1991). MJRTY— a fast majority vote algorithm. Pp. 105- 117 in R. Boyer (ed.), Automated Reasoning: Essays in Honour of Woody Bledsoe. Kluwer, Dordrecht. Descartes, R. (1954). Geometry. English translation by D. Smith and M. Latham with a facsimile of the 1st edition (1637). Dover, New York. Dijkstra, E. (1986). On a cultural gap. Mathematical Intelligencer, 8, 48-52. Kolmogorov, A. (1932). Zur Deutung der intuitionistischen Logik. Mathematische Zeitschrift, 35, 58-65. Maenpaa, P. (1993). The Art of Analysis. Logic and History of Problem Solving. PhD thesis, University of Helsinki. Maenpaa, P. (1996). Program synthesis in type theory. Talk given at the Seventh Scan- dinavian Logic Symposium, Uppsala, August 1996. Maenpaa, P. (1997). From backward reduction to configurational analysis. In M. Otte and M. Panza (eds), Analysis and Synthesis in Mathematics. History and Philosophy. Kluwer, Dordrecht. Martin-Lof, P. (1982). Constructive Mathematics and Computer Programming. Pp. 153-175 in L. Cohen et al. (eds), Proceedings of Logic, Methodology and Phi- losophy of Science VI, Hannover 1979. North-Holland, Amsterdam. Martin-Lof, P. (1984). Intuitionistic Type Theory. Bibliopolis, Naples. Misra, J. and Gries. D. (1982). Finding repeated elements. Science of Computer Pro- gramming, 2, 143-152. Mohring, C. (1986). Algorithm development in the calculus of constructions. Pp. 84-91 in Proceedings of Logic in Computer Science '86. Nordstrom, P., Petersson, K. and Smith, J. (1990). Programming in Martin-Lof's Type Theory—An Introduction. Oxford University Press, Oxford. Paulin-Mohring, C. (1989). Extracting F^'s programs from proofs in the calculus of constructions. Pp. 89-104 in Sixteenth Annual ACM Symposium on Principles of Programming Languages, Austin, January 1989. Paulin-Mohring, C. and Werner, B. (1993). Synthesis of ML programs in the system Coq. Journal of Symbolic Computation, 15, 607-640. 8 An intuitionistic theory of types Per Martin-Lof Department of Mathematics, University of Stockholm The theory of types with which we shall be concerned is intended to be a full scale sys- tem for formalizing intuitionistic mathematics as developed, for example, in the book by Bishop 1967. The language of the theory is richer than the language of first order predi- cate logic. This makes it possible to strengthen the axioms for existence and disjunction. In the case of existence, the possibility of strengthening the usual elimination rule seems first to have been indicated by Howard 1969, whose proposed axioms are special cases of the existential elimination rule of the present theory. Furthermore, there is a reflec- tion principle which links the generation of objects and types and plays somewhat the same role for the present theory as does the replacement axiom for Zermelo-Fraenkel set theory. An earlier, not yet conclusive, attempt at formulating a theory of this kind was made by Scott 1970. Also related, although less closely, are the type and logic free theories of constructions of Kreisel 1962 and 1965 and Goodman 1970. In its first version, the present theory was based on the strongly impredicative axiom that there is a type of all types whatsoever, which is at the same time a type and an object of that type. This axiom had to be abandoned, however, after it was shown to lead to a contradiction by Jean Yves Girard. I am very grateful to him for showing me his paradox. The change that it necessitated is so drastic that my theory no longer contains intuitionistic simple type theory as it originally did. Instead, its proof theoretic strength should be close to that of predicative analysis. 1. INFORMAL EXPLANATIONS OF THE BASIC CONCEPTS. 1.1. Mathematical objects and their types. We shall think of mathematical objects or constructions. Every mathematical object is of a certain kind or type. Better, a mathematical object is always given together with its type, that is, it is not just an object, it is an object of a certain type. This may be regarded as a simpler and at the same time more general formulation of Russell's 1903 doctrine of types, according to which a type is the range of significance of a prepositional function, because in the theory that I am about to describe every prepositional function will indeed have a type as its 128 P. Martin-Lof domain. A type is defined by prescribing what we have to do in order to construct an object of that type. This is almost verbatim the definition of the notion of set given by Bishop 1967. Put differently, a type is well defined if we understand (or grasp to use a word favoured by Kreisel 1970) what it means to be an object of that type. Thus, for instance, N —> N is a type not because we know particular number theoretic functions like the primitive recursive ones but because we think we understand the notion of number theoretic function in general. Note that it is required neither that we should be able to generate somehow all objects of a given type nor that we should so to say know them all individually. It is only a question of understanding what it means to be an arbitrary object of the type in question. I shall use the notation to express that a is an object of type A. 1.2. Propositions and proofs. A proposition is defined by prescribing how we are allowed to prove it. For example 971 is a non prime number is the proposition which we prove by exhibiting two natural numbers greater than one and a computation which shows that their product equals 971. In the present context, however, it will not be necessary to introduce the notion of proposition as a separate notion because we can represent each proposition by a certain type, namely, the type of proofs of that proposition. That the proofs of a proposition must form a type is inherent already in the intuitionistic explanations of the logical operations when taken together with the doctrine of types. For example, the intuitionistic notion of implication is explained by saying that a proof of A D B is a function which to an arbitrary proof of A assigns a proof of B. And, if every function is to have a type as its domain, this requires that the proofs of the proposition A must form a type. To avoid an unwieldy mode of expression and notation, I shall sometimes simply identify a proposition with the type that represents it. When a type A represents a proposition, may be read alternatively a is a proof of the proposition A. On the formal level, the analogy between formulae and types was discovered by Curry and Feys 1958 and further extended by Howard 1969 to whom I am indebted for explaining it to me. In what follows, I shall make use of it in much the same way as Scott 1970. An intuitionistic theory of types 129 1.3. Cartesian product of a family of types. Suppose now that A is a type and that B is a function, rule or method which to an arbitrary object a of type A assigns a type B(a). Then the cartesian product is a type, namely the type of functions which take an arbitrary object a of type A into an object of type B(a). Clearly, we may apply an object b of type (Hx € A)B(x) to an object of type A, thereby getting an object b(a) of type B(a). The notation b(a\\,... ,a n) will be preferred to b(a\\)... (an). When B(a) represents a proposition for every object a of type A, i represents the universal proposition A proof of is a function which to an arbitrary object a of type A assigns a proof of 6(a). Functions may be introduced by explicit definition. That is, if we, starting from a variable x that denotes an arbitrary object of type A, build up a term b[x] that denotes an object of type B(x), then we may define a function denoted of type by means of the schema Here b[a] denotes the result of substituting the object a of type A for the variable x in the term b [x]. If B(a) is defined to be one and the same type B for every object a of type A, then ) will be abbreviated It is the type of functions from A to B. Parentheses are associated to the right so that abbreviates , . When A and B both represent propositions, represents the implication A proof of, is a function which takes an arbitrary proof of A into a proof of B. 1.4. Disjoint union of a family of types. Given a type A and a function B which to an object a of type A assigns a type B(a), we may form the disjoint union which is the type of pairs (a, b) where a and b are objects of type A and B(a), respec- tively. When B(a) represents a proposition for every object a of type , i represents the existential proposition (3^6A)B(x) 130 P. Martin-Lof which we prove by exhibiting a pair (a, b) where a is an object of type A and b a proof of the proposition B(a). Let C be a function which to an arbitrary object of type assigns a type. Given a function d of type we may then introduce a function of type whose value for the argument c will be denoted E(c, d) by the schema In particular, we can introduce the left and right projections p and q of types and , respectively, by putting A third function of > is to represent the type of all objects a of type A such that B(a), because, from the intuitionistic point of view, to give an object a of type A such that B(a) is to give a together with a proof b of the proposition B(a). This interpretation of the notion of such that is implicitly used by Bishop 1967 and discussed by Kreisel 1968. However, its explicit formulation requires us to consider proofs as mathematical objects. For example, the type R of real numbers is defined as Thus, a real number is a pair (a, b) where a is a sequence of rational numbers and b is a proof that a satisfies the Cauchy condition. An example which shows the necessity of treating proofs as mathematical objects is afforded by the inverse function which is not of type R -^ R but of type ( r^ _ ,' ~ ~;, because the definition of the inverse c\" 1 of a non zero real number c de- pends effectively on the proof that c ^ 0. A similar phenomenon occurs in the intuition- istic theory of ordinals of the second number class (see Brouwer 1918) where the sub- traction function is not of type but of type , because the definition of the difference b — a of two ordinals a and b depends effectively on the proof that In the special case when B(a) is defined to be one and the same type B for every object a of type , is abbreviated It is the cartesian product of the two types A and B. If A and B both represent propo- sitions, then A x B represents their conjunction An intuitionistic theory of types 131 1.5. Disjoint union of two types. If A and B are types, so is the disjoint union which is the type of objects of the form i (a) with a of type A or / (£>) with b of type B. Here i and j denote the canonical injections. When A and B both represent proposi- tions, A + B represents their disjunction Let C be a function which to an arbitrary object of type A + B assigns a type, and suppose that d and e are functions of types > and i , respectively. Then we may define a function of type i ) whose value for the argument c will be denoted D(c, d, e) by the schema 1.6. Finite types. For each non-negative integer n we introduce a type Nn with precisely the n objects 1, 2,...,« . Actually, it would suffice to introduce NQ and N\\ because, for n greater than one, we can define Nn to be the union of N\\ with itself n times. If C is a function which to an arbitrary object of type Nn assigns a type and ci,.. . , cn are objects of types C(l),.. . , C(«), respectively, then we may define a function of type whose value for the argument c will be denoted R n(c, c\\,..., cn) by the schema In particular, NQ is the empty type which also represents the logical constant/a/se/zood -L, and the function ' \" of type is the empty function. Similarly, the one element type N\\ is used to represent the logical constant truth T. 1.7. Natural numbers. N is a type, namely, the type of natural numbers. 0 is an object of type N and, if n is an object of type N, so is its successor s(n). These are the first two Peano axioms. Let C be a function which to an arbitrary natural number assigns a type. Then, given an object d of type C(0) and a function e of type j, we may introduce a function of type whose value for the argument n will be denoted R(n, d, e) by the recursion schema 132 P. Martin-Lof If C(n) represents a proposition for every natural number n, then (Xx)R(x, d, e) is the proof of the universal proposition > which we get by applying the principle of mathematical induction to the proof d of C(0) and the proof e of i » The type N is just the prime example of a type introduced by an ordinary induc- tive definition. However, it seems preferable to treat this special case rather than to give the necessarily much more complicated general formulation which would include and N as special cases. See Martin-Lof 1971 for a general formulation of inductive definitions in the language of first order predicate logic. 1.8. Reflection principle. The abstractions described so far still do not allow us to define enough types and type valued functions. For example, we want to be able to define equality between natural numbers by the schema i which will give us in particular the third and fourth Peano axioms. This can clearly be done by recursion if only the propositions alias types J_ and T were objects of some type V. Also, we want to be able to define transfinite types like i where Again, this offers no difficulty if only there were a type V such that N is an object of type V and A -> B is an object of type V as soon as A and B are objects of type V. Guided by these heuristic considerations, we introduce a type V which will be called a universe and whose objects are to be types, together with the reflection principle which roughly speaking says that whatever we are used to doing with types can be done inside the universe V. More precisely, this means that V is closed under the following inductive clauses. NO, N\\, .. . and N are objects of type V. If A and B are objects of type V, then so is A + B. If A is an object of type V and B is a function which to an arbitrary object of type A assigns an object of type V, then and are objects of type V. Note, however, that the reflection principle does not justify the axiom that V is an object of type V which Girard 1972 has shown to be contradictory, because then V would so to say have to have been there already before we introduced it. It is not natural although possible to add the principle of (transfinite) induction over V, expressing the idea that V is the least type which is closed with respect to the above inductive clauses, because we want to keep our universe V open so as to be free to throw new types into it or require it to be closed with respect to new type forming operations. For example, we may want to introduce the type O of ordinals of the second number class or the operation which to a type A assigns the type W(A) of well founded trees over A (see Tait 1968, Scott 1970 and Howard 1969). An intuitionistic theory of types 133 Borrowing terminology from category theory, a type which is an object of V is said to be small whereas V itself and all types which are derived from it are large. Thus the universe V is the type of small types. With this distinction between small and large, the present theory, despite its limited proof theoretical strength, is adequate for the formulation of the basic notions and constructions of category theory. However, it does not legitimatize the construction of the category of all categories whatsoever which in view of Girard's paradox seems highly dubious. The use of the reflection principle in the present theory, on the one hand, to over- come the unnatural limitation to finite types and, on the other hand, to make possible the formalization of category theory should be compared to the use of the quite different reflection principle in the equally different language of set theory for the same purposes. The idea of using the set theoretical reflection principle for the formalization of category theory is due to Kreisel 1965 and has been elaborated by Feferman 1969. 1.9. Girard's paradox. Suppose that we think of V not as the type of small types but as the type of all types whatsoever. Then, being a type, namely, the type of types, V is itself an object of type V, in short, and a type is the same as an object of type V. The following paradox which is a modifi- cation of the one discovered by Girard 1972 (which, in turn, resembles the Burali-Forti paradox) shows that the idea of the type of all types whatsoever is inconsistent. Define an ordering without infinite descending chains (Girard 1972 introduces in- stead what he calls torsion free orderings) to be a type A together with a binary relation < on A such that the propositions and which express that < is transitive and free from infinite descending chains, both hold. Note that an ordering without descending chains is necessarily irreflexive, because, if then is an infinite descending chain and we get a contradiction. Remembering the representation of propositions as types and the interpretation of the notion of such that, is the type of all orderings without infinite descending chains. On U we define a binary relation by putting 134 P. Martin-Lof that is, one ordering of the kind that we are considering is defined to be less than another if there exists an order preserving map from the first to the second and an element of the second ordering which dominates the range of this map. The ordering is transitive. Suppose namely that that is, that there are order preserving maps and and elements b e B and c e C that dominate their respective ranges. Then the composition of / and g is an order preserving map from A to C whose range is dominated by c so that We have now constructed a proof ') • The ordering <{/ has no infinite descending chains. Suppose namely that and let /„ be the order preserving function that maps An+\\ into A n and a n the object of type A n that dominates its range. Then so that we get an infinite descending chain in AQ contrary to the assumption that i is an ordering without such chains. We have now constructed a proof From i and I we can conclude The next step is to show that this is a maximal element of U with respect to the ordering that is, that for all To this end, we let / be the function which takes an object a of type A into the segment of A determined by a, that is, where, remembering the interpretation of such that, An intuitionistic theory of types 135 <fl is the restriction of < to A and pa and qa are the obvious proofs that is transitive and free from infinite descending chains. We have to show that / is order preserving and that its range has a dominating element. Suppose Then because the injection of A a in to A/, is order preserving and its range is dominated by the pair of type A\\, which consists of a and the proof of As the element of type U which is to dominate the range of / we can take itself. Indeed, if a is an arbitrary object of type A, then because the injection of A a into A is order preserving and its range is dominated by a. We have now shown that (U, <u, pu, qu) is a maximal element of U with respect to the ordering <y . But (U, <u, Pu, qu) is itself an object of type U and hence This, however, is impossible, because we have shown <{/ to be an ordering without infinite descending chains and, as remarked above, such an ordering is necessarily ir- reflexive. 2. FORMALIZATION OF AN INTUITIONISTIC THEORY OF TYPES. 2.1. Notational conventions. There is no need to give a list of all the formal sym- bols. Suffice it to say that it should contain all the symbols that are used in the following except the square brackets which will be reserved for the substitution operation. Thus, b[x] denotes an expression in which there may be some free occurrences of the variable x, and b[a] denotes the result of substituting the expression a for all free occurrences of the variable x in b[x]. Free and bound variables are defined by stipulating that all free occurrences of x in b[x] become bound in and, similarly, that all free occurrences of x in B[x] become bound in and By a simultaneous induction, we shall generate certain symbolic expressions called types and, for every type, certain other expressions called the terms of that type. The rules of type and term formation are such that, when the formal symbols are given their abstract interpretation as described in the previous section, it becomes clear that a type A denotes an abstract type and that a term a of type A denotes an abstract object of the type denoted by A. I shall use the notation a 6 A to express that a is a term of type A. There will be variables each of which has a unique type associated with it, and a term or type will always depend on a certain finite number of variables. The notion of dependence is defined inductively by stipulating that a term or type depends on all its free variables as well as on all variables on which the types of its free variables depend. Consequently, a term or type is closed if and only if it depends on no variables at all. There will be variable restrictions prohibiting us to bind a variable in a term or type if 136 P. Martin-Lof there is a free variable in the said term or type whose type depends on the variable in question. These variable restrictions contain as special cases those stated by Gentzen for his system of natural deduction for first order logic. To avoid explicit mention of the variable restrictions, it will be tacitly assumed that a term which is denoted by contains no free variable distinct from whose type depends on x m , m = 1,... , n. The same notational convention will be used for types. Thus, for instance, when saying that b[x] is a term of type B[x], it is tacitly assumed that there is no free variable in b[x] or B[x] whose type depends on x. 2.2. Types. 2.2.1. If P is an «-ary type constant with arguments of types AI, ... , A n [x\\,..., and ai,.. . ,a n are terms of types/. . ,'..' . ~. respectively, then P(a\\,..., an~) is a type. Here, for m = 1,... , n, the variable xm is of the type which must not depend on any other variables than the explicitly exhibited x\\, ...,x m -\\. The type constants correspond to the predicate constants in ordinary first order predicate logic. 2.2.2. If x is a variable of type A and B[x] is a type, then is a type. When B does not contain x free, is abbreviated A —> B. 2.2.3. If x is a variable of type A and B[x] is a type, then ' | is a type. When B does not contain x free, is abbreviated A x B. 2.2.4. If A and B are types, then A + B is a type. 2.2.5. V is a type. 2.2.6. A term of type V is a small type. This is the clause which links the generation of the types with the generation of the terms. A type which is not small is large. Thus, for instance, V is a large type. A type is large if and only if it contains an occurrence of V or a type constant P, and hence it can be mechanically decided whether a type is small or large. 2.3. Terms. Each rule of term formation will be classified a la Gentzen 1934 as an introduction or elimination rule associated with one of the basic types or type forming operations. 2.3.1. Variables. If* is a variable of type A, then* is a term of type A. We are not allowed to introduce a variable x of type A unless x is distinct from all the variables on which the type A depends. Also, as remarked earlier, the type of a free variable must always be uniquely associated with the variable in question. We shall not care about the naming of bound variables. 2.3.2. Constants. If a is an object constant of type A, then a is a term of type A. The type of an object constant must always be closed. The object constants correspond, on the one hand, to the individual constants and function symbols in ordinary first order predicate logic and, on the other hand, to the axioms of a first order theory. 2.3.3. n-introduction or A.-abstraction. If x is a variable of type A and b[x] is a term of type B[x], then (X.x)b[x] is a term of type , _ ,. 2.3.4. It-elimination or application. If a and b are terms of types A and ', respectively, then b(d) is a term of type B[a]. 2.3.5. E-introduction or pairing. Let x be a variable of type A and B[x] a type. An intuitionistic theory of types 137 Then, if a and b are terms of types A and B[a], respectively, (a, b) is a term of type 2.3.6. £ -elimination. Let x, y and z be variables of type A, Z?[;t] and , respectively, and let C[z] be a type. Then, if c and d[x, y] are terms of types | and C[(x, y)], respectively, 1 is a term of type C[c]. 2.3.7. +-introduction or injection. If a is a term of type A, then i(a) is a term of type A + B. Similarly, if b is a term of type B, then j (b) is a term of type A + B. 2.3.8. +-elimination or definition by cases. Let x, y and z be variables of types A, B and A + B, respectively, and let C[z] be a type. Then, if c, d[x] and e[j] are terms of types A + B, C[i(x)] and C[j (y)], respectively, ) is a term of type C[c]. 2.3.9. Nn-introduction. 1,... , n are terms of type N n. 2.3.10. ^-elimination. Let z be a variable of type Nn and C[z] a type. Then, if c, c\\, ... , cn are terms of types N n, C[l],..., C[n], respectively, R n(c, c\\,..., cn) is a term of type C[c]. 2.3.11. AMntroduction or Peano's first and second axioms. 0 is a term of type N. If a is a term of type N, so is s(a). A term of type N which has the form s(s(.. .s(0) ...)) is called a numeral. 2.3.12. A'-elimination or recursion. Let* and y be variables of types N and C[x], respectively. Then, if c, d and e[x, y] are terms of types N, C[0] and C[s(x)], respec- tively, i is a term of type C[c]. 2.3.13. V-introduction or the reflection principle. NO, N\\, ... and N are terms of type V. If A and B are terms of type V, then so is A + fi. If A and B[x] are terms of type V, x being a variable of type A, then and are terms of type V. NQ and N\\ are alternatively denoted by _L and T, respectively. 2.3.14. Type conversion. This is a structural rule, that is, a rule which is to be considered neither as an introduction rule nor as an elimination rule. If a is a term of type A which converts to a type B, then a is a term of type B. It remains for us to define the notion of conversion. Before doing this, however, it will be convenient to represent the rules of term formation by schemata similar to those used by Gentzen 1934 in his system of natural deduction for first order predicate logic. Fl-introduction n-elimination £ -introduction 138 P. Martin-Lof 2.4. Contraction, reduction and conversion. We shall be concerned with contrac- tion, reduction and conversion of terms as well as types. However, in order to show that the terms and types are closed under reduction, we need a certain combinatorial property, the so-called Church-Rosser property, which will be proved for a class of in general meaningless formal expressions which is wide enough to include both the terms and the types. 2.4.1. Definition of formal expressions. 2.4.1.1. If a\\, ...,a n are expressions and P is an n-ary type constant, then P(ai,..., an~) is an expression. E-elimination -(--introduction -{--elimination Nn -introduction Nn -elimination //-introduction ./V-elimination V -introduction Type conversion An intuitionistic theory of types 139 2.4.1.2. If x is a variable and A and B[x] are expressions, then (Ylx e A)B[x] and (Ex e A)B[x] are expressions. 2.4.1.3. If A and B are expressions, then so is A + B. 2.4.1.4. TVo, NI, ..., N and V are expressions. 2.4.1.5. Variables and object constants are expressions. 2.4.1.6. If b[x] is an expression, then so is 2.4.1.7. If a and b are expressions, then so is b(a). 2.4.1.8. If a and b are expressions, then so is (a, b). 2.4.1.9. If c and d[x, y] are expressions, then so is 2.4.1.10. If a and b are expressions, then so are / (a) and ; (b). 2.4.1.11. If c, d[x] and e[y] are expressions, then so is 2.4.1.12. !,..., « are expressions. 2.4.1.13. If c, ci,... , cn are expressions, then so is , 2.4.1.14. 0 is an expression, and, if a is an expression, then so is s(a). 2.4.1.15. If c, d and e[x, y] are expressions, then so is 2.4.2. Rules of contraction. contr contr contr contr contr contr contr contr An expression which has the form of the left hand member of one of the rules of contraction is called a redex and the corresponding right hand member is its contractum. An expression a reduces to an expression b, abbreviated a red b, if b can be obtained from a by repeated contractions of parts of the expression a, and an expression is ir- reducible or normal if it cannot be further reduced. Finally, an expression a is said to convert into an expression b, abbreviated a conv b, if there is an expression c such that both a red c and b red c. 2.4.3. Church-Rosser property. If a red b and a red c, then there is an expression d such that b red d and c red d. The proof given below is an adaptation of a proof for the type free combinator calculus shown to me by William Tait. The idea is to introduce a suitable measure of the length of the sequence of contractions which reduces an expression a to an expression b. We shall say that a reduces in one step and write a redi b if b is obtained by contracting some, possibly all or none, of the redexes in a, starting from within and proceeding outwards. (Of course, even if we contract all redexes that occur in a certain expression, 140 P. Martin-Lof we do not necessarily obtain a normal one, because new redexes may arise when the old ones are contracted.) Reduction in n steps is defined inductively by putting a redo a and letting a redrt+i c mean that a redn b and b redi c for some b. Clearly, a red b if and only if a redn b for some n. (Indeed, n can be taken to be the total number of contractions that are carried out when reducing a to b.) 2.4.3.1. Lemma. If a red\\ c andb[x] red\\ d[x] then b[a] red\\ d[c]. This is obvious from the definition of one step reduction. 2.4.3.2. Lemma. If a red\\ b and a red\\ c, then there is an expression d such that b red\\ d and c red\\ d. The proof is by induction on the construction of the expression a. All cases in which a does not have the form of a redex are handled immediately by means of the induction hypothesis. Equally trivial are the cases when a is a redex which is contracted neither in b nor in c. There remain the cases when a is a redex which is contracted either in one of b and c, say c, or in both. 2.4.3.2.1. a has the form I. Then b has the form i or b2[b\\] and c has the form C2[ci] where By induction hypothesis, we can find d\\ and di[x] such that But then (kx)b2[x](b\\) redi d2[d\\\\ by the definition of one step reduction and b2[b\\] and C2[ci] redi ^2^1] by the previous lemma so that d can be taken to be d2[d\\]. 2.4.3.2.2. a has the form j I. Then b has the form or b^[b\\, b2\\ and c has the form cafci, 02] where i By induction hypothesis, we can find d\\, di and d$[x, y] such that But then ) redi di,[d\\, d^\\ by the definition of one step re- duction and b$[bi, b^} and 03[ci, ci} redi dj,[d\\, di\\ by the previous lemma so that d can be taken to be d^[d\\, d-i\\. 2.4.3.2.3. a has the form Then b has the form or bi\\b\\\\ and c has the form ci[ci] where a\\ redi b\\, ai[x] redi bi[x], a^[y] redi b^[y], a\\ redi c\\, a2[x] redi C2[x]. An intuitionistic theory of types 141 By induction hypothesis, we can find d\\ and d2[x] such that But then D(i(b\\), ' redi di[d\\] by the definition of one step re- duction and b2[bi] and C2[ci] redi fifof^i] by the previous lemma so that d can be taken to bec?2[di]. 2.4.3.2.4. a has the form C . This case is completely symmetric to the previous one. 2.4.3.2.5. a has the form Rn(m, a\\,..., an). Then b has the form Rn(m, b\\, ..., bn) or bm and c has the form cm where By induction hypothesis, we can find dm such that But then Rn(m, b\\,..., bn) redi dm by the definition of one step reduction and bm and cm redi dm so that d can be taken to be d m. 2.4.3.2.6. a has the form . Then b has the form or £>2 and c has the form 02 where By induction hypothesis, we can find di such that But then by the definition of one step reduction and bi and ci redi <^2 so that d can be taken to be di. 2.4.3.2.7. a has the form Then b has the form or and c has the form where a\\ redi b\\, 02 redi bz, aj,[x, y] redi b^[x, y], a\\ redi c\\, ai redi C2> a^[x, y] redi c^[x, y]. 142 P. Martin-Lof By induction hypothesis, we can find d\\, di and d$[x, y] such that Let d be the expression Then redi d and and by the definition of one step reduction so that \" _\"\" _ ~ '\" _ '.'...'/. . ... and redi d by the previous lemma as desired. 2.4.3.3. Lemma. If a redm b and a redn c then there is an expression d such that b redn d and c redm d. This folllows by mn applications of the previous lemma. The proof of the Church- Rosser property is now complete. 2.4.4. Corollary. The relation a conv b is an equivalence relation. The reflexivity and symmetry are both obvious from the definition. To prove the transitivity, suppose that a conv b and b conv c. By the definition of the convertibility relation, this means that there are expressions d and e such that a red d, b red d, b red e and c red e. Because of the Church-Rosser property, we can find an expression / such that d red / and e red / . Since the reducibility relation is transitive, a red / and c red / so that a conv c as desired. It is a consequence of the transitivity of the convertibility relation that a sequence of successive applications of the rule of type conversion can be condensed into one application of the same rule. Thus, whenever convenient, we can assume that there is at most one (or even precisely one) application of the rule of type conversion between two successive applications of the non structural rules of term formation. 2.4.5. Uniqueness of normal forms. An expression can convert into at most one normal expression. First note that, because of the Church-Rosser property, an expression which con- verts into a normal expression must necessarily reduce to it. So suppose that a red b and a red c where a is an arbitrary expression and b and c are both normal. By the Church- Rosser property, there is an expression d such that b red d and c red d. Since b and c are both normal, they must be equal to d and hence equal to each other. Remember that equality means syntactical equality neglecting differences in the naming of bound variables. 2.4.6. Definitional equality. Two types A and B are said to be definitionally equal provided A conv B. Also a term a of type A is definitionally equal to a term b of type B if both a conv b and A conv B. Note that, because of the rule of type conversion, two terms are of definitionally equal types if and only if they are of the same type. Two def- initionally equal types denote the same abstract type, and, similarly, two definitionally An intuitionistic theory of types 143 equal terms denote the same object of the abstract type denoted by their types. Thus, definitional equality is a relation between linguistic expressions and not between the abstract entities which they denote (and which are the same). This explains why the rule of type conversion, unlike all the other rules of term formation, has no counterpart on the informal level. (It is superfluous to say that if a is an object of type A and the types A and В are the same, then a is an object of type 5.) Because of the representation of propositions as types and hence of proofs as mathe- matical objects, the relation of definitional equality just introduced embraces at the same time Tail's 1967 notion of definitional equality between the terms of Gödel's 1958 the- ory of primitive recursive functionals of finite type and the notion of definitional equality between derivations representing proofs that I have proposed earlier (see Prawitz 1971). 2.4.7. Theorem. The terms of a given type are closed under reduction. This means that, if a term of a certain type reduces to an expression, then this ex- pression is actually a term of the same type. Clearly, it suffices to prove this when the expression is obtained from the given term by one step reduction. The proof is by induction on the derivation of the given term. Several cases have to be distinguished. 2.4.7.1. The derivation of the given term has the form and because . By induction hypothesis, under th e assumption an d hencefollow s b y П-introduction. 2.4.7.2. The derivation of the given term has the form and b(a) redi d(c) because a redj с and b redi d. By induction hypothesis, and , from which follows by -elimination. Type conversion then yields as desired. 2.4.7.3. The derivation of the given term has the form red 144 R Martin-Löf where conv , that is, A conv В and B[x] conv D[x], and because a redi с and b[x] redi d[x]. By induction hypothesis, and under the assumption . The derivation shows that d[c] is indeed a term of type B[a]. 2 A.I A. The derivation of the given term has the form and (a, b) redi (с, d) because a red] с and b redi d. By induction hypothesis, and E-introduction. 2.4.7.5. The derivation of the given term has the form and redi because с redi / and d[x, y] redi gf*,} 1]. By induction hypothesis, and under the assumptions , and hence . follows by -elimination. Type conversion then yields as desired. 2.4.7.6. The derivation of the given term has the form where conv , that is, A conv С and B[x] conv D[x], and because a redj c, b redi d and d[x, y] redi tybe conversion yield then follows byand An intuitionistic theory of types 145 g[x,y]. By induction hypothesis, and under the assumptions and . The derivation shows that g[c, d] indeed is a term of type C[(a, b)]. 2.4.7.7. The derivation of the given term has the form and i (a) redi i (с) because a redi с. By induction hypothesis, we get , from which follows by -introduction. The other rule of -introduction is treated in the same way. 2.4.7.8. The derivation of the given term has the form and redi because с redi /> d[x} redi g[x] and e[y] redi h[y]. By induction hypothesis, and and under the assumptionsan d , respectively, and hence follows by -elimination. Type conversion then yields as desired. 2.4.7.9. The derivation of the given term has the form where A + В conv С + D, that is, A conv С and В conv D, and , because a redi с and d[x] redi g[x]. By induction hypothesis, 146 P. Martin-Löf and under the assumption , The derivation shows that g[c] is indeed a term of type C\\i(a)}. The case when i (a) is replaced by j (b) is treated in the same way. 2.4.7.10. The terms of type Nn cannot reduce to anything but themselves, and hence this case is trivial. 2.4Л.11. The derivation of the given term has the form and red; because с redi redi /„. By induction hypothesis, we get , from which follows by N n -elimination. Type conversion then yields as desired. 2.4.7.12. The derivation of the given term has the form and redi fm because c m red] fm. By induction hypothesis, we get as desired. 2.4.7.13. The case when the given term is 0 of type N is trivial, so suppose the derivation of the given term has the form and that s(a) redi s (с) because a redi с. By induction hypothesis, and hence follows by TV-introduction. An intuitionistic theory of types 147 2.4.7.14. The derivation of the given term has the form and l redi .._....becaus e с red] /, d redi g and e[x, y] redi h[x, y]. By induction hypothesis, and under the assumptions. and , and hence follows by TV-elimination. Type conversion then yields as desired. 2.4.7.15. The derivation of the given term has the form and redi g because d redi g- By induction hypothesis, we get g e C[0] as desired. We also have to consider the case when the derivation of the given term has the form and redi because a redi с, d redi g and By induction hypothesis,an d under the assumptions and The derivation shows that is indeed a term of type C[s(a)]. 148 P. Martin-Löf 2.4.7.16. The derivation of the given term has the form and redi ч - , . , because A red] С and B[x] red] D[x]. By induction hypothesis, andunde r the assumption . The derivation shows that is indeed a term of type V. The case when takes the place of is treated in the same way, so suppose instead that the derivation of the given term has the form and that A + В redi С + D because A redi С and В redi D. By induction hypothesis, and so that as desired. The case when the given term is one of NO, is trivial because they do not reduce to anything but themselves. The proof of theorem 2.4.7 is now complete. 2.4.8. Corollary. The types are closed under reduction. Suppose that a type A reduces to an expression В. We have to show that В is a type as well and use induction on the construction of A. The induction step is trivial, and so is the case when A is V. If A is a term of type V, then, by the previous theorem, В is a term of type V and hence a type. Finally, suppose that A has the form where are terms of types . , respectively. Then В must have the form , where a\\ red red b n . By the previous theorem, ar e terms o f types , respectively. Bu t conv and hence, by the rule of type conversion, b indeed a type. 2.5. Axiom of choice. Let x and у be variables of types A and Я [JE], respectively, and let С [JE, y] be a type. We shall show how to derive the axiom of choice, that is, how to construct a closed term of type isis a term of tybe An intuitionistic theory of types 149 To begin with, note that, if we let p[z] and q[z] denote the terms and which satisfy then hold as derived rules of term formation since they are instances of the -elimination rule. Now, suppose and П-elimination gives from which the derived rules of inference just stated allow us to conclude and Type conversion on the latter yields and we can then use П-introduction to get as well as Applying -introduction to the last two terms, we get and a final -introduction then shows that is a (closed) term of type as desired. 150 R Martin-Löf 3. REDUCTION OF SOME OTHER FORMAL THEORIES TO THE THEORY OF TYPES. 3.1. Intuitionistic first order predicate logic. 3.1.1. Formulae are built up as usual from individual variables, function constants and predicate constants by means of the logical operators and . The negation A of a formula A is defined as . We take the rules of inference from Gentzen 1934. '-introduction -elimination -introduction -elimination -introduction -elimination '-introduction -elimination -introduction -elimination An intuitionistic theory of types 151 -elimination 3.1.2. To translate this system into the theory of types, we first introduce a 0-ary type constant for the type of individuals and then proceed as follows. 3.1.2.1. Translation of the language. 3.1.2.1.1. An individual variable x is mapped into a variable of type 3.1.2.1.2. An n-ary function symbol / is mapped into a constant oftype and, if a\\,..., a n are individual terms, we let be 3.1.2.1.3. An n-ary predicate constant P is mapped into an n-ary type constant with all arguments of type 3.1.2.1.4. An atomic formula P(a\\,..., a n) is mapped into the type , , and the formulae. are translated into the types NO, . respectively. Note that, for every formula A, the type is normal. 3.1.2.2. Translation of the derivations. By induction on the length of a derivation a of a formula A in first order logic, I shall construct a term of type in the theory of types. 3.1.2.2.1. Corresponding to an assumption A in first order logic, we introduce a variable oftype in the theory of types. 3.1.2.2.2. -introduction. By induction hypothesis, we have constructed a term of type where is the variable of type that corresponds to the assumption A. The translation of the derivation o f i s defined t o be . B y th e rule o f -introduction, this i s a term of the type which is 3.1.2.2.3. -elimination. By induction hypothesis, we have constructed terms and of types and , respectively. The translation of the derivation of В is defined to be which, by the rule of -elimination and the definition of as . , is a term of type . and and 152 P. Martin-Löf 3.1.2.2.4. -introduction. By induction hypothesis, we have constructed terms : and of types and _ , respectively. The translation of the derivation of is defined to bei . By the rule of introduction, this is a term of the type. which is 3.1.2.2.5. elimination. By induction hypothesis, we have constructed a term of type . The transla- tion of the derivation of A is defined to be , that is, , which, by the rule of -elimination and the definition of as , is a term of type . The case when В rather than A is inferred from A &B is treated in the same way. 3.1.2.2.6. -introduction. By induction hypothesis, we have constructed a term of type . The translation of the derivation of is defined to be . By the rule of -introduction, this is a term of the type. which is . The case in which is inferred from В instead of A is treated in the same way. 3.1.2.2.7. -elimination. By induction hypothesis, we have constructed terms and of types and , respectively, where and are the variables corresponding to the assumptions A and B. The translation of the derivation of С is defined to be which, by the rule of -elimination and the definition of is a term of type as required. 3.1.2.2.8. -introduction. An intuitionistic theory of types 153 By induction hypothesis, we have constructed a term of type where is the variable of type which corresponds to the individual variable x. The translation of the derivation of is defined to be By the rule of -introduction, this is a term of the type which is 3.1.2.2.9. -elimination. By induction hypothesis, we have constructed a term of type . Let the term of type be the translation of the individual term a. The translation of the derivation of В [a] is defined to which, by the rule of -elimination and the definition o f as , i s a term o f type . I t only remains to remark that equals 3.1.2.2.10. l-introduction. By induction hypothesis, we have constructed a term of type or, what amounts to the same, . Let the term of type be the translation of the individual term a. The translation of the derivation of is defined to be . By the rule of -introduction, this is a term of the type which is 3.1.2.2.11. -elimination. By induction hypothesis, we have constructed terms and of types and , respectively, where is the translation of the individual variable x and is the variable of type that corresponds to the assumption B[x]. The translation of the derivation of С is defined to be which, term of type 3.1.2.2.12. -elimination. by the rule ofelimination and the defifition of is a 154 P. Martin-Löf By induction hypothesis, we have constructed a term of type . The translation of the derivation of С is defined to be RQ which, by the rule of NO -elimination and the definition of as NO, is a term of type 3.1.3. Consider the reduction relation between derivations in first order logic which is generated by Prawitz's 1965 rules of contraction. -contraction -contraction -contraction -contraction -contraction The mapping of the derivations of first order logic into terms of the theory of types is an isomorphic imbedding in the sense that, if a red b, then red, , and, conversely, if a is a derivation in first order logic and red , then is the translation of a derivation contr contr contr contr contr contr contr An intuitionistic theory of types 155 b in first order logic such that a red b. Consequently, Prawitz's 1965 normalization theorem for first order logic is a corollary of the normalization theorem for the theory of types that will be proved later on. 3.2. Intuitionistic first order arithmetic. 3.2.1. As usual, we take the language to be the language of first order predicate logic based on the single binary predicate constant = and the four function constants, , and •. We also include the propositional constant T for truth. To the rules of inference of intuitionistic first order predicate logic, we add the axiom T, the induction schema and the rule of formula conversion A conv В where conv is the convertibility relation which is generated by the rules of contraction It is easy to verify that the usual axioms for number theory as given by Kleene 1952, for example, can be derived in this system. When one is interested in the reduction of derivations, the present formulation of first order arithmetic has a definite advantage over the standard one. Suppose namely that the numerical term a reduces to b. We then want a derivation of the form contr ?? ??? ???? ?? ???????????? ??? ??? ?????????? ??? ?? ? contrcontr contr contr contr contr 156 P. Martin-Löf to reduce to the derivation in which a has been replaced by b, However, if arithmetic is formulated without a rule of formula conversion, this reduction cannot be carried out without inserting a logically complex derivation of C[a] from C[b], and this is a transformation which destroys the structure of the derivation to such an extent that the transformed derivation fails to be defmitionally equal to the original one. 3.2.2. The translation of first order arithmetic into the theory of types proceeds as follows. 3.2.2.1. Translation of the language. 3.2.2.1.1.A numerical variable x is translated into a variable of type W. 3.2.2.1.2. « : is taken to be the term 0 of type N. 3.2.2.1.3. is 3.2.2.1.4. is 3.2.2.1.5. is 3.2.2.1.6. An equation a = b is translated into where E (a, b) is defined tobe which is a term of type V and hence a type that satisfies the schema Note that the axioms and which form part of the reflection principle are needed in order to prove that E (a, b) is a term of type V and hence a type. 3.2.2.1.7. The translation of composite formulae runs as in the case of first order predicate logic, the prepositional constant T being translated into NI. 3.2.2.2. Translation of the derivations. In addition to the rules of inference of first order predicate logic already stated, we have to consider the axiom T, the induction schema and the rule of formula conversion. 3.2.2.2.1. The axiom T is translated into the term 1 of the type NI which is conv An intuitionistic theory of types 157 3.2.2.2.2. Let us now turn to the induction schema, By the hypothesis of the induction on the length of the given derivation, we have found terms and of types and , respectively, being the variable of type that corresponds to the assumption С [x ]. The translation of the derivation of C[a] is defined to be which, by the TV-elimination rale, is a term of type or, what amounts to the same, Note that the translation is such that the induction contractions in first order arith- metic (see, for example, Prawitz 1971) are mapped into the contractions in the theory of types. 3.2.2.2.3. If the term of type is the translation of the derivation of the premise of an application of the rule of formula conversion contr contr contr contr contr 158 P. Martin-Löf we can take the translation of the derivation of В to be the same term , because A conv В implies conv and hence we can conclude that is a term of type by the rule of type conversion. 3.3. Intuitionistic arithmetic of finite type with the axiom of choice. 3.3.1. The formalization of this theory that we shall consider extends the system of first order arithmetic specified above and differs in certain respects from the ones given by Spector 1962, Tait 1967 and Troelstra 1971. 3.3.1.1. Types. 0 is a type, and, if a and are types, so is 3.3.1.2. Terms. 3.3.1.2.1. A variable of type is a term of type . 3.3.1.2.2. 0 is a term of type 0, and, if a is a term of type 0, so is a!. 3.3.1.2.3. If x is a variable of type and b[x] is a term of type , then is a term of type 3.3.1.2.4. If c, d and e[x, y] are terms of types 0, and , respectively, x being a numerical variable and y a variable of type , then is a term of type . 3.3.1.2.5. If a and b are terms of types and i , respectively, then b(d) is a term of type . 3.3.1.3. Formulae are built up from numerical equations by means of propositional connection and quantification of variables of arbitrary finite type. 3.3.1.4. Rules of contraction. 3.3.1.5. The rules of inference are those of intuitionistic first order arithmetic, except that the quantifier rules have to be extended in the obvious way to all finite types. In addition, there is the (intuitionistically valid) axiom of choice with x, y and / of arbitrary types and , respectively. 3.3.2. The translation of this theory into the theory of types proceeds as follows. 3.3.2.1. Translation of the types. We take to be N and tobe 3.3.2.2. Translation of the terms. contr contr contr contr contr An intuitionistic theory of types 159 3.3.2.2.1.A variable x of typei s translated into a variableo f type 3.3.2.2.2. is the term Oof type N, andi s 3.3.2.2.3. is defined to be 3.3.2.2.4. is defined to be i. 3.3.2.2.5. is defined to be 3.3.2.3. The translation of the formulae runs as in the case of first order arithmetic, the only novelty being that ' and : with x of type are defined to be and , respectively. 3.3.2.4. The interpretation of the rules of inference is no more complicated than in the case of first order arithmetic, the quantifier rules of inference of higher type being treated just like those of ground type. There remains the axiom of choice, whose translation is but an instance of the axiom of choice in the theory of types which we proved in section 2.5. 3.3.3. When the law of the excluded middle (or, equivalently, reductio ad absurdum • is added to intuitionistic arithmetic of finite type with the axiom of choice, the resulting system contains full simple type theory. (See Spector 1962, for example, in the case when the function which exists by virtue of the axiom of choice and the species which exists by virtue of the comprehension axiom both have arguments of ground type.) Thus the proof theoretic strength of the system increases by a very large amount. Since intuitionistic arithmetic of finite type with the axiom of choice is a subsystem of the theory of types, the same holds for the latter theory. Consequently, the axiom schema . (or, equivalently, ) is not consistent relative to the theory of types, although, of course, it may be proved to be consistent by stronger means. In particular, there is no hope for the double negation interpretation (see Kolmogorov 1925, Gödel 1933 and Gentzen 1933) to work, the reason for this being that the axioms for and are stronger than the usual intuitionistic axioms for and 3.4. Intuitionistic arithmetical analysis with the axiom of choice. 3.4.1. To the system of first order arithmetic we now add и-агу predicate variables X, У,.. . for every An atomic formula is either of the form a = b or of the form where В is an n-ary predicate term and a\\,..., a n are numerical terms. Formulae are built up from atomic ones by means of the propositional connec- tives and quantifiers of both first and second order. An n-ary predicate term is either an и-ary predicate variable or of the form where is a formula which contains no bound predicate variables. The first order quantifier rules of inference are extended in the obvious way to the second order. Finally, we add the axiom of choice 160 P. Martin-Löf Here Y is a predicate variable of one argument more than X and C[x, Y(x)] denotes the result of replacing every part of С [x, X] of the form by 3.4.2. The translation of mis theory into the theory of types proceeds as in the case of first order arithmetic with the following additions. 3.4.2.1. An и-ary predicate variable X is translated into a variable. of type in the theory of tvpes. 3.4.2.2. is defined to be 3.4.2.3. an d ar e translated and , respectively. 3.4.2.4. is defined to be jc*] which is seen to be a term of type by repeated use of the reflection principle and the fact that the translations and ¡ of the atomic formulae a = b and , are terms of type V. 3.4.2.5. The second order quantifier rules of inference are interpreted just like the first order ones. 3.4.2.6. The translation of the axiom of choice is just an instance of the axiom of choice in the theory of types which we proved in section 2.5. 4. THE NORMALIZATION THEOREM AND ITS CONSEQUENCES. 4.1. Normalization theorem. Every term reduces to a normal term. Since we have introduced constants of every closed type, it will be sufficient to prove normalization for closed terms. Suppose namely that, is an open term which depends o n th e variables o f types , re - spectively. For we may then introduce a constant a m of the closed type . By substituting the constants for the variables. we get a closed term which behaves just like from the point of view of normalization. My proof of normalization uses an extension of the method of computability in- troduced by Tait 1967 in order to prove normalization for the terms of Gödel's 1958 theory of primitive recursive functionals of finite type and systematically exploited in the 'Proceedings of the Second Scandinavian Logic Symposium'. In Gödel's theory, the types and the terms are generated separately from each other. This makes it possible, first, to define by induction on the construction of a type the notion of computability for terms of that type, and, second, to prove by induction on the construction of a term that latedinto An intuitionistic theory of types 161 it is computable. In the present theory, however, the definition of the notion of com- putability and the proof that an arbitrary term is computable can no longer be separated, because the terms and the types are generated simultaneously. Instead, we have to show by induction on the construction of a type or term, in case A is a type, how to define the predicate which expresses the computability of a term of type A, and, in case a is a term of type A, that is defined and that i holds, that is, that a is a computable term of type A. The situation is further complicated by the fact that a type as well as a term of type in general depends on certain free variables of types , respectively. By induction hypothesis, we shall then know that has been defined and that if a\\ is a closed term of type AI such that , then has been defined and thati f are closed terms of types \" \", respectively, such that , then I has been defined. Letting closed terms of types respectively, such that we have to show, in case is a type, how to define and, in case a is a term of type , that • is defined and that holds, that is, that a is a computable term of type Several cases have to be distinguished, one for each of the rules of type and term formation. In order to alleviate the notational burden, I shall not exhibit explicitly any free variables except the eigenvariables of the particular rule of type or term formation which is being considered. It will be convenient to say that a term has introduction or elimination form de- pending on whether it has been formed by means of one of the introduction or one of the elimination rules. Thus, unless it is a constant, a closed term necessarily has either introduction or elimination form. 4.1.1. Definition of for a type symbol A. 4.1.1.1. is the species of normalizable closed terms of type 4.1.1.2. Suppose that has been defined and that has been defined for all closed terms a of type A such that ). We then define by the following three clauses. 4.1.1.2.1. If is a closed term of type and for all closed terms a of type A such that , then ( i. 4.1.1.2.2. A closed normal term of type which is not of the form satisfies 162 P. Martin-Löf 4.1.1.2.3. If the closed term b of type has elimination form and reduces to a term a such that , then 4.1.1.3. Again, suppose that has been defined and that has been defined for all closed terms a of type A such that We then define by the following three clauses. 4.1.1.3.1. If a and b are closed terms of types A and B[a], respectively such that , then 4.1.1.3.2. A closed normal term of type which is not of the form (a, b) satisfies 4.1.1.3.3. If the closed term b of type has elimination form and reduces to a term a such that ' ' , then ). 4.1.1.4. Supposing and have been defined already, we define by the following three clauses. 4.1.1.4.1. If a is a closed term of type A such that , then . Simi- larly, if b is a closed term of type В such that i , then 4.1.1.4.2. A closed normal term of type A + В which is neither of the form ¿(a) nor of the form j (b) satisfies 4.1.1.4.3. If the closed term b of type A + В has elimination form and reduces to a term a such that , then 4.1.1.5. The predicate is defined by transfinite induction. But, simultaneously with the definition of the meaning of , that is, of what constitutes a proof of , we have to define by transfinite induction the predicate which expresses what it means for a closed term of the small type A to be computable. Actually, depends not only on A but also on the proof of ) although my notation does not indicate that explicitly. 4.1.1.5.1.If С is a closed normal term of type V which is not of the form or A + B, then and is defined to be the species of normalizable closed terms of type C. 4.1.1.5.2.Iflan d for all closed terms a of type A such that then i and is defined as in 4.1.1.2. 4.1.1.5.3. This case is like the previous one, replacing by and referring to 4.1.1.3 instead. 4.1.1.5.4. I f and , thenandi s defined a s i n 4.1.1.4. 4.1.1.5.5. If the closed term В of type V has elimination form and reduces to a term A such that , then and is set equal to 4.1.1.6. If A is a term of type V such that i,then is the associated predicate defined in 4.1.1.5. 4.1.2. Lemma. When defined, the predicate has the following three proper- ties. First, holds if a is a closed normal term of type A which does not have introduction form. Second, ifb is a closed term of type A which has elimination form and reduces to a term a such that , then' ' \" Third,implies that a is normalizable. We prove the lemma by induction on the definition of 4.1.2.1. is the species of normalizable closed terms of type An intuitionistic theory of types 163 and has therefore trivially the three properties stated in the lemma. 4.1.2.2. has trivially the first two properties. To verify the third, sup- pose that a term satisfies |. Then it reduces to a term which is either nor- mal, in which case we are done, or else has the form and the property that for all a such that . By induction hypothesis, holds if a is a constant of type A. Consequently, is defined and so that b[a] is nor- malizable by induction hypothesis. And, b[a] being normalizable, so is 4.1.2.3. was defined so as to have the first two properties. To verify the third, suppose that a term satisfies It must then reduce to a term which is either normal, in which case we are done, or else has the form (a, b) where and I. By induction hypothesis, a and b are normalizable and, consequently, so is (a,b). 4.1.2.4. was defined so as to have the first two properties. To verify the third, suppose that a term satisfies . It must then reduce to a term which is either normal, in which case we are done, or else has the form i (a) or j (b) where, in the first case, and, in the second case, . By induction hypothesis, implies that a is normalizable and implies that b is normalizable. Hence I (a) is normalizable in the first case and j (b) in the second. 4.1.2.5. was defined so as to have the first two properties. By transfmite induc- tion on the proof of , we shall at the same time prove thatimplie s that A is normalizable and verify that the associated predicate has all the three properties stated in the lemma. 4.1.2.5.1. If С is a closed normal term of type V which is not of the form or A + B, then С is a fortiori normalizable and the associated predicate , being defined as the species of normalizable closed terms of type C, has trivially all the three properties stated in the lemma. 4.1.2.5.2. Suppose that is concluded from and for all terms a such that I. By induction hypothesis, A is normalizable and if a is a constant of type A. Hence so that, again by induction hypothesis, В [a] is normalizable. But then so is \"~~ ]. The verification that the lemma holds for is as in case 4.1.2.2. 4.1.2.5.3. This case is like the previous one, replacing by and referring to 4.1.2.3 instead. 4.1.2.5.4. Suppose that has been concluded from andi .By induction hypothesis, A and ß are normalizable and hence so is A + B. The verification that the lemma holds for is as in case 4.1.2.4. 4.1.2.5.5. Suppose that is concluded from and the knowledge that the closed term В of type V has elimination form and reduces to A. By induction hypothesis, A is normalizable and has all the three properties stated in the lemma. Hence ß is normalizable and, since was set equal to ,, the lemma holds for as well. 4.1.2.6.That the lemma holds for the predicateassociated with a term of type V such that has just been proved in 4.1.2.5. The proof of the lemma is now complete. 164 P. Martin-Löf 4.1.3. Lemma. If and are both defined and A conv B, then ifandonly if Note that, in accordance with the remark in 4.1.1.5, the lemma is not trivially true even if A and В are syntactically equal, because even for one and the same type symbol A there may be different ways of defining the predicate Since A conv B, the types A and В are either both small or both large. In the latter case, they must be built up in the same way from V, definitionally equal atomic types of the form and definitionally equal small types. was defined in 4.1.1.1 to be the species of normalizable closed terms of type . Hence, if conv , thei and are extensionally equal because of the rule of type conversion. It now only remains to prove the lemma for two small types A and B. When A is a small type, is defined if and only if Therefore we can use transfinite induction on the proofs of and . Several cases have to be distinguished depending on how ' and have been inferred. 4.1.3.1. If both and hold by virtue of 4.1.1.5.1, then and are the species of normalizable closed terms of types A and В, respectively, and so they are extensionally equal by the rule of type conversion. 4.1.3.2. If A and В have the forms and , respectively, then С conv E and D[x] conv F[x]. Hence and are extensionally equal by induction hypothesis. For the same reason, and are extensionally equal for all с such that or, equivalently, . Being defined by 4.1.1.2, and are extensionally equal as well. 4.1.3.3. This case is like the previous one, replacing by and referring to 4.1.1.3 instead. 4.1.3.4. If A and В have the forms С + D and E + F, respectively, then С conv E and D conv F. Hence, on the one hand, and on the other hand, and are extensionally equal by induction hypothesis. Being defined by 4.1.1.4, and i are extensionally equal as well. 4.1.3.5. If one of i and , say , is inferred by 4.1.1.5.5, then A reduces to С such that . By induction hypothesis, and are extensionally equal, and, since in this case is set equal to , so are and 4.1.4. Verification that, if a is a term of type A, then is defined and 4.1.4.1. When we introduce a variable x of type A, we know by induction hypoth- esis that is defined. We have to show that is defined and that, if a is a closed term of type A, such that i , then . This requires no argument. 4.1.4.2. When we introduce a constanta of type A, we know by induction hypoth- esis that is defined. We have to show that is defined and that holds which follows from the first part of lemma 4.1.2. 4.1.4.3. -introduction. By induction hypothesis, we know that is defined and that, if a is a closed term of type A, then is defined and i I. Hence is defined by 4.1.1.2 and holds by virtueof 4.1.1.2.1 which is what we had to prove. 4.1.4.4. -elimination. By induction hypothesis, we know that and are defined and that and i ) both hold. Three cases have to be An intuitionistic theory of types 165 distinguished corresponding to the defining clauses of 4.1.4.4.1. b is of the form holds for all a such that '. Then b(a) has elimination form and reduces to d[a] so that i by the second part of lemma 4.1.2. 4.1.4.4.2. b is normal and not of the form . Let с be the normal form of a which exists by the third part of lemma 4.1.2. Then b(a) reduces to b(c) which is normal and has elimination form so that by the first and second parts of lemma 4.1.2. 4.1.4.4.3. b has elimination form and reduces to d which satisfies Then b(a) reduces to d(a) which we have already shown to satisfy . Hence by the second part of lemma 4.1.2. 4.1.4.5. -introduction. By induction hypothesis, is defined and is defined for all a such that . Also, l and i. Hence is defined by 4.1.1.3 and holds by virtue of 4.1.1.3.1. 4.1.4.6. -elimination. B y induction hypothesis, w e know thati s defined and that is defined for all с such that . Also, holds and holds for all a and b such that and . Three cases have to be distinguished corresponding to the defining clauses of 4.1.4.6.1. с has the form (a, b) where • and . Then I d[x, y]) has elimination form and reduces to d[a, b] which satisfies . Hence by the second part of lemma 4.1.2. 4.1.4.6.2. с is normal and not of the form (a,b). Let a and b be constants of types A and B[a], respectively. Then and < by the first part of lemma 4.1.2. Hence < so that d[a, b] reduces to a normal term g[a, b] by the third part of lemma 4.1.2. But then , reduces to which is normal and has elimination form so that < by the first two parts of lemma 4.1.2. 4.1.4.6.3. с has elimination form and reduces to a term / which satisfies . Then reduces to which we part of lemma 4.1.2 and lemma 4.1.3. 4.1.4.7. -introduction. By induction hypothesis, and are both defined and holds. Hence is defined by 4.1.1.4 and <¡ hold s by virtue of 4.1.1.4.1. The second rule of -introduction is treated in the same way. 4.1.4.8. -elimination. By induction hypothesis, we know that is defined and that is defined for all с such that Also, holds and and hold for all a and b such thatan d respectively. Three cases have to be distinguished corresponding to the defining clauses of 4.1.4.8.1. с has the form ¿(a) and i .Then . has elim- ination form and reduces to d[a] which satisfies j. Hence , by the second part of lemma 4.1.2. The case when с is of the form j(b) is treated in the same way. 4.1.4.8.2. с is normal and not of the form i(a) or j(b). Let a and b be constants of types A and В, respectively. Then i and by the first part of lemma 4.1.2. ???? ??????? ????? ?? ??????? ??????? ??? ?????? by The Seconda 166 P. Martin-Löf Hence and so that d[a] and e[b] reduce to normal terms g[a] and h\\b} bv the third Dart of lemma 4.1.2. But then reduces to which is normal and has elimination form so that by the first two parts of lemma 4.1.2. 4.1.4.8.3. с has elimination form and reduces to a term / which satisfies then ready shown to satisfy Hence by the second part of lemma 4.1.2 and lemma 4.1.3. 4.1.4.9. N n-introduction. is defined by 4.1.1.5.1 to be the species of normaliz- able closed terms of type N n. Hence i. 4.1.4.10. N n-elimination. By induction hypothesis, we know that is defined for all с such that . Also, and . We distinguish three cases depending on the form of c. 4.1.4.10.1. с is m. Then , has elimination form and reduces to c 4.1.2. 4.1.4.10.2. с is normal and not one of . By the third part of lemma 4.1.2, reduce to normal terms . Hence reduces to which is normal and has elimination form so that by the first two parts of lemma 4.1.2. 4.1.4.10.3. с is not normal but reduces to a normal term /. Then - reduces to , which we have already shown to satisfy Hence by the first part of lemma 4.1.2 and lemma 4.1.3. 4.1.4.11. ^-introduction. is defined by 4.1.1.5.1 to be the species of normaliz- able closed terms of type N. Hence holds and implies i. 4.1.4.12. Л'-elimination. By induction hypothesis, we know that is defined for all a such that . Also, i hold and holds for all a and b such that and . We distinguish four cases depending on how we have inferred 4.1.4.12.1. с is 0. Then reduces to d which satisfies so that by the second part of lemma 4.1.2. 4.1.4.12.2. с is of the form s (a). We then know already that and < both hold so that we can conclude . Bu t reduces t that it must satisfy by the second part of lemma 4.1.2. 4.1.4.12.3. с is normal and has elimination form. From we can conclude that d reduces to a normal term g by the third part of lemma 4.1.2. Also, let a and b be constant of types N and С [a], respectively. Then and by the first part of lemma 4.1.2. Hence i so that e[a, b] reduces to a normal term h[a, b], again by the third part of lemma 4.1.2. But then reduceds which we have al and ? ????? ????????? ? ??????? ??? ????a?? ???? ?? ????? An intuitionistic theory of types 167 reduces to which is normal and has elimination form so that < by the first two parts of lemma 4.1.2. 4.1 A.12.4. с has elimination form and reduces to a term / such that . Then reduces to ; which we have already shown to satisfy Hence by the second part of lemma 4.1.2 and lemma 4.1.3. 4.1.4.13. У-introduction, and all hold by virtue of definition 4.1.1.5.1. Next, suppose that holds and that (py(B[a]) holds for all a such that ( . Then we can conclude and by 4.1.1.5.2and 4.1.1.5.3. Finally, suppose that and both hold. Then we can conclude by 4.1.1.5.4. 4.1.4.14. Type conversion. By induction hypothesis, and are both defined and holds. Hence by Iemma4.1.3. Theproof of the normalization theorem is now complete. 4.2. Corollary. Every type reduces to a normal type. Every type is built up by means of the operations , , and from , small types and atomic types of the form . A small type, being a term of type , is normalizable according to the normalization theorem, and so is a type of the form since are all terms. Hence every type is normalizable. 4.3. Corollary. It can be mechanically decided whether or not two terms or two types are definitionally equal. Let A and В be two types. In order to decide whether or not A conv В we simply normalize A and B, which is possible according to the previous corollary, and check whether or not their normal forms are syntactically equal except possibly for differences in the naming of their bound variables. Similarly, if a is a term of type A and b a term of type B, we first decide whether or not A conv В and then, in case the answer is positive, whether or not a conv b. According to the normalization theorem, the latter decision can also be reached by normalizing a and b and checking if their normal forms are the same. 4.4. The form of the normal terms. In order to determine the syntactical form of the normal terms, it will be convenient to introduce some terminology. The major sub- term of a term which has elimination form is defined by stipulating that the major sub- term of b(a) is b and that the major subterm of and in all cases is c. The main redex of a redex is the redex itself, and the main redex of a term which has elimination form but is not a redex is the main redex of its major subterm. If a term has elimina- tion form, then either it contains a main redex or else by taking the major subterm of its major subterm of of its major subterm we reach a constant or a free variable, because when we form a term of elimination form no free variable in its major subterm can become bound. In particular, a normal term must either have introduction form or contain a constant or a free variable. Hence we have proved (by purely combinatorial reasoning) that, in the system without object constants, 168 R Martin-Löf a closed normal must have term of type the form Combining this with the normalization theorem, we can conclude that a closed term of one of the types shown in the left column reduces to a term of the form exhibited on the same line in the right column. 4.5. Corollary. A number theoretic function which can be constructed in the theory of types is mechanically computable. Of course, the fact that there is a not necessarily mechanical procedure for comput- ing every function in the present theory of types does not require any proof at all for us, intelligent beings, who can understand the meaning of the types and the terms and recognize that the axioms and rules of inference of the theory are consonant with the intuitionistic notion of function according to which a function is the same as a rule or method. By saying that a number theoretic function can be constructed in the theory of types, I mean that there is a closed term / of type which denotes it. (Of course, / must not contain any object constants.) Suppose that we want to find the value of the function for a certain natural number which is denoted by the numeral m. Then f(m) denotes the value of the function for this argument. But / (m) is a closed term of type ./V so that, according to what was proved in 4.4, it reduces to a numeral n. It only remains to remark that the normal form of a term can be found in a purely mechanical way, that is, by manipulating symbol strings according to rules which refer solely to their syntactical structure and not to their meaning. Similarly, having formalized the construction of the real numbers (for example, as Cauchy sequences of rationals) in the theory of types, we can prove as a corollary to the normalization theorem that every individual real number which we construct in the formal theory can be computed by a machine with an arbitrary degree of approximation. These corollaries show that formalization taken together with the ensuing proof the- oretical analysis effectuates the computerization of abstract intuitionistic mathematics that above all Bishop 1967 and 1970 has asked for. What is doubtful at present is not whether computerization is possible in principle, because we already know that, but rather whether these proof theoretical computation procedures are at all useful in prac- tice. So far, they do not seem to have found a single significant application. 4.6. Completeness of intuitionistic first order predicate logic. Consider a first order formula С containing no other logical constants than and , and let be its translation into the theory of types as defined in section 3.1.2.1. Remember that in An intuitionistic theory of types 169 order to define the translation we had to introduce, first, a type constant denoting the type of individuals, second, for every predicate constant P, a type constant with all arguments of type . , and, third, for every function constant /, an object constant. of type '. We suppose that no other object constants than these have been introduced into the theory of types. 4.6.1. Theorem. Let С be a closed first order formula. Then there is a closed term of type in the theory of types if and only if С is provable in intuitionistic first order predicate logic. This shows that the fragment of first order predicate logic determined by and is complete relative to the theory of types. Kreisel 1970 has suggested to call this property faithfulness rather than completeness since it is quite different from the property that classical first order predicate logic enjoys by virtue of Gödel's completeness theorem. The sufficiency was established already in section 3.1.2.2 where we showed how to translate a derivation с of a formula С in intuitionistic first order predicate logic into a term of type _ in the theory of types. The translation is such that is closed if and only if the derivation с contains no free individual variables and no undischarged assumptions. The necessity is a consequence of the normalization theorem and lemma 4.6.3 be- low. 4.6.2.Lemma. Lei b e a normal term of typewhose free variables are either of type or of type where A is a first order formula. Then there is an individual term a whose translation is The proof is by induction on the size of the term which, being of type . , cannot have introduction form. Hence we can take the major subterm of of its major subterm until we reach either a variable or a constant. In the first case, it must be a variable of type and we are done, and, in the second case, it must be a constant : of type , so that is of the form . By induction hypothesis, are translations of individual terms in first order logic. Hence is the translation of the individual term 4.6.3. Lemma. Let С be a first order formula and suppose that is a normal term of type whose free variables are either of type or of type where A is a first order formula. Then there is a derivation с of the formula С in intuitionistic first order logic whose translation is The proof is by induction on the construction of . Three cases have to be distin- guished. 4.6.3.1. and have the forms and Respectively. By induction hypothesis, there is a derivation in intuitionistic first order logic whose translation is Consequently, we can take 170 P. Martin-Löf с to be the derivation 4.6.3.2. and have the forms and , respectively. By induction hypothesis, there is a derivation in intuitionistic first order logic whose translation is ]. Consequently, we can take с to be the derivation in which the assumption A corresponding to the variable of type has been can- celled. 4.6.3.3. с has elimination form. Being normal, this is not possible unless it has the form where is a variable of a type which is the translation of a first order formula ß . But then the type of must be either or of the form where is a first order formula. In the first case, we can conclude from the previous lemma that must be the translation of an individual term a,-, and, in the second case, we can conclude from the induction hypothesis that must be the translation of a derivation a,- of the formula A,- in intuitionistic first order logic. Consequently, is the translation of the derivation с which is obtained by letting the assumption be followed by a sequence of elimination inferences, in the first case, a -elimination with the individual term a,- in the conclusion, and, in the second case, an application of modus ponens with A,; as minor premise. Bibliography Bishop, E. (1967), Foundations of Constructive Analysis, McGraw-Hill, New York. Bishop, E. (1970), Mathematics as a numerical language, in J. Myhill, A. Kino and R. E. Vesley, eds, 'Intuitionism and Proof Theory', North-Holland, Amsterdam, pp. 53-71. Brouwer, L. E. J. (1918), 'Begründung der Mengenlehre unabhängig vom logischen Satz vom ausgeschlossenen Dritten. Erster Teil: Allgemeine Mengenlehre', Verh. Nederl. Akad. Wetensch. Afd. Natuurk. Sect, l 12(5), 3-43. An intuitionistic theory of types 111 Curry, H. B. and Feys, R. (1958), Combinatory Logic, Vol. I, North-Holland, Amster- dam. Feferman, S. (1969), Set-theoretical foundations of category theory, in 'Reports of the Midwest Category Theory Seminar ПГ, Vol. 106 of Lecture Notes in Mathematics, Springer-Verlag, Berlin, pp. 201-247. Gentzen, G. (1933), On the relation between intuitionistic and classical arithmetic, in E. Szabo, ed., 'The Collected Papers of Gerhard Gentzen', North-Holland, Amster- dam, 1969, pp. 53-67. Gentzen, G. (1934), 'Untersuchungen über das logische Schliessen', Math. Z. 39, 176— 210 and 405-431. Girard, J. Y. (1972), 'Interprétation fonctionelle et élimination des coupures de l'arith- métique d'ordre supérieur', Thèse, Université Paris VII. Goodman, N. D. (1970), A theory of constructions equivalent to arithmetic, in J. My- hill, A. Kino and R. E. Vesley, eds, 'Intuitionism and Proof Theory', North-Holland, Amsterdam, pp. 101-120. Gödel, K. (1933), Zur intuitionistischen Arithmetik und Zahlentheorie, in 'Ergebnisse eines mathematischen Kolloquiums, Heft 4', pp. 34-38. Gödel, K. (1958), 'Über eine bisher noch nicht benützte Erweiterung des finiten Stand- punktes', Dialéctica 12, 280-287. Howard, W. A. (1969), 'The formulae-as-types notion of construction'. Privately cir- culated notes. Howard, W. A. (1972), 'A system of abstract constructive ordinals', J. Symb. Logic 37(2), 355-374. Kleene, S. C. (1952), Introduction to Metamathematics, North-Holland, Amsterdam. Kolmogorov, A. N. (1925), 'On the principle of excluded middle', Mat. Sb. 32, 646- 667. Kreisel, G. (1962), Foundations of intuitionistic logic, in E. Nagel, P. Suppes and A. Tarski, eds, 'Logic, Methodology and Philosophy of Science', Stanford Univer- sity Press, Stanford, California, pp. 198-210. Kreisel, G. (1965), Mathematical logic, in T. L. Saaty, éd., 'Lectures on Modern Math- ematics', Vol. Ill, John Wiley & Sons, New York, pp. 95-195. Kreisel, G. (1968), Functions, ordinals, species, in B. van Rootselaar and J. F. Staal, eds, 'Logic, Methodology and Philosophy of Science ПГ, North-Holland, Amsterdam, pp. 145-159. Kreisel, G. (1970), Church's thesis: a kind of reducibility axiom for constructive math- ematics, in J. Myhill, A. Kino and R. E. Vesley, eds, 'Intuitionism and Proof Theory', North-Holland, Amsterdam, pp. 121-150. Martin-Löf, P. (1971), Hauptsatz for the intuitionistic theory of iterated inductive def- initions, in J. E. Fenstad, ed., 'Proceedings of the Second Scandinavian Logic Sym - posium', North-Holland, Amsterdam, pp. 179-216. Prawitz, D. (1965), Natural Deduction, Almqvist & Wiksell, Stockholm. 172 P. Martin-Löf Prawitz, D. (1971), Ideas and results in proof theory, m J. E. Fenstad, ed., 'Proceed- ings of the Second Scandinavian Logic Symposium', North-Holland, Amsterdam, pp. 235-307. Russell, B. (1903), The Principles of Mathematics, Vol. I, Cambridge University Press, Cambridge. Scott, D. (1970), Constructive validity, in 'Symposium on Automatic Demonstration', Vol. 125 of Lecture Notes in Mathematics, Springer-Verlag, Berlin, pp. 237-275. Spector, C. (1962), Provably recursive functionals of analysis: a consistency proof of analysis by an extension of principles formulated in current intuitionistic mathemat- ics, in 'Recursive Function Theory', Vol. V of Proceedings of Symposia in Pure Mathematics, American Mathematical Society, Providence, Rhode Island, pp. 1-27. Tait, W. W. (1967), 'Intensional interpretation of functionals of finite type', J. Symb. Logic 32, 198-212. Tait, W. W. (1968), Constructive reasoning, in B. van Rootselaar and J. F. Staal, eds, 'Logic, Methodology and Philosophy of Science III', North-Holland, Amsterdam, pp. 185-199. Troelstra, A. S. (1971), Notions of reali/ability for intuitionistic arithmetic and intu- itionistic arithmetic in all finite types, in J. E. Fenstad, ed., 'Proceedings of the Sec- ond Scandinavian Logic Symposium', North-Holland, Amsterdam, pp. 369-405. 9 On storage operators Karim Nour Département de Mathématique, Université de Savoie 1 Introduction A-calculus as such is not a computational model. A reduction strategy is needed. In this paper, we consider -calculus with the left reduction. This strategy has many advan- tages: it always terminates when applied to a normalizable -term and it seems more economic since we compute a -term only when we need it. But the major drawback of this strategy is that a function must compute its argument every time it uses it. This is the reason why this strategy is not really used. In 1990 Krivine (1990b) introduced the notion of storage operators in order to avoid this problem and to simulate call-by-value when necessary. The AF2 type system is a way of interpreting the proof rules for second-order intuitionistic logic plus equational reasoning as construction rules for terms. Krivine (1990b) has shown that, by using Gödel translation from classical to intuitionistic logic (denoted by *), we can find in system AF2 a very simple type for storage operators. Historically the type was discovered before the notion of storage operator itself. Kriv- ine (1990a) proved that as far as totality of functions is concerned second-order classical logic is conservative over second-order intuitionistic logic. To prove this, Krivine intro- duced the following notions: A[x] is an input (resp. output) data type if one can prove intuitionistically (resp. . Then if A[x] is an input data type and B[x] is an output data type, then if one can prove classi- cally one can prove it intuitionistically. The notion of storage operator was discovered by investigating the property of all -terms of type where N[x] is the type of integers. Parigot (1992) and Krivine (1994) have extended the AF2 system to classical logic. The method of Krivine is very simple: it consists of adding a new constant, denoted by C, with the declaration С : which axiomatizes classical logic over intuitionistic logic. For the constant C, he adds a new reduction rule which is a particular case of a rule given by Felleisen (1987) for control operator. Parigot (1992) considered a (second-order) natural deduction system with several conclusions which is more convenient than the usual natural deduction system with the classical absurdity rule. Its computational interpretation is a natural extension of -calculus, called calculus, which preserves the main properties of -calculus and allows the modelling of control structures too. In these systems the property of the unicity of representation of 174 K. Nour data is lost, but Parigot (1993a) and Krivine (1994) have shown that storage operators typeable in AF2 can be used to find the values of classical integers. This paper studies some properties of storage operators in pure and typed Л-calculus. We present, in particular, the results of Krivine, Parigot and the author, 2 Pure and typed A-calculus Let t, M i,... , u n be -terms; the application of t to и i,... , u n is denoted by (t)u \\. .. u n . Fv(t) is the set of free variables of a -term t. The -reduction (resp. -equivalence) relation is denoted by и —> u (resp. ). If ? is a normalizable -term, we de- note by N(t) the number of steps used to go from t to its normal form. The notation a (t) represents the result of the simultaneous substitution a to the free variables of t after a suitable renaming of the bounded variables of t. We denote by the -term (и) .. . (м)и where occurs n times, and the sequence of -terms MI, ... , и„ If M = M i,... , u n, we denote by the -term Let us recall that a -term t either has a head redex (i.e. the head redex being or is in head normal form (i.e. . The notation means that v is obtained from и by some head reductions. A -term t is said to be solvable if and only if the head reduction of t terminates. If u >- D, we denote by и (и, и) the length of the head reduction between и and D. And if t is solvable, we denote by n(t) the number of steps used to go from t to its head normal form. Krivine (1990b) has shown that: Lemma 2.1 J)If then, for any substitution , and 2) If , then, for every sequence of -terms there is a w, such that , and i Lemma 2.1 shows that to make the head reduction of (resp. ofi t is equivalent to making some steps in the head reduction of M, and after making the head reduction of i (resp. of (u)tïï). The types will be formulas of second-order predicate logic over a given language. The logical connectives are . , and There are individual (or first-order) vari- ables denoted by x,y,z,..., and predicate (or second-order) variables denoted by X, Y, Z, We do not suppose that the language has a special constant for equality. Instead, we define the formula и = и (where u, v are terms) to be where У is a unary predicate variable. Such a formula will be called an equation. We denote by a ~ b the equivalence binary relation such that: if a = b is an equation, then The formula is also denoted by F\\, FI, .. ., F n —> G. For every formula A, we denote by —•A the formula A —> _L Let t be a A.-term, A a type, Г = x\\ : AI, ... ,x n : A,, a context, and E a set of equations. We define by means of the following rules the notion \"i is of type A in Г with respect to £\"'; this notion is denoted by (1) On storage operators 175 (6) (7) (8) together with the following conditions: (*) x, X have no free occurrences in and (** ) и (resp. G) is a term (resp. formula). This typed -calculus system is called AF2 (for Arithmétique Fonctionnelle du sec- ond ordre). It has the following properties (Krivine 1990a). Theorem 2.2 I) Types are preserved during reduction. 2) Typable -terms are strongly normalizable. 3 Storage operators For every и 6 N, we define the Church integer, , Let it is easy to check that £ is a -term for the successor. Let F be a -term (a function). During the computation, by left reduction of (F)6n (where may be computed as many times as F uses it. We would like to transform (F)9n to (F~)n. We also want this transformation to depend only on в п (and not F). In other words, we look for some closed Л-terms Т with the following properties: 1. For every -term and we have 2. The computation time of depends only on в„. Definition (temporary): A closed X-term Т is called a storage operator for Church integers iff for every , and for every(wher e / is a new variable). It is clear that a storage operator satisfies the required properties. Indeed, since we have , then the variable / never appears in the head position during the reduction, and we may then replace / by any -term. We will show (see Theorem 3.1 ) that it is not possible to get the normal form of . We then change the definition. Definition (temporary): A closed -term Т is called a storage operator for Church integers iff for every n e N, there is a closed -term such that for every (where / is a new variable). Krivine (1990b) has shown that, by using Gödel translation from classical to in- tuitionitic logic, we can find a very simple type for storage operators. But the term obtained may contain variables substituted by -terms u\\ u m depend- ing on . Since the -term is equivalent to n, therefore, the left reduction of ()3 (2) (4) (5) 176 K. Nour T„[UI/X\\, ..., u m/x m] is equivalent to the left reduction of and the -terms u\\, ..., u m will therefore never be evaluated during the reduction. Definition (final): A closed -term T is called a storage operator for Church inte- gers iff for every , there is a -termsuc h that for every , there is a substitution a, such that ( (where / is a new variable). Let F be any -term (for a function), and 9 n a -term -equivalent to n_. During the computation of (F)dn, may be computed each time it appears in the head position. Instead of computing (F)dn, let us look at the head reduction of . Since it is by Lemma 2.1, we shall first reduce ( to its head normal form, which is , and then computewher e = F and The computation has been decomposed into two parts, the first being independent of F. This first part is essentially a computation of , the result being т п, which is a kind of normal form of 0„. The substitutions made in have no computational significance, since n_ is closed. So, in the computation of is computed first, and the result is given to F as an argument; Т has stored the result, before giving it, as many times as needed, to any function. If we take where and and where , then we can check that for every (Krivine 1990a and Nour 1993a). Therefore T[ and TI are storage operators for Church integers. The most effective storage operators for Church integers—found by Krivine—give as a result A question arises: Can we find storage operators for Church integers which give normal forms as a result? These kinds of storage operators are called strong storage operators. We have shown (Nour 1995a) that: Theorem 3.1 Church integers do not have strong storage operators. The non-existence of strong storage operators for Church integers results from the following facts: 1. The infinity of integers: We can prove that every finite subset of Church integers has strong storage operators (Nour 1995a). 2. The representation of integers'. We can prove that we cannot create a Church integer during head reduction in the application. If we change the representation of integers, we can find strong storage operators. For every n e N, we define the recursive integer Л by induction: and . Let ; it is easy to check that í is a X-term for the successor. If we take vhere and , then, for every Therefore T' is a strong storage operator for recursive integers (Nour 1995a). 4 Directed -calculus and storage operators A closed -term Г is a storage operator for Church integers iff for every there is a -term , such that for everyi , there is a substitution cr, such that i . Let us analyse the head reduction by ?? ??????? ????????? ??? replacing each -term which comes from by a new variable. This will help us to understand better the Krivine proof of his principal storage theorem (Theorem 5.2 ) and also to justify the introduction of directed Л-calculus which allows us to find similar results in the general case. If then and ..,..„ . _ _ .. Let x n be a new variable (.*„ represents в п). (T)x nf is solvable, and its head normal form does not begin with A.; therefore it is a variable applied to some arguments. The free variables of (T)xnf are x n and /; we then have two possibilities for its head normal form: (f)S (in this case we stop) or (x n)a\\... a m . Assume we obtain (x n)a\\... a m . The variable x n represents в п , and therefore (в п)а\\... a m and , a m have the same head nor- mal form. The A.-term tn-\\[a\\/x, a^/g] comes from Qn. Let х л-1,01,02 be a new variable (x n-\\,a¡,a 2 represents \" ' ' \" The -term ((02)^-1,^,02)03 •• -a m is solvable, and its head normal form does not begin with ; therefore it is a vari- able applied to some arguments. The free variables of ((02)^-1,01,«2)аз • • - am are among , and /; we then have three possibilities for its head normal form: (f)S (in this case we stop) or (x n)b\\... b r or . Assume we obtain (*n-i,ai,a2)£i • • -b r- The variable x„_i,a,,a2 represents , and ; therefore < and i have the same head normal form. TheX-termf„_2[ai/x,ii2/g] comes from #„. Let b e a ne w variable , represents . The-ter m b\\.. .b r is solvable, and its head normal form does not begin with ; therefore it is a variable applied to arguments. The free variables of are among JEn-2,ai,a2, Xn-i,ai.a2> xn> and /; therefore we have four possibilities for its head normal form: (f)S (in this case we stop) or (xn)c\\ .. .c s or C*n_i,aba2)ci • • • °s or C*n-2,aba2)ci • • -cs- And so on. Assume we obtain (%o,dbd2)ei. ..e^ during the construction. The variable *o,di,d2 represents to[d\\/x,d2/g], and ÍQ > x; therefore (îu[d\\/x, dï/g])e\\... e* and (d\\)e\\ ... et have the same head normal form; we then follow the construction with the A-term (d\\)e\\... e^. The Л-term (T)9nf is solvable, and has (/)сл as head normal form, so this construction always stops on (/)<5. We can prove by a simple argument that i According to the previous construction, the reduction (Г)6>„/ > (f)a(rn) can be divided into two parts: a reduction that does not depend on и and a reduction that depends on n (and not on в п). If we allow some new reduction rules to have the later reductions (something like I xo,ai,a2 x fli) w e obtain a n equivalent definition fo r th e storage operators fo r Church integers: a closed Л-term Г is a storage operator for Church integers iff for every n e N, where . To prove his storage theorem (Theorem 5.2), Krivine used the sufficient condition of the last equivalence. The notion of storage operators can be generalized for each set of closed normal A-terms. Let t be a closed normal -term and T a closed A.-term. We said that Г is a storage operator for t iff there is a -term , such that for every -term , there is a substitution a, such that (where / is a new variable). Let D 178 K. Nour be a set of closed normal Я-terms and Т a closed -term. We said that Г is a storage operator for D iff it is a storage operator for every í in D. The directed -calculus is an extension of the ordinary -calculus built for tracing a normal -term t during some head reduction. Assume и is some normal -term having í as a subterm. We wish to trace the places where we really need to know what í is during the reduction of и. We will show how the directed ,-calculus allows to find an equivalent—and easily expressed—definition for the storage operators. Let У be a set of variables of pure -calculus. The set of terms of directed - calculus, denoted by , is defined in the following way: 1. If,the n 2. If ,and then 3. If, ,then 4.I f í e Л i s a normal Я-term, such that ¡ , an d a\\,... , a n then | A ЯП-term of the form [t](a\\/x\\,..., an/xn) is said to be a box directed by t. This notation represents, intuitively, the Я-term t where all free variables x\\,..., x n will be replaced by a\\,..., a n . The substitution (a\\/x\\,..., an/xn) is denoted by (a/x). A []-term of the form IMS called -redex; u[v/x] is called its contractum. A f]-term of the form [/]{a/x) is called []-redex; its contractum R is defined by induction on t: 1. If then R = ai. 2. If , then R = x. 3. If then i where 4. If í = (u)v, then R = ([и](а/х))[и](а/х). By interpreting the box [t](a\\/x\\,... ,a n/xn) by t[[ai/xi,... ,a n/x n]] (the- -term í with an explicit substitution), the new reduction rules are those that allow us to do the substitution. This kind of -calculus has been studied by Curien (1988); his a- calculus contain terms and substitutions and is intended to control better the substitution process created by -reduction, and then the implementation of the .-calculus. The main difference between the -calculus and the directed -calculus is that the first one produces an explicit substitution after each , -reduction and the second only \"executes\" the substitutions given in advance. We can therefore consider the directed -calculus as a restriction (the interdiction of producing explicit substitutions) of -calculus, a well-adapted way to the study of the head reduction. Every -term í can be uniquely written as being a variable or a redex. If Л is a variable, we say that í is a -head normal form. If Л is a redex, we say that R is the head redex of î. The notation means that v is obtained from и by some head reductions. Now we can state the theorem which gives an equivalent definition for storage op- erators (Nour and David 1995). On storage operators 179 Theorem 4.1 Let t be a closed normal -term, and T a closed -term. T is a storage operator for t iff there is a k-term r t ~ ^ t, such that •••,[tm](a m/\\m)/y m]- To prove the necessary condition we associate to every t a special substitution 50 over the boxes directed by subterms of f such that t and satisfying the following property: then . Then , Fo r the sufficient condition we use the idea given at the beginning of this section. The only difficulty is to prove that . For this we use the fact that r t does not depend on Qt. The last result allows us to find some important properties for storage operators (Nour and David 1995). Theorem 4.2 1) Let D be a set of closed normal -terms, T andT'two closed -terms. IfT is a storage operator for D, and ' , then T' is also a storage operator for D. 2) The set of storage operators for a set of closed normal -terms is not recursive, but the set of storage operators for a finite set of closed normal -terms is recursively enumerable. 3) Each finite set of normal -terms having all distinct -normal forms has a storage operator. 4)Lett be a closed normal ^-term, and T a closed, -term. IfT is a storage operator for t, then there are two constants and BT,I, such that for every 5 Storage operators in typed -calculus Each data type generated by free algebras can be defined by a second-order formula. The type of integers is the formula , where X is a unary predicate variable, 0 is a constant symbol for zero, and s is a unary function symbol for successor. The formula N[x] means semantically that x is an inte- ger iff x belongs to each set X containing 0 and closed under the successor function s. It is easy to check that, for every the Church integer и is of type and s_ is of type ). A set of equations E is said to be adequate with the type of integers iff s > and if s ; then . In the rest of the paper, we assume that all sets of equations are adequate with the type of integers. The AF2 system has the property of unicity of integer representation (Krivine 1990a). Theorem 5.1 Let : then A very important property of the data type is the following (we express it for the type of integers): in order to get a program for a function / : N —»• N it is sufficient to prove s ...... ^^ ,„ For example, a proof of l from the equations , gives a term for the predecessor in Church integers (Krivine 1990a). If we try to type a storage operator T for Church integers in the AF2 type system, we naturally find the type . But this type does not characterize the 180 K.Nour storage operators (take for example . This is due to the fact that the type does not take into account the independency of r n from в п . То solve this problem, we must prevent the use of the first as well as its subtypes to prove the second N[x]. For each formula F of A F2, we indicate by F 8 the formula obtained by putting -> in front of each atomic formula of F (F8 is called the Gödel translation of F). For exam- ple, i It is well known that, if F is provable in classical logic, then F g is provable in intuitionistic logic (Krivine 1990a). We can check that . And, in general, we have the following theorem (Krivine 1990a, Nour 1994): Theorem 5.2 If , then Т is a storage operator for Church integers. We will give some ideas for the proof of this theorem. Krivine (1990a) introduced a semantic for his system and he proved that if f is of type A then f belongs A. Since Т is o f type then Т belongs to, . With th e proper semantic interpretation of . we can check that x n belongs tc and / belongs tc This implies that ' belongs to , which gives the theorem directly from the choice of the interpretation of . We have presented (Nour 1994) a syntactical proof of this result. We prove, using only the syntactical properties of the AF2 system that the term Т satisfies the properties which we need. The storage operators given in this paper up to now give closed -terms as results. These kinds of storage operators are called proper storage operators. A question arises: Can we find a typed non-proper storage operator for Church integers? We have shown that (Nour 1993b): Theorem 5.3 There is a non-proper storage operator for Church integers T such that An example of such an operator is the following: where 6 Generalizatio n Some authors have been interested in the research on a most general type for storage op- erators. For example, Danos and Régnier (1992) have given the formula as the type for storage operators, where the operation e is an elaborate Gödel translation which associates to every formula F the formula Fe obtained by replacing in F each atomic formula X(t) by X\\(t) Xr(t) Krivine (1993) and the au- thor (Nour 1996a) have given the formula , a more general type for storage operators, where the operation G is the general Gödel translation which as- sociates to every formula F the formula F G obtained by replacing in F each atomic formula X (J) by a formula ending with . With the types cited earlier, we On storage operators 181 cannot type the simple storage operator f (i = 1 or 2). This is due to the fact that the normal form of T contains a variable v applied to two argu- ments and another v applied to three arguments. Therefore, we cannot type T because the variable v is assigned by . t ] (for example) and thus the number of v-arguments is fixed once and for all. To solve the problem, we replace N g [x] in the type of stor- age operators by another type which does not limit the number of v-arguments and only enables the generation of formulas ending with in order to find a general specification for storage operators. We assume that for every integer n, there is a countable set of special н-ary second- order variables denoted by and called -variables. A type A is called an J_-type iff A is obtained by the following rules: 1. is an -type. 2. is an-type. 3. If В is an -type, then A -> В is an -type for every type A. 4. If A is an -type, then is an _-type for every variable v. We add to the AF2 type system the following new rules: (6') (7') together with the following conditions: has no free occurrence in Г and (** ) G is an -type. We call , the new type system, and we write : Л if f is typable in _ of type A in the context Г. We define two sets of types of the AF2 type system: (the set of -positive types), and __ (the set of -negative types) in the following way: 1. If Л is an atomic type, then , and 2. If Г.and ! _ ,then , and : 3 . I f Г(resp . , then(resp . 4 . If Г , then 5. If Т , and X has no free occurrence in T, then Therefore, Г is a V-positive type iff the universal second-order quantifier appears posi- tively in T. For each predicate variable X, we associate an variable . . For each formula A of the A F2 type system, we define the formula as follows: 1. If A = R(t\\,..., tn), where R is an и-агу predicate symbol, then А^~ = A. 2. If A = X(t\\,..., tn), where X is an и-агу predicate variable, then A^ = X±(ti,...,t n). 3. If A = В -» С, then 4. If A =Vjtß,then 5. If A = VXß,then Let Г be a closed -term, and D, E two closed types of the AF2 type system. 182 K. Nour We say that Т is a storage operator for the pair of types (D, E) iff for every -term , there are -terms and such that : E, and for every i there is a substitution a, such that(wher e / is a new variable). We have the following generalization (Nour 1995d). Theorem 6.1 Let D, E be two V-positive closed types of the AF2 type system, such that E does not contain - then Т is a storage operator for the pair (D,E). The condition \"D, E are V-positive types\" is necessary in order to obtain Theo- rem 6.1. Indeed, let and T = . It is easy to check that D is not a V-positive type, t : D, and T is not a storage operator for D (Nour 1993a). This counterexample also works with the original Gödel translation and with any general Gödel translation. Theorem 6.1 allows us also to generalize the result of Krivine (Theorem 5.2) to every data type (booleans, lists, trees, product and sum of data types, etc.). 7 Pure and typed AC-calculus We add a constant С to the pure A,-calculus and we denote by ЛС the set of new terms also called XC-terms. We consider the following rales of reduction, called rules of head C-reduction: (2) for every being a A,- variable not appearing in t\\,..., t n . The rule (2) is a particular case of a general law of reduction for control operators (given in Felleisein 1987) which is For any ,C-terms t, t', we shall write ' if t' is obtained from t by applying these rules finitely many times. A C-term t is said to be -normal iff t does not contain a ß-redex. A C-term t is said to be C-solvable iff t ^c (f)t\\,... ,t n where / is a variable. We add to the AF2 type system the following new rule: This rule axiomatizes the classical over the intuitionistic logic. We call C2 the new type system, and we write I : A if / is of type Л in the context Г. In this system we have only the following weak properties (Krivine 1994). Theorem 7. 1 7J//1 : A , ana , then 2) , and •', then 3) If A is an atomic type, and : A, then t is C-solvable. In this system, the problem is: given a typed term in classical logic, what kind of program is it? We shall take the example of integers. Let us call a C-term в a classical ? ?????(1) On storage operators 183 integer if . If then we know that , and thus we know the operational behaviour of в. But when в is a classical integer, it is no longer true that Fo r e order to recognize the integer и hidden inside в (the value of в), we have to make use of storage operators. Krivine (1994) has shown that: Theorem 7.2 If , then for every n e N, there is a -term such that for every classical integer B n of value n, there is a substitution a such thai *hen The difficulties of proving this theorem (by comparison with Theorem 5.1) are: the operational characterization of classical integers and the fact that this characterization corresponds to the behaviour of typed storage operators. Theorem 7.2 cannot be generalized for the C2 system. Indeed, let (i = 1 or 2). We have and there is no ЛС- term such that for every classical integer 9 n of value n, there is a substitution a, such that (Nour 1997a). Theorem 7.2 poses many questions. For instance: 1. What is the relation between classical integers and the type N 8 [jt]? 2. Why do we need intuitionistic logic to model the storage operators and classical logic to model the control operators? 8 The M2 type system In this section, we present a new classical type system based on a logical system called mixed logic. This system allows us essentially to distinguish between classical proofs and intuitionistic proofs. We assume that for every integer n, there is a countable set of special n-ary second-order variables denoted by Xc, YC, Zc,.. •, and called classical variables. Let X be an и-агу predicate variable or predicate symbol. A type A is said to end with X iff A is obtained by the following rules: 1. X(t\\,..., t n) ends with X. 2. If В ends with X, then A —> В ends with X for every type A. 3. If A ends with X, then ends with X for every variable v. A type A is said to be a classical type iff A ends with or a classical variable. We add to the AF 2 type system the following new rules: together with the following conditions: (*) Xc has no free occurrence in and (**) G is a classical type. We call M2 the new type system, and we write : A if t is of type A in the context Г. mple In 184 K. Nour 8.1 Properties of M 2 With each classical variable Xc, we associate a special variable X* of AF2 having the same arity as Xc- For each formula A of M2, we define the formula A* of AF2 in the following way: 1. If A = D(t\\,..., tn) where D is a predicate symbol or a predicate variable, then A* = A. 2. If A = X c (ti,..., tn), then A* = -X'(fi , ... , r„). 3. If A = ß -> С, then A* = Я* -> C*. 4. If A = Vjfi (resp. A = VX5), then A* = Vjto* (resp. A* = VXB*). 5. If A =rVX c5,then A* = VX'ß*. We have the following result (Nour 1997a). Theorem 8.1 Let A be a V-positive type of AF2 and t a ß-normal КС-term. If^~M2 t '. A, then t is a normal X-term, and \\~AFÏ t : A. With each predicate variable X of C2, we associate a classical variable Xc having the same arity as X. For each formula A of C2, we define the formula A c of M2 in the following way: 1. If A = D (t i,..., tn ) where D is a constant symbol, then A c = A. 2. If A = X(?i,..., tn) where X is a predicate symbol, then A c = Xc(t\\ ,..., tn). 3. If A = В -> С, then A c = B c ~> C c . 4. If A = VxB, then A c = Vxß c. 5. If A=VXß,thenA c =VX c 5 c . As for the relation between the C2 and Ml systems, we have (Nour 1997a): Theorem8.2 Lei Abe a type of CI, and t a C-term. Then 8.2 The integers in M2 According to the results of section 8.1, we can obtain some results concerning integers in the M2 system (Nour 1997a). Theorem 8.3 Let Let n € N. By Theorem 8.1, a classical integer of value « is a closed C-term 9n such that For the classical integers we have only one operational characterization. In order to obtain this characterization, we shall need some definitions. Let V be the set of variables of .C-calculus. Let P be an infinite set of constants called stack constants. 1 We define a set of C-terms ЛСР by: 1. If .then. 2. If , and , then 3 . If, ,andi.the n ' The notion of stack constants is taken from a manuscript of Krivine. iff then On storage operators 185 In other words, iff the stack constants are in argument positions in t. We consider, on the set Л С Р, the following rules of reduction: and x being -variable and not appearing in fi,... , t n . For any , we shall write ' is obtained from t by applying these rules finitely many times. Let We have result (Nour 1997a). Theorem 8.4 Let n a classical integer of value n, and x, g two distinct vari- ables. Then 1) If n = 0, then, for every stack constant p, we have : 2) If n -ф- 0, then there is an m e N*, and a mapping I : (0,... , m] -> N, such that for all distinct stack constants po, pi,..., p m , we have (O n)xgpo >c (g)tiPr(i; (ti)pi >c (g)ti+ipr¡ (1 < i < m - 1); (tm)pm where /(0 ) = n , I(r m )=0,and Theorem 8.4 allows us to find the value of a classical integer. Let в п be a classi- cal integer of value n. Let p be a stack constant and g, x two distinct variables. If then n = 0. If not there is an m a sequence where i, and a mapping 7 : {0,... , m] -> N such that /(0 ) = 0, and Therefore J(r m) = n. 8.3 Storage operators for classical integers In the Ml system we have a similar result to Theorem 5.2 (Nour 1997a). Let Г be a closed T-term. We say that Г is a storage operator for classical integers iff for every и e N, there is a T-term such that for every classical integer в п of value n, there is a substitution a, such that (where / is a new variable). Theorem 8.5 If then Т is a storage operator for classical integers. Theorem 8.5 means that if \\~M2 Т : , then Т takes a clas- sical integer as an argument and returns the Church integer corresponding to its value. It is sufficient to do the proof of this theorem in the propositional case. The type sys- tem M is the subsystem of M2 where we only have propositional variables and con- stants. We write Г \\~м t : A if t is typable in M of type A in the context Г. Let j Theorem 8.5 is a consequence of the following theorem (Nour 1997a). Theorem 8.6 If , then for every there is an i and a XC-term т т ~ß rn_, such that for every classical integer 9n of value n, there is a substitution cr, such that for all and for and ? ????? ??????? ?? ???? ??? ????????? 186 K. Nour Indeed, if , then ... Therefore for every , there i s a n ,suc h that fo r every classical integer of value и, there is a substitution a, such that . We have ; then , and therefore .„ ,_ and Therefore n — m, and Г is a storage operator for classical integers. The proof of Theorem 8.6 uses two independent theorems: the first one (Theorem 8.4) expresses a property of classical integers and the second one (Theorem 8.7) ex- presses a property of C-terms of type Let v and / be two fixed variables. We denote by (where n is an integer, a, b two -terms, and с a finite sequence of -terms) a variable which does not appear in a, b, ~c. We have (Nour 1997a): Theorem 8.7 Let and.. There is an and a finite sequence of head reductions such that: 1 ) andwher e 2) Let Г be a closed C-term, and D, E two closed types of the AF2 type system. We say that Г is a storage operator for the pair of types (D, E) iff for every À-term there is a ,-term anda C-terrr , such that ^ r _ t : E, and for every \\~ci 0/ : D, there is a substitution a, such that i (where / is a new variable). We can generalize Theorem 8.5 (Nour 1997a) as follows. Theorem 8.8 Let D, E be two V'-positive closed types of the AF2 type system, such that E does not contain , then Т is a storage operator for the pair (D,E). 9 The -calculus 9.1 Pure and typed -calculus -calculus has two distinct alphabets of variables: the set of A,-variables x,y,z, • • -, and the set of i-variables a, ¡, x,.. . . Terms (also called -terms) are defined by the following grammar: The reduction relation of Хд-calculus is induced by five different notions of reduc- tion: The computation rules where is obtained from и by replacing inductively each subterm of the form [a]w by [a](w)v. The simplification rules then if and ???? if and On storage operators 187 (£2) . , if ot has no free occurrence in и (5з) if M contains a subterm of the form Parigot (1992) has shown that: Theorem 9.1 In -calculus, reduction is confluent. The notation means that v is obtained from и by some head reductions. The head equivalence relation is denoted by iff there is a w, such that and Proofs are written in a natural deduction system with several conclusions, presented with sequents. One deals with sequents such that: 1. Formulas to the left of \\- are labelled with -variables. 2. Formulas to the right of h are labelled with, -variables, except one formula which is labelled with a -term. 3. Distinct formulas never have the same label. Let t be a -term, A a type, Г = x\\ : A\\,..., x n : A n, and Д = ce\\ : B\\,..., u m : B m . We define by means of the following rules the notion \"i is of type A in and \". This notion is denoted by The rules are (l)-(8 ) of the AF2 type system and the following rule: (9) Weakenings are included in rules (2) and (9). As in typed Л-calculus one can define -iA as A ->_L and use the previous rules with the following special interpretation for naming _L: for a a /¿-variable, a :JL, is not mentioned. This typed A-calculus system is called FD2. It has the following properties (Parigot 1992). Theorem 9.2 1 ) Type is preserved during reduction. 2) Typable Xfi-terms are strongly normalizable. 9.2 Classical integers Let n be an integer. A classical integer of value и is a closed A,/¿-term в п such that Let x and / be fixed variables, and N xj be the set of Л/z-terms defined by the following grammar: i . We define, for each ; the set rep(u), which is intuitively the set of integers potentially represented by u: rep rep( = I\") rep(v) for each subterm of The following theorem characterizes the classical integers (Parigot 1992). Theorem 9.3 The normal classical integers of value n are the -terms of the form with without a free -variable and such that rep(u) = {n}. 188 K. Nour Let where We can check that rep(u) = {4}. Then в is a classical integer of value 4. We will now present a simple method to find the value of a classical integer. We define, for each the set val(u), which is intuitively the set of the possible values of и : val( = U val (v) for each subterm [a]v of Let M without a free -variable and a\\,... ,<x n the , -variables of и which satisfy the following: « i is the , -variable such that is a subterm of u, a¡ is the .-variable such that is a subterm of u, and We have (Nour 1997b) Lemma 9.4 For every i 1) vai(tj-i) = 2) For each subterm t ofuj, such that val(t) = 0. In particular val (u) = Using Lemma 9.1 and the fact that for each val(u), we deduce the following result (Nour 1997b): Theorem 9.5 If в is a normal classical integer of value n, then with \\ without a free [¿-variable and such that val(u) = {n}. Then to find the value of a normal classical integer „ we try the variables and the integers of the -term u. The value of в is equal to 9.3 Storage operators in -calculus Let Г be a closed term. We say that Г is a storage operator for classical integers iff for every _ j, there is a -term , such that for every classical integer B n of value n, there is a substitution a, such that (where / is a new variable). Parigot (1993a) has shown that: Theorem 9.6 If }, then Т is a storage operator for classical integers. In order to define, in this framework, the equivalent of the Ml system, the demon- stration of should not be allowed for all formulas A, and thus we should prevent the occurrence of some formulas on the right. Thus we have the following definition. LET and We add to the FD2 tvoe system the following new rules: (6') (*) (7') - (**) together with the following conditions: (#) Xc has no free occurrence in Г and (**) G is a classical type. We call Ml the new type system, and we write if í is of type A in and Let Г be a closed Л/n-term. We say that Т isa storage operator for classical integers iff for every , there is a i-term , such that for every classical integer 9n of value n, there is a substitution cr, such that (where / is a new variable). We have the following result: Theorem 9.7 // \\, then Т is a storage operator for classical integers. Bibliography Abadi, M., Cardelli, L., Curien, P. L., and Levy, J. L. (1990). Explicit Substitutions. Technical report 1176, INRIA. Barendregt, H. (1984). The lambda calculus: its syntax and semantics. North-Holland, Amsterdam. Curien, P. L. (1988). The Xp-calculi: an abstract framework for closures. Technical report, LIENS - Ecole Normale Supérieure. Danos, V. and Régnier, L. (1992). Notes sur la mise en mémoire. Manuscript. Felleisen, M. (1987). The calculi of\\ v — CS conversion: a syntactic theory of con- trol and state in imperative higher order programming. Ph.D. dissertation, Indiana University. Krivine, J. L. (1990a). Lambda-calcul, types et modèles. Massen, Paris. Krivine, J. L. (1990b). Opérateurs de mise en mémoire et traduction de Gödel. Archive for Mathematical Logic 30, 241-267. Krivine, J. L. (1991). Lambda-calcul, évaluation paresseuse et mise en mémoire. The- oretical Informatics and Applications 25-1,67-84. Krivine, J. L. (1993). Mise en mémoire (preuve générale). Manuscript. Krivine, J. L. (1994). Classical logic, storage operators and 2nd order lambda-calculus. Annals of Pure and Applied Logic 68,53-78. Krivine, J. L. ( 1996). A general storage theorem for integers in call-by-name A-calculus. Theoretical Computer Science 29,79-94. Labib-Sami, R. (1986). Typer avec (ou sans) types auxilières. Manuscript. Leivant, D. (1983). Reasoning about functional programs and complexity classes asso- ciated with type disciplines. In 24th Annual Symposium on Foundations of Computer Science 44,460-469. On storage operators 187190 K. Nour Leivant, D. (1986). Typing and computation properties of lambda expressions. Theo- retical Computer Science 44, 51-68. Nour, K. (1993a). Opérateurs de mise en mémoire en lambda-calcul pur et typé. Thèse de Doctorat, Université de Chambéry. Nour, K. (1993b). Opérateurs propre de mise en mémoire. Comptes-Rendus de l'Académie des Sciences de Paris 317-1, 1-6. Nour, K. (1994). Une preuve syntaxique d'un théorème de J.L. Krivine sur les opérateurs de mise en mémoire. Comptes-Rendus de l'Académie des Sciences de Paris 318-1, 201-204. Nour, K. (1995a). Strong storage operators and data types. Archive for Mathematical Logic 34,65-78. Nour, K. (1995b). Quelques résultats sur le ÀC-calcul. Comptes-Rendus de l'Académie des Sciences de Paris 320-1, 259-262. Nour, K. (1995e). A general type for storage operators. Mathematical Logic Quarterly 41,505-514. Nour, К. (1995d). Caractérisation opérationnelle des entiers classiques en ЯС-calcul. Comptes-Rendus de l'Académie des Sciences de Paris 320-1, 1431-1434. Nour, K. (1996a). Opérateurs de mise en mémoire et types V-positifs. Theoretical In- formatics and Applications 30-3, 261-293. Nour, К. (1996b). Storage operators and V-positive types in system TTR. Mathemati- cal Logic Quarterly 42, 349-368. Nour, K. (1996c). Entiers intuitionnistes et entiers classiques en ЛС-calcul. Theoretical Informatics and Applications 29-4, 293-313. Nour, K. (1997a). Mixed logic and storage operators. Archive for Mathematical Logic, in press. Nour, K. (1997b). La valeur d'un entier classique en À/a-calcul. Archive for Mathemat- ical Logic, in press. Nour, K. and David, R. (1995). Storage operators and directed Л-calculus. Journal of Symbolic Logic 60-4,1054-1086. Parigot, M. (1992). Л/г-calculus: an algorithm interpretation of classical natural deduc- tion. Lecture Notes in Artificial Intelligence, Springer-Verlag 624, 190-201. Parigot, M. (1993a). Classical proofs as programs. Lectures Notes in Computer Science, Springer-Verlag 713, 263-276. Parigot, M. (1993b). Strong normalization for second order classical natural deduc- tion. Proceedings of the 8th Annual IEEE Symposium on Logic in Computer Science 39-46. 10 On universes in type theory 1 Erik Palmgren Department of Mathematics, Uppsala University 1 Introduction The notion of a universe of types was introduced into constructive type theory by Martin-Löf (1975). According to the propositions-as-types principle inherent in type theory, the notion plays two roles. The first is as a collection of sets or types closed un- der certain type constructions. The second is as a set of constructively given infinitary formulas. In this paper we discuss the notion of universe in type theory and suggest and study some useful extensions. We assume familiarity with type theory as presented in, for example, Martin-Löf (1984). Universes have been effective in expanding the realm of constructivism. One exam- ple is constructive category theory where type universes take the roles of Grothendieck universes of sets, in handling large categories. A more profound example is Aczel's (1986) type-theoretic interpretation of constructive set theory (CZF). It is done by coding e-diagrams into well-order types, with branching over an arbitrary type of the universe. The latter generality is crucial for interpreting the separation axiom. The introduction of universes and well-orders (W-types) in conjunction gives a great proof- theoretic strength. This has provided constructive justification of strong subsystems of second-order arithmetic studied by proof-theorists (see Griffor and Rathjen (1994) and Setzer (1993), and for some early results, see Palmgren (1992)). At present, it ap- pears that the most easily justifiable way to increase the proof-theoretic strength of type theory is to introduce ever more powerful universe constructions. We will give two such extensions in this paper. Besides contributing to the understanding of subsystems of second-order arithmetic and pushing the limits of inductive definability, such con- structions provide intuitionistic analogues of large cardinals (Rathjen et al, in press). A third new use of universes is to facilitate the incorporation of classical reasoning into constructive type theory. We introduce a universe of classical propositions and prove a conservation result for 'Ill-formulas'. Extracting programs from classical proofs is then tractable within type theory. The next section gives an introduction to the notion of universe. The central part of the paper is section 3 where we introduce a universe forming operator and a super 1 The research reported herein was supported partly by the Swedish Research Councils for Natural Sciences (NFR) and Engineering Sciences (TFR), and partly by the EU Project Twinning: Proof Theory and Compu- tation (contract SC1*-CT91-0724 (TSTS)). 192 E. Palmgren universe closed under this operator. Section 4 summarises what is known about the proof-theoretic strength of this extension, mainly results due to M. Rathjen. In section 5 we introduce the notion of higher order universe operators. While all of the preced- ing development is predicative, it is also possible to define impredicative theories using universes. In section 6 we point out some dangers in combining such ideas with elimi- nation rules. In particular, we discuss Setzer's Mahlo universe. Finally, in section 7 we construct the classical universe. 2 Universes From an abstract point of view a type universe is simply a type of types closed under certain type constructions. Being a type of types can be formulated in essentially two ways (Martin-Löf 1984): à la Tarski, by introducing a type U of code for types and a decoding function T(-): U type or, alternatively, à la Russell by simply introducing U and identifying codes and types U type The Russell formulation should be regarded as an informal version of the Tarski for- mulation, but is too unclear when nesting universe constructions, e.g. as in the super universe. Thus we use the Tarski formulation for complete precision. Modern presentations of type theory employ a so-called logical framework (Nord- ström et al. 1990). This is a typed lambda calculus with a dependent function space construction ( -types) and a universe of types (Set, £/(•))• The types of this universe are called sets. In this framework different type theories can be specified by giving closure conditions to the sets, and by introducing constants and computation rules to types constructed from sets. Later extensions have also -types or records. We shall present here the rules for the extensions of type theory in the older, more readable style of Martin-Löf (1984), as far as possible. (In section 5 we need, however, a logical framework with -types.) In Martin-Löf's type theory two different conceptions of universes occur. The first captures the idea of reflection of the judgement forms A set and A = В into a hierarchy of universes (U n, T n) externally indexed by n = 1, 2, 3, That is, whenever A set then in some universe U n, there is a code a so that T n(a) = A, and if A = В with T n(a) = A and T n(b) = B, then , . This is as in Martin-Löf (1975; 1982) albeit there it is formulated à la Russell. The second idea, which is preferable, is uniformly to construct universes above earlier universes (hinted at in Martin-Löf (1984), p. 89). Universes as full reflections. We view the formation of the hierarchy (i/i, T\\), (Ui, Ti),... as a process. At first there is no universe. Then we introduce a universe t/i of codes for all basic sets, On universes in type theory 193 i/l set where NQ is the empty set, N\\ is the set with single element Oj, and N is the set of natural numbers. Furthermore we assume that it is closed under formation: and we also assume that (U\\, T\\ ) is similarly closed under , /, + and other set formers, if desired. Hence for every set A formed without universes there is so that At this stage there is no difference between the two versions of universes. We have that if A = В is formed without the use of universes, then for some a and b such that by the usual equalities that come with every canonical constant. Then at the next stage we introduce a new universe (i/2, TÏ) closed under the set formers П, E,.. . with new codes for all sets But i/i and T\\(x) are sets of the previous stage, so we must also introduce We have a host of new set equalities to reflect in U г'- and 1 Ч , give and since we should assume and so on for all codes for set formers. We may also express this as: is a homomor- phism with respect to set constructors, extending , and ;. At each step in the construction of the hierarchy of universes we introduce new codes and equalities between codes for sets and set equalities which can be formed. Having completed the hierarchy , we notice that any proof in the resulting system can only use finitely many universes (proofs are finite and the universes are externally indexed) and hence the reflection principle holds for both sets and set equalities. If we try to iterate this process into the transfmite we run into something like 194 E. Palmgren a universe which has infinitely many introduction rules. Thus it is impossible to formu- late an elimination rule without having some kind of internal indexing of the universes. Universes as uniform constructions. Here we do not reflect set equalities. This allows us simply to inject the codes for sets from an earlier universe into the next. We construct a hierarchy of universes (U\\, T\\), (i/2, ?2),... stepwise. Assume that (Un, T n) has already been constructed; then set and Thus tn(a) is now considered to be a canonical element in , and is regarded as a copy of a in . As an example, note that the code for is t n , We furthermore assume that i is closed under the same set formers as (Un, T n). The construction of thus depends only on the family (Un, Г„). Observe that we still reflect the judgement form A set. It seems that the idea of universes as full reflections is difficult to formulate for transfinite hierarchies. The usefulness of reflecting equalities of sets is not clear. Thus we shall only consider hierarchies of universes built using the uniform construction. Remark The formation of the next universe was formulated as an operator in the domain-theoretic model (Palmgren 1993) of partial type theory. This leads to the for- malisation of universe operators in the next section. 3 Universe operators and super universes By having universe formation as an operator and a super universe closed under this operator we may form transfinite level universes much the same way as we may form transfinite sets using an ordinary universe. The universe forming operation acts on families of sets. We can form a universe (U(A, (x)B), T(A, (x)B)) above any family of sets (A, (x)B) We assume that (U(A, (x)B), T (A, (x)B)) is closed under the usual set formers , Id. That the universe is above the family (A, (x)B) is expressed by On universes in type theory 195 Thus is a code for A in , andi s a copy of the code am A for B(a/x). If we assume that (i/o, TO) is some basic family of sets, then we can define the hierarchy of universes as follows: and let and ¡ The super universe. We now consider a universe (V, S)—the super universe—which in addition to being closed under the set formers is also closed under uni- verse formation. Moreover, we assume that it contains basic sets. The closure under the universe operator is given by Note that u(a, (x)b) and t(a, (x)b, c) are canonical elements. The term t(a, (x)b, •) injects codes from the universe U(S(a), (x)S(b}) into V. The super universe has an inductive structure and it is not difficult to formulate an elimination rule for it. Transfinite hierarchies. Examples of a transfmite set can easily be constructed using recursion and a universe (cf. Martin-Löf 1975, p. 83). Transfinite level universes are, however, more complicated to construct since they are to be given as families of sets. Consider the set of all codes for families in the super universe V In the following, let {-, •) denote pairing and p,q the first and second projection respec- tively. Define j , the base of the family coded by c, and , the family of sets over BV(C) coded by , We shall define , such that and this is achieved by 196 E. Palmgren Hence if с is a code for a universe, then w(c) is a code for the universe above c. Let со be a code for a suitable basic family of sets. By recursion we can define M\"(CO) ( i e N) as the codes for finite iterates of universes above CQ. Then is a universe of transfinite level, and it is straightforward to find its code in the super universe. 4 Proof-theoretic strength Type theory with one universe closed under the W-set, named MLi W, is proof-theoretic- ally very strong, among the theories that have so far been given a complete constructive justification. Recall that the W-set is a general inductive set former, by which one may construct the Brouwer ordinals as well-founded trees which branch over a given fam- ily of sets. A slight weakening of MLi W has the strength of Kripke-Platek set theory extended with a principle corresponding to the existence of an inaccessible cardinal (Griffor and Rathjen 1994). Independently, Setzer (1993) determined the strength of the full theory. It is interesting to note that universes give strength already without W-sets. Let and let where (<p a)a are the Veblen functions, i.e. and, for is the enumeration function for the common fixed points of the functions Aczel (1977) showed that the strength of type theory with one universe is . Hancock's conjecture (cf. Martin-Lof 1975) stated that the strength of type theory with n universes is , and was proved by Feferman (1982). From this it follows that the strength of type theory with arbitrarily many finite level universes is the limit of , i.e. Го. The latter result was achieved independently by Aczel. In a previous version of the present paper we interpreted an intuitionistic version of a theory ATR using an internally indexed hierarchy I The clas- sical version of this theory has strength (cf. Simpson 1982). Subsequently, Rath- jen has obtained sharp results for theories involving the super universe. One ingre- dient in the proof of the lower bound of the super universe is (a relativised version of) the interpretation of ATR. We summarise his results. Let MLU denote the type theory with the universe operator U of section 3 and no elimination rules for U. Let MLS be type theory with the universe operator U and the super universe closed under this operator, as in section 3, and no elimination rules. The variant of MLS where the operator U may only act on families from the super universe is called MLS . Let a be defined just as the hierarchy of Veblen functions, except that Theorem 4.1. (Rathjen 1997) (i) |MLU (ii) |MLS (Hi) |MLS On universes in type theory 197 The strength of MLS with W-types has also been determined by Rathjen (1997). We refer to Griffor and Rathjen (1994), Palmgren (1992), Rathjen et al. (in press), Setzer (1993; 1995) and the next section for further proof-theoretic results. Remark The ordinal is usually called the Feferman-Schütte bound for predicativ- ity. The proof-theorist's notion of predicativity is based on the idea that an ordinal is predicative if it can be reached by a certain autonomous progression of theories starting from Peano arithmetic. This is to be contrasted with what we could call the construc- tivist's notion of predicativity, which recognises a construction as predicative if it has a clear inductive structure, e.g. W-sets and super universes. Note for example that the theory MLS goes well beyond . Not too many theories of strength between and the Howard ordinal have been found. According to the results above, universes seem to provide natural examples of such theories. 5 Higher order universe operators The notion of universe operator can be extended to all finite orders. To formulate them we use a logical framework (Set, £7(-)) with -types. The -types are written in boldface and their associated pairing function, left and right projections are denoted by , p and q respectively. Where no confusion can arise we write A instead of El(A) to simplify the presentation. Definition 5.1 Construct an externally indexed hierarchy of types Then O n is the type of operators of order n, and Fn is the type of families of operators of order n. The theories ML\", n = 0,1,2 , — We define this sequence of theories inductively. Basic type theory with 1 and /-sets, and the basic sets NO, N\\ and N, is ML 0. We define a type theory ML\" +1 by adding to the theory ML™ the new func- tions and The pair 1 is used to construct a family of operators of order k from given families of operators of orders k,k + 1, ...,«. Thus will construct the actual universe. The constants are lifting functions analogous to I and * for the universe operator of section 3. The constants ' signify the application of an operator of level k to a family of operators of level k - 1. All these functions are canonical (constructors), except the T£. Their axiomatisation is as follows. Let .Set , . Write P for the se- quence of parameters „„,_„,...,..„,_„ . For we assume the following rules: 198 E. Palmgren We assume rules that state that is a universe closed under and / and that it contains the basic sets NO, NI and W. Below we abbreviate by i and '. . For k = 1,... , и we have the following rules for the application of operators. We introduce codes for the code sets resulting when applying oto(a,(x)b): and under the same assumptions we have the equality Set. Furthermore and under the same assumptions we have the equality This concludes the axiomatisation of Remark Note that the axiomatisation of is not minimal, since for can do the job of by letting , where B(x) is an empty family, and similarly foi etc. Example 5.2 (Universe operator) The theory ML1 is simply MLU. Clearly and is a universe above the family of sets A, B. Example 5.3 (Super universe operator) Define an operator of order 1 by letting Then i and , with Q\\ as in Example 5.2, define a super universe above the family of sets A, B. Indeed, letting \"P = NI , (x)Qi, On universes in type theory 199 A, В then corresponds to the canonical expression и (а, (x)b) of section 3, and corresponds to t (a, (x)b, z). The theory ML 2 also allows the formation of universes closed under an arbitrary prescribed family of operators. Example 5.4 Here is an example of the use of __ be defined by This gives a super universe operator from a given family /, J of (universe) opera- tors. Define from this an operator of order 2, by letting J. Let P' be the sequence , A, B. Then M = i is a universe closed under this operator as well. Let Q = and Then (Q; F, G) represents the universe of universe operators (cf. Rathjen et al., in press). There are interesting proof-theoretic applications of these kinds of theories. In the presence of W-sets the universes become type-theoretic counterparts of large cardinals. Setzer (1995) gives a type theory whose strength exceeds Kripke-Platek (KP) set theory together with a Mahlo cardinal. His universe construction is, however, impredicative, see section 6. Rathjen (1997) considers a theory MLFw which is essentially ML 2 ex- tended with W-sets and where all universes are closed under W-sets. The strength is that of a KP set theory with a Mahlo cardinal, but with restricted set induction. The corre- sponding theory without W-sets, MLF, seems considerably harder to analyse; neverthe- less its strength has been conjectured (Rathjen 1997). Rathjen et al. (in press) present an extension of Aczel's constructive set theory which encompasses constructive versions of Mahlo's 7Г -numbers. A constructive justification of this set theory is obtained by an interpretation in the type theory MLQ. This theory may in turn be interpreted in ML 3, if we expand it and its universes with W-sets. Example 5.5 (The theory ML m+1 ) To give a further example of the use of the higher operators, we show how some operator , may be internalised. Notice its mixed order. Write —the code set—and I—the decoding function. We need to lift Q to by putting 200 E. Palmgren Let _ .. be a set of parameters, where for some i and We show that Q is indeed internal to the universe given by I and We write for , respectively. Suppose that Define \\f tobe Then a straightforward calculation shows that TO I is Moreover, define to be i Then: Remark The theories ML\" were suggested by the author in October 1989. A more re- cent development is Dybjer's general scheme for inductive-recursive definitions (Dybjer, in press). It captures the super universe construction, and a further general- isation also captures ML\". The scheme was partly inspired by Mendler's (1991) cate- gorical interpretation of universes, which in turn took as a motivation the super universe of section 3. 6 Stepping into the impredicative Impredicative theories can be formulated very clearly using universes. However, such universes have no inductive structure as we shall see in two examples. Consider type theory with one universe i extended by codes for second-order universal quantification V in the following manner. Letting we adopt the introduction rules We thus add second-order quantification over each set a in U. As is well known, the second-order existential quantifier is definable from the universal quantifier. It is straightforward to see that the full comprehension principle is valid in this universe. On universes in type theory 201 We note that the universe is in some sense non-well-founded. Indeed, assume one imposes the natural elimination rule for the universe by assuming ¿/-elimination (cf. Palmgren 1992, p. 95) extended with a clause for the -case (6.1) Then we obtain an inconsistent theory with non-normalising terms. Let no and n\\ be codes for the sets NO and NI, respectively. Using (6.1) we define a term such that wherei s an arbitrary function and i . Now letting , we have Hence h((p) is a fixed point of g. Letting , , this leads to outright inconsistency, since we then obtain a set , such that If instead we take , the equation A = A —> A emerges. From this we obtain a non-terminating term, by considering it as a model of untyped lambda calculus. The problematic point with the above universe is that it occurs negatively in one of its own introduction rales. Another, proof-theoretically more interesting, example is Setzer's Mahlo universe (M, S) (Setzer 1995). Here one crucial introduction rule is where J . Similarly to the above we can prove that it is inconsistent with the natural elimination rule. This rule is analogous to the one for (Ü, T) but we have instead For any we define , and for any we define . (The particular choice of n\\ is not important, any other code would do.) Thus : i . By the natural elimination rule, there exists such that No w pu t . Then b y th e above , so, «o- Hence for some A, and analogously to the above for some B. We summarise the results as a theorem. Theorem 6.1 Let T be a type theory with either the second-order universe or Setter's Mahlo universe. Then T becomes inconsistent and non-normalising, when adding the natural elimination rules. We remark that Setzer did not himself consider an elimination rule for his universe (Setzer 1995). However, it seems reasonable from a predicative point of view to require that any set introduced in type theory should be consistent with the natural elimination rules generated by the introduction rules. 202 E. Palmgren 7 Classical universes within type theory The A-translation is a combination of Gödel's negative translation with Dragalin and Friedman's well-known syntactic translation. This translation gives an easy method for proving conservativity of ¡-sentences of many classical theories over their intu- itionistic counterpart. We shall use here a universe of classical propositions to obtain a semantic version of this method. The idea is to extend type theory with a universe of propositions for which classical logic holds. It is in a precise sense a (small) complete boolean algebra with prescribed falsity. The A-translation for the fragment of minimal logic (Berger and Schwicht- enberg 1995) has a particularly simple form. We shall make a semantic version of this translation. Our starting point is a Martin-Lof type theory with a universe of sets (U, T). Here it will be useful to think of a code as a (constructively) given infinitary formula, and the decoding T(d) as its canonical Tarski semantics. We extend this type theory with a universe of propositions for each set A. We define it as follows: The absurdity of this universe will be A, and for each set p of U we introduce a new proposition 8 p into the new universe: We assume closure only under implication, conjunction and universal quantification over small sets: We also admit proof by induction on this universe, a principle which is no stronger than recursion on an ordinary universe. This is then the semantic version of the A- translation for minimal logic. The basic results are proved similarly as in the syntactic case. On universes in type theory 203 Theorem 7.1 The universe satisfies stability and ex falso quod libet, i.e. there are constructions for and for any Proof By induction on the universe. Theorem 7.2. ( -conservation) Let , be a family of small sets over small sets R = T(r) and S = T (s). If for all small A, is true, then i l is true. Proof For any given x e R, substitute for A the set and then proceed as in the familiar syntactic proof. Note that TA (¿>) does not in general follow from T (b). It is possible to make intricate analyses for what b this is in fact the case, by generalising results from the syntactic situation. Here we only observe that ) holds whenever I(T(s), x, y) holds and that the translation of Peano's fourth axiom (n + 1 -ф. О) is valid. Moreover, the induction schemata for natural numbers and W-sets, with branching over any small family of sets, are valid in translated form. This means that in the classical universe we may use higher type arithmetic and the mentioned induction schemes. It seems to be an interesting task to investigate what further principles are valid. The semantic version of the A-translation was completely formalised using the proof support system ALF, and tested on a small program extraction problem. This was done in cooperation with U. Berger. The advantage of the semantic version is that it is possi- ble to work entirely within one theory, and that classical and constructive methods may be mixed. 8 Acknowledgements I am grateful to Per Martin-Löf for encouragement to pursue the construction of uni- verses, and to Ed Griffor and Michael Rathjen for discussions. Sections 2 and 3 formed part of my PhD Thesis. Section 7 was written (an d implemented) while visiting the Ludwig-Maximilians Universität in Munich. Thanks go to Helmut Schwichtenberg, Ul- rich Berger and Anton Setzer for their hospitality. I thank Peter Hancock and an anony- mous referee for valuable comments on the content and presentation of this paper. Bibliography Aczel, P. (1977). The strength of Martin-Löf's intuitionistic type theory with one uni- verse. In: S. Miettinen and J. Väänänen (eds) Proc. Symp. on Mathematical Logic (Oulo 1974), pp. 1-32, Report no. 2, Dept. of Philosophy, University of Helsinki. Aczel, P. (1986). The type theoretic interpretation of constructive set theory: inductive definitions. In: R. B. Marcus et al. (eds) Logic, Methodology and Philosophy of Science VII, pp. 17-49. North-Holland, Amsterdam. 204 E. Palmgren Berger, U. and Schwichtenberg, H. (1995). Program extraction from classical proofs. In: D. Leivant (ed.) Logic and Computational Complexity, Indianapolis 1994, Lec- tures Notes in Computer Science, vol. 960, pp. 77-97. Springer, Berlin. Dybjer, P. (in press). A general formulation of simultaneous inductive-recursive defini- tions in type theory. J. Symb. Logic. Feferman, S. (1982). Iterated inductive fixed-point theories: application to Hancock's conjecture. In: G. Metakides (éd.) Fatras Logic Symposium, pp. 171-196. North- Holland, Amsterdam. Griffor, E. and Rathjen, M. (1994). The strength of some Martin-Lof type theories. Arch. Math. Logic 33, pp. 347-385. Martin-Löf, P. (1975). An intuitionistic theory of types: predicative part. In: H. E. Rose and J. Shepherdson (eds) Logic Colloquium '73, pp. 73-118. North-Holland, Amsterdam. Martin-Löf, P. (1982). Constructive mathematics and computer programming. In: L. J. Cohen et al. (eds) Logic, Methodology and Philosophy of Science VI, pp. 153-175. North-Holland, Amsterdam. Martin-Löf, P. (1984). Intuitionistic Type Theory. Bibliopolis, Naples. Mendier, N. P. (1991). Predicative type universes and primitive recursion. In: Proc. Sixth Annual Symp. on Logic in Computer Science, pp. 173-184. IEEE Computer Society Press. Nordström, В., Peterson, К. and Smith, J. M. (1990). Programming in Martin-Lofs Type Theory. Oxford University Press, Oxford. Palmgren, E. (1991). On Fixed Points, Inductive Definitions and Universes in Martin- Lofs Type Theory. Dissertation, Uppsala. Palmgren, E. (1992). Type-theoretic interpretation of strictly positive, iterated inductive definitions. Arch. Math. Logic 32, pp. 75-99. Palmgren, E. (1993). An information system interpretation of Martin-Löf's partial type theory with universes. Inf. Comput. 106, pp. 26-60. Rathjen, M. (1997). The strength of some universe constructions in Martin-Löf type theory. Abstract, March 25,1997. Rathjen, M., Griffor, E. and Palmgren, E. (in press). Inaccessibility in constructive set theory and type theory. Ann. Pure Appl. Logic Setzer, A. (1993). Proof Theoretical Strength of Martin-Löf Type Theory with W-type and one Universe. Dissertation, Munich (revised version to appear in Ann. Pure Appl. Logic). Setzer, A. (1995). Л type theory for one Mahlo universe. Manuscript, September 1995. Abstract in Bull. Symb. Logic 3 (1997), pp. 128-129. Simpson, S. G. (1982). E} and n { transfinite induction. In: D. van Dalen et al. (eds) Logic Colloquium '80, pp. 239-253. North-Holland, Amsterdam. 11 How to believe a machine-checked proof Robert Pollack BRICS, l Computer Science Department, Aarhus University 1 Introduction Suppose I say \"Here is a machine-checked proof of Fermat's last theorem (FLT)\". How can you use my putative machine-checked proof as evidence for belief in FLT? I start from the position that you must have some personal experience of understanding to attain belief, and to have this experience you must engage your intuition and other mental processes which are impossible to formalise. By machine-checked proof I mean a formal derivation in some given formal system; I am talking about derivability, not about truth. Further, I want to talk about actually believing an actual formal proof, not about formal proofs in principle; to be interesting, any approach to this problem must be feasible. You might try to read my proof, just as you would a proof in ajournai; however, with the current state of the art, this proof will surely be too long for you to have confidence that you have understood it. This paper presents a technological approach for reducing the problem of believing a formal proof to the same psychological and philosophical issues as believing a conventional proof in a mathematics journal. The approach is not entirely successful philosophically as there seems to be a fundamental difference between machine-checked mathematics, which depends on empirical knowledge about the physical world, and informal mathematics, which needs no such knowledge (see section 3.2.2). In the rest of this introduction I outline the approach and mention related work. In following sections I discuss what we expect from a proof, add details to the approach, pointing out problems that arise, and concentrate on what I believe is the primary tech- nical problem: expressiveness and feasibility for checking of formal systems and repre- sentations of mathematical notions. 1.1 Outline of the approach The problem is how to believe FLT when given only a putative proof formalised in a given logic. Assume it is a logic that you believe is consistent, and appropriate for FLT. The \"thing\" I give you is some computer files. There may be questions about the physical and abstract representations of the files (how to read them physically and how 'Basic Research in Computer Science, Centre of the Danish National Research Foundation. The author also thanks Edinburgh University and Chalmers University. 206 R, Pollack to parse them as a proof), and correctness of the hardware and software to do these things; ignore them until section 3.1. My approach is to separate the problem into two subproblems: (1) deciding whether the putative formal proof is really a derivation in the given formal system (a formal question), and (2) deciding if what it proves really has the informal meaning claimed for it (an informal question). Is it a theorem? Is the putative proof really a derivation in the given formal system? This is a formal question; it can be answered by a machine. The difficulty is how can you believe the machine's answer, i.e. do you trust the proof-checking program, the compiler it was processed by, the operating system supporting it, the hardware, etc.? This is usually taken to be the crux of the problem of believing machine-checked theorems. To address this problem, you can independently check the putative proof using a simple proof-checking program for the given logic, written in some metalanguage, e.g. a programming language or a logical framework. In order to believe the putative deriva- tion is correct, you must believe this simple proof checker is correct. I have in mind a proof-checking program that only checks explicit derivations in the given logic, ver- ifying that'each step in the derivation actually follows by a specified rule of the logic; no heuristics, decision procedures, or proof search is required for checking, although these techniques may have been used in constructing the proof in the first place. Such a simple proof-checking program is a formal object that is much smaller and easier to understand than almost any non-trivial formal proof, so this approach greatly simplifies the problem 2 (see section 3.2). I am not suggesting such a simple proof checker be used to discover or construct formal proofs, only to check proofs constructed with more user-friendly tools. Since my goal is to reduce believing a formal proof to the same issues as believing a conventional proof, my favoured technique for believing the correctness of a simple proof checker is to read and understand the program in light of your knowledge of the logic being checked and the semantics of the metalanguage in which the checker is written. We should use available techniques to make this task as simple as possible, e.g. using LCF style (Gordon et al. 1979; Pollack 1995) to implement the simple checker, so very few lines of code are critical for its correctness, or using an executable spec- ification of the logic in a logical framework or generic proof checker. If the logic is simple enough, and the metalanguage has a simple enough semantics, then the sum to- tal of what you are required to read and understand is neither longer nor more difficult to understand than a conventional proof, and belief in the putative derivation is attained through your personal experience of understanding. This approach differs from the con- ventional one, of reading and understanding the proof yourself, only in being indirect, a kind of cut rule at the metalevel of the readers' understanding; rather than using personal intuition to believe a proof, you use personal intuition to believe a mechanism to check 2Conversely, .1. Moore once commented that, until Shankar did his NQTHM proof of Gödel's incomplete- ness theorem, if you wanted to believe everything checked by NQTHM, you would do better to read all the proofs than to read the code of NQTHM, as the code was longer than all the proofs. How to believe a machine-checked proof 207 proofs. If you have understood a simple proof checker, and believe it correctly checks derivations in the given formal system, then you have reason to believe the correctness of a derivation it accepts. You can also use other techniques to gain confidence in the proof. You can recheck it with another proof checker, perhaps one publicly available from a library of checkers that are refereed by experts, and that have high confidence from being used to check previous examples. If a few logics become accepted as appropriate for formalisation, and large bodies of formal mathematics are developed in these few logics, then only a few independently refereed simple proof checkers are necessary, even though users may prefer many different tools for constructing proofs in the first place. These techniques are similar to those used to gain confidence in conventional proofs, and seem to be even more reliable in the present approach. What theorem is it? Having believed that my putative proof is actually a derivation in the claimed formal system, you ask \"does it prove FLT?\" Is the meaning of the formal theorem really what is claimed? This is an informal question; it cannot be answered by a machine, as one side of the \"equivalence\" is informal. 3 You must bridge this fundamental gap by using your own understanding; you will want to consider the formal theorem in light of your understanding of the formal system (the logic) being used, any assumptions used in the proof, and all the definitions used in stating the formal theorem. The difficulty is how can you read the formal proof to decide its meaning for yourself, given the size and obscure presentation of formal proofs? This issue is sometimes overlooked in discussions of reliability of formal proof. You don't need to read the entire proof in order to believe the theorem. Given that you have reason to believe the putative proof is a correct derivation in the given logic (by independent checking), only the outstanding assumptions, the formal statement of the theorem, and the definitions used hereditarily in stating the formal theorem must be read. Although the formal proof, perhaps partially generated by machine, may contain many definitions and lemmas, these need not be read, as we trust that they are all cor- rectly formulated and used as allowed by the logic, since they are checked by our trusted proof checker. You can use the trusted proof checker to print out the parts of the formal proof you need to read. (It is necessary to trust the tool that shows us the assumptions used in the proof, as the formal proof is too big to ascertain for ourselves that these really are all the assumptions used.) Then it is up you, using your own understanding of the formal system, to decide if the formal statement means what is informally claimed. But this is anyway a subtask of believing a conventional proof; so this second subprob- lem of believing a formal proof is no more difficult than the corresponding aspect of believing a conventional proof. Having used your own understanding, you can gain confidence by discussing the problem with other knowledgeable readers, as in the first step of the approach. In the (distant?) future all the work of bridging the informal-formal gap may have been done, i.e. the gap is bridged at some foundational level. When all mathematics is done formally, using accepted formal definitions for the basic mathematical notions, then new definitions and conjectures will be stated in terms of already formal notions, and no question will arise about whether some string of symbols is really FLT. 208 R. Pollack 1.2 Related work The prototypical paper on this topic is DeMillo et al. (1979), where it is argued that \"Mathematical proofs increase our confidence in the truth of mathematical statements only after they have been subjected to the social mechanisms of the mathematical com- munity\", whereas machine-checked proofs \"cannot acquire credibility gradually, as a mathematical theorem does; one either believes them blindly as a pure act of faith, or not at all\". I agree with the first statement, but completely disagree with the second, and present the means for social mechanisms of the mathematical community to operate on formal proofs, namely independent checking. Independent checking is not a new idea. It has been discussed for increasing con- fidence in computer-based enumerative search (Lam 1990) (see section 2.2 below). It is considered the standard approach in tasks such as computing many digits of тт. It is mentioned by Cohn (1989). A proposal similar to the present paper (\"verify the proofs rather than the programs which produce them\") is made, in less detail, by Slaney (1994). There has recently been discussion of the possibility and desirability of pursuing formal mathematics (Boyer 1994; Harrison 1996). My guess is that technologies of automated proof search will be highly developed because of economic pressure for re- liable hardware and software, and these, applied as tactics to proof checking, will make formal mathematics a practical reality in the foreseeable future. This paper addresses some points necessary for this program. 2 What can we expect from a proof? All belief held by a human being is based on that person's experiences of understand- ing, and all experiences of understanding derive from perception of evidence. In cer- tain areas of discourse, like law and mathematics, there are more or less precise rules about what kind of perceptions should be accepted as evidence. No matter how precise the rules about evidence, it still depends on some operations of human consciousness to apply the rules and experience understanding or not. Without claiming anything deep about operations of human consciousness, there are some things we can say about human beliefs. 2.1 Truth If God has mathematics of his own that needs to be done, let him do it himself. Bishop (1967) We have no access to truth in any aspect of human experience, including either for- mal or informal mathematics; predictions about the world might always be falsified by experiment. Even when we formally verify that some hardware or software meets its specification, there is uncertainty about the behaviour of the physical object, since the specification is with respect to some model of the physical world, and we can never completely model the world. For me this is neither a deep claim nor a serious limitation on our practice of mathe- matics. The problem stems from too broad a notion of truth; I will restrict my comments How to believe a machine-checked proof 209 to proof, suggesting how to approach the question of whether Peano arithmetic (or ZF set theory, or the calculus of constructions (CC), etc.) proves FLT for some given defi- nitions of \"natural number\", \"addition\", etc. 2.2 Certainty At the moment you find an error, your brain may disappear because of the Heisenberg uncertainty principle, and be replaced by a new brain that thinks the proof is correct. L. A. Levin, quoted in Horgan (1993) Everyone has had the experience of understanding and believing a proof at one time, and later seeing an error in it. After such an experience, you must accept that it might happen again. Therefore the notion of certainty, like that of truth, is not of particu- lar relevance to human knowledge. This view is not always accepted in conventional mathematics, where practitioners often talk of the certainty of a (correct?) proof. For example, Lam (1990), talking about reliability of enumerative searches by computer, cautions \"Notice that the assertion of correctness is not absolute, but only nearly certain, which is a special characteristic of a computer-based result.\" (Lam's italics, but my un- derlining, to show the contrast with my belief that no knowledge is absolute.) It isn't credible that useful analysis of the probability of error caused by software bugs in big calculations is possible, and I don't think this is what readers of proofs want. What is important is how knowledgeable people working in a field attain belief. Lam is com- menting on his own proof that there do not exist any finite projective planes of order 10, which uses several thousand hours of supercomputer time, running many highly opti- mised (hence complicated) programs for different cases. It is clear that belief in such an argument is hard to come by, even with independent checking (which Lam suggests), not because it isn't \"absolutely certain\", but because there is no way for a reader to apply his or her own intuition to attain belief. As an aside, my approach does raise a possibility that enumerative searches such as Lam's proof and the famous proof of the four-colour theorem by Appel and Haken (1977), which can never be accepted as conventional proofs, might be made into formal proofs. For example, in type theory we might construct an inhabitant of the four-colour theorem by proving that some program (lambda term) correctly tests numbers for certain properties, proving that if a certain finite set of numbers have those properties then every map is four-colourable, and executing the program on that finite set (showing that two lambda terms are convertible by computation). Probabilistic proofs A red herring sometimes arises (DeMillo et al. 1979): since all proof is uncertain, why not abandon deterministic notions of proof in favour of proba- bilistic proof? Proof systems involving random choices (coin tosses) (Goldreich 1994) can have much smaller derivations than their deterministic counterparts. While they carry a probability of error, this probability is bounded, and can be reduced to any de- sired positive number. But the probabilistic nature of such systems doesn't mean you are allowed to make mistakes in applying their rules. Further, since one of the rules is that the random choices must be independent of each other, a trace of all the steps 210 R. Pollack of a probabilistic proof is not convincing at all: if I toss the coin myself I may be- lieve a probabilistic proof, but if I only see a written trace of the proof I may think the coin toss outcomes have been faked to give the desired result. Thus probabilistic approaches do not support a claim that the appropriate warrant for proof correctness is direct understanding of the proof; it is the procedure for probabilistic testing (that asks for occasional random input) that must be believed, not the proof itself, and in this indirectness probabilistic proof is similar to my suggestion of indirect checking. 2.3 Explanation Explanation is the purely informal pointing out of what the author of the proof wants the reader to see. This pointing out is a kind of abstraction, and is at least as useful for a formal proof as for an informal proof. In formal mathematics, explanation has no bearing on the correctness of a putative proof, but may be very important in the process of constructing a proof, and in the reader's work of bridging the formal-informal gap to see that the formal theorem expresses what it informally claims. 3 Some details of the approach This section treats some points that were postponed or suppressed in section 1.1, and concludes with an overview of what has been gained. 3.1 Reading the files Both parts of the approach, independent checking and understanding the statement of the theorem, require examining the proof files. Questions arise about (1) correctness of hardware and software to read the files as a long ASCII string, and (2) correctness of software to parse this ASCII string as a proof, and to pretty-print parts of it so you can read them. The former is the job of the software/hardware platform (section 3.2.2). Here I consider parsing and pretty-printing. The second part of my approach requires us to read the formula that is derived, and verify that it is really FLT. We read a concrete representation of the formula (an ASCII string), but the proof checker uses an abstract representation (an abstract syntax tree). If we don't understand the relationship between these representations, then nothing the proof checker says can be believed, no matter how trustworthy the checker is on the abstract representation. (This is often overlooked in discussing LCF style proof check- ers, where correctness of the kernel, implementing abstract proof constructors, is taken to be the only critical part of the program.) Consequently the language of our formal system must be parsable in a simple and formally explained way. Some proof tools sup- port complex user-extensible syntax, and even unparsable syntax entered using control keys and special editors. This may be helpful to users while constructing proofs and browsing libraries, but to believe such a checker, it must also support an official syntax that is parsable and printable. 3.2 Is it a theorem? How is the putative formal proof of FLT constructed? Users interacting with some proof tool (Alf, Coq, HOL, Isabelle, LEGO, NQTHM, etc.) develop a file that How to believe a machine-checked proof 211 stimulates the tool to print \"QED\". This proof script is not a formal derivation, but contains instructions to the proof tool to find a derivation, i.e. the script refers to heuris- tics, decision procedures, tactics, etc., that are particular to that proof tool. These are programs to compute derivations in the official formal system, e.g. derivable rules, or arbitrary searches that may fail (Pollack 1995). For example, many proof tools support tautology checking and equality rewriting tactics. Crucially, there is no need for you to understand any of the tactics or heuristics in order to check independently the claimed proof of FLT. In principle such tactics, when they succeed at their task, check that their results follow by official derivations: this is the definition of proof checking. The proof tool can write out the complete official derivation it constructs from the proof script. Since checking a derivation is a simple thing, you should be able to check independently this official derivation of FLT using a simple proof checker that you trust. The questions to ask are (1) is it feasible to write out the official derivation and to check it, and (2) how can you trust any proof checker? The former question is addressed in section 4; here we consider the latter. The hardware/software stack How can you have confidence in a proof just because it was machine checked? There are many layers of hardware and software involved in checking the proof of FLT. The top layer is a simple proof-checking program for some specified formal system, coded in some programming language. The bottom layer is a physical machine. Intermediate layers include compiler, linker, operating system, etc. Bevier et al. (1989) show that such a system can be formalised as a stack of abstract machines. Programming language, operating system, and hardware definitions, etc., are specifications of various interfaces in this stack, and each layer implements its specifi- cation in terms of the next layer down. In current practice, very few of these layers have formal specification, let alone verification. Every (unverified) computer system has bugs, but we have confidence in the be- haviour of a general purpose computing environment because there are many users \"testing\" the environment over time, allowing a consensus to develop. Further, lower layers of the stack are largely interchangeable, allowing for independent checking. For example, if I've coded my LCF style proof checker in SML, I can compile it using differ- ent SML implementations and run it on different operating system/processor platforms; then a proof can be rechecked without depending on any particular system platform. Similarly, we can use other simple proof checkers for the same logic that have gained a consensus of trust over time. Finally, it is unlikely that a bug in the computing platform causes a proof checker to accept a proof erroneously, and incredible that independent checks could erroneously agree.4 For these reasons, most people agree that machine checking a proof increases its reliability. But my approach calls for more than consensus by random testing; it calls for con- sensus among readers who have each attained belief by personal intuition applied di- rectly or indirectly. The top layer of the stack, the simple proof checker program itself, 4But a bug in the proof-checking program itself may cause an erroneous proof to be accepted when checked using independent platforms, so in practice we are much more interested in validating the proof- checking program than the rest of the computing environment. 212 R. Pollack can be believed by direct understanding of a small amount of code; this is discussed in section 3.2.1. That the rest of the stack is not so easy to believe is discussed in section 3.2.2. 3.2.1 How to believe a proof-checking program The top layer of the hardware/software stack is a simple proof-checking program. Its specification is a definition of the formal system to be checked, 5 and its job is to im- plement this definition in terms of the specification of the next layer in the stack, i.e. the programming language in which it is coded. We want to believe that the checking program is correct by understanding an amount of code that is small compared with the size of a formal proof, but in order to understand any code at all we must understand the semantics of the programming language it is written in, and we will use non-trivial properties of the semantics to attain belief in the checker. For example, if the checker is coded in LCF style, we are depending on a strong type correctness property of the SML definition (not just of particular SML implementations) when we claim that the type of theorems is abstract, and its constructors cannot be misused to accept non-theorems. Thus we must use a programming language with a simple formal semantics and study the properties that are needed to trust a proof checker in this language. SML is perhaps too complicated to do this seriously. The three-level approach I suggest that the \"programming language\" for the check- ing program be a logical framework, i.e. a formal metatheory, enabling precise and concrete presentations of a class of formal systems. I have in mind such formalisms as the Edinburgh logical framework (ELF) (Harper et al. 1993), Martin-Löf's framework (Nordström, et al. 1990) and Feferman's F So (Feferman 1988). These frameworks are precisely and concretely specified and are designed specifically for representing formal systems. We give an inductive definition of the logic to be checked (details vary), and either the implementation of the framework itself becomes a checker (Paulson 1994), or we program a checker in the internal language of the framework which is formally proved to be correct w.r.t. the definition (Pollack 1994; Barras 1995). The latter of these variations can be seen as an application of LCF style to type systems more expres- sive than SML (Pollack 1995) and supports LCF style tactics. For technical reasons, classical LCF tactics must be expanded to official proofs (which can be very costly) even when they are metatheoretically proved to be sound, while the suggestion of Pol- lack (1995) allows admissible rules as tactics that don't have to be computed to official proofs. This is very important for feasibility of checking. The question then arises: where will we find a believable implementation of a log- ical framework? We can use a classic LCF style implementation, with an SML-like metalanguage. Isabelle (Paulson 1994) is an example of this approach: its metalogic is coded in SML using LCF style, and you can get a proof checker for your chosen object logic by specifying it in a high-level form. Isabelle is not a perfect realization of my proposal for two reasons. First, Isabelle uses higher-order unification inside its 5 The question of whether this definition captures our informal understanding of the logic is not about correctness of the checker, but about bridging the formal-informal gap, and is treated in the second step of my approach. How to believe a machine-checked proof 213 safe kernel; I want a simpler kernel, supporting the programming of unification as a tactic. Second, owing to its style of framework, Isabelle supports derivable rules but not admissible rules of encoded object logics. This three-level approach (programming language, logical framework, object logic) places few restrictions on the object logic. There is a different proposal in the literature, called reflection (Allen et al. 1990; Harrison 1995), that collapses the framework and the object logic in order to provide admissible rules that can safely be used without expansion. However, reflection distorts the object logic, and is much harder to believe. 3.2.2 Believing the hardware/software stack and the philosophical claim It seems that a computer system (CPU, operating system, compiler, etc.) is too complex to believe by direct understanding.6 Thus the only possibility is to attempt indirect belief by verification. I think this must fail, but I want to make clear that I am not criticising verification as such; it clearly improves the reliability of computer systems. I am questioning whether verification can satisfy my goal to reduce believing a formal proof to the same psychological and philosophical issues as believing a con- ventional proof. Assume we have a verified hardware/software stack whose top layer is a simple proof-checking program. The formal-informal gap at the top of the stack has been discussed in section 3.2.1, and does not challenge the philosophical goal. I see two other problems: (1) the formal-physical gap at the bottom of the stack, and (2) believing the verification of the stack itself. At the bottom of the stack is a formal model of the behaviour of physical hard- ware, predicted by quantum mechanics and tested by experiment. Belief in machine- checked mathematics must depend on scientific theory, i.e. empirical knowledge about the physical world whose correctness cannot be believed by individual understanding. In order to believe conventional mathematics by direct understanding we must believe that our own computational platform, our nervous system, behaves correctly, e.g. that we identify symbols consistently, and that our short-term memory is correct. But there is no question of belief in conventional mathematics depending on empirical knowledge for two reasons: (1) we don't (yet) have an empirical theory of cognition, and (2) the operations we would seek to explain by such a theory are subjective, and cannot be invalidated by failure of such a theory. Thus my philosophical goal is not met for the paradoxical reason that we demand more justification for indirect belief than for direct belief, since its physical foundation includes non-subjective aspects. The verification of the stack itself is another formal proof that must be believed. Since this proof is surely too big to believe directly, we must believe it indirectly by independent checking with a trusted proof checker. But this cannot be well founded, as the problem we are now addressing is how to trust a proof checker. 7 This problem, too, will prevent meeting my philosophical goal. \"Perhaps a system architecture designed specifically for simplicity could overcome this problem. 7This might be overcome by using a very simple, directly believable, computing platform to check the verification of a more realistic platform. 214 R. Pollack The philosophical claim Subjective experience depends for its interpretation on ab- stract correctness assumptions about experience itself. In believing a formal proof in- directly by believing a proof checker, we are shifting this abstraction to some compu- tational platform outside of our consciousness. This is not simply giving up; just as we are careful about checking that our experiences are internally consistent and match with that of other people, so we are careful about the computational platform we use, and compare it with other independent platforms. Such a shift of abstraction seems unavoidable if we are ever to accept as correct a putative proof that cannot actually be checked by a person. 3.3 What theorem is it? You now have a file that you believe is a derivation in the given formal system. Is the derived formula really FLT? You must interpret the formula with your own understand- ing. This is exactly how informal mathematics is done; no matter how big the formal proof, this process must be tractable, as the formal statement of FLT is not significantly different than the informal statement. One apparent difference is that informally we don't redefine the natural numbers and all their basic operations, and prove the properties of these operations for every theorem we want to believe. Conventional mathematics rests on a basis of mathemati- cal knowledge that is previously believed, and formal mathematics must proceed in the same way, developing libraries of formal knowledge covering this mathematical basis. Such libraries should be developed, independently checked and widely used by a com- munity of mathematicians. Then we can have confidence, not only that their theorems are provable, but also that their definitions mean what they informally claim. 3.4 What have we gained, and where has it come from? I have suggested how belief in correctness of a formal proof comes from engaging our own understanding to check it (and recheck it if necessary), and from the social process of many knowledgeable readers independently checking it. The only way this differs from informal mathematics is the extra indirectness in our checking, where we allow a machine to do the mechanical steps of pattern matching, substitution, etc. This extra indirectness is not a trivial matter: because of it we allow more things as proofs, e.g. derivations that are too big, or too combinatorially complicated, to be checked by a person, as mentioned in section 2.2. An advantage hinted at above is that proofs in the same logic can be shared by different proof checkers for that logic if a standard syntax can be found (or mechanical translations believed), because the official proofs don't depend on the tactics that are particular to individual proof tools. In current practice this idea is a can of worms, and the phrase \"in the same logic\" causes experts in the field to roll on the floor with laughter. However, alternative suggestions such as using cryptographic means to certify that a theorem has been checked by some proof tool (Grundy 1996) break the primary abstraction: the only way a proof checker can accept a theorem as proved is actually to check a proof of it. It is necessary to restrict the notion of \"proof-checking program\" to programs that How to believe a machine-checked proof 215 actually check derivations in some given formal system, and to restrict the acceptable formal systems by criteria of feasibility of communicating and checking official deriva- tions (section 4). The eschewing of absoluteness is crucial to my argument. This is obvious, since absolute correctness cannot be attained by any means at all. However, some criticism of formalisation seems based on the subtext that formal proof is not good enough since it cannot guarantee correctness. Formal proof can attain higher confidence than conven- tional proof, and can do so for more arguments. 4 About feasible formalisation While correctness of derivations is defined ideally in conventional logic (e.g. the size of a derivation has no bearing on its correctness 8), we are only interested in actually checked derivations. 4.1 Presentations of formal systems For the purpose of formal mathematics, we are sensitive to properties of a formal system such as how large or complicated it is, for two distinct reasons: (1) we must understand a logic in order to believe a theorem it proves, and (2) its derivations must be feasible to check. Thus it is the presentation of a formal system that interests us, not just the consequence relation it defines. How to believe a formal system We are interested in believing mathematical state- ments from formal proofs, so we must be able to read and understand the formal system we are checking; this is an essential part of bridging the gap between a formal property and our informal belief. From this perspective, various presentations of first-order logic (FOL) are suitable formal systems: there are few rules, they are organised around use- ful principles (introduction, elimination), and it is widely studied and accepted. On the other hand, the Nuprl logic (Constable et al. 1986) is less satisfactory in this regard, as it has many rules, and some complicated side conditions (e.g. the Arit h rule). By metamathematical study of a complex formal system, we may see how it is related to some simpler or better known system. For example, in 1987 I struggled with ELF (with three classes of terms, five judgements and seventeen rules) until I realised it translates into a subsystem of CC (with one class of terms, two judgements and eight rules). One theme of this paper is using computers as a tool to bridge the gap between a large formal object and our informal understanding of it; since formal systems can themselves be studied mathematically in simpler metasystems (e.g. logical frameworks), we can apply the same technique to gain understanding of a formal system that is otherwise too large or complicated by formally proving some of its properties. Of course there are limitations to this approach, and system presentations that are too complex may not be formalisable at all. For example, is Nuprl formalisable? There is no sharp line between what is taken to be a formal system and what is not. 8But both Hubert and Wittgenstein require a proof be surveyable, or \"given as such to our perceptual intuition\", i.e. a feasible object. 216 R. Pollack Formal systems that are feasible to check The second reason we care about inten- sional properties of a formal system is that we actually want to check derivations of non-trivial statements, so the size of derivations, and more generally the feasibility of checking derivations, is important. In section 4.2 I discuss styles of proof for feasi- ble checking. Here I am interested in the formal system itself, and finding alternative presentations deriving the same judgements with better intensional properties: smaller derivations, or ones that are easier to check. More generally, we can look for a different formal system (different language, deriving different judgements) that allows us more feasibly to check the original system in some indirect way. Two things can make a for- mal system computationally expensive to check: the derivations can be big and the side conditions (non-recursive premises) can be expensive to check. As an example of big derivations, the Gentzen cut-free system for FOL is completely infeasible. It is well known that adding the cut rule does not change the derivable judge- ments and allows much smaller derivations; the system with cut is a better presentation (for formal mathematics) of the same consequence relation. Section 3.2.1 discusses how a simple proof checker can support meta-theoretic extensibility by adding admis- sible rules (such as cut) to a logic. Another way to reduce the size of derivations is to eliminate duplicate subderiva- tions. In a derivation tree, subderivations may have repeated occurrences at different places in the tree. By using a linear presentation of derivations, where each line names the previous lines it depends on, only one occurrence of each subderivation is required; the indirectness of naming lines allows sharing. 9 Extending a formal system with defi- nitions allows a similar kind of sharing. In the cases just mentioned, we depend on ad hoc identification of common substructures by the user, but some formal systems dupli- cate work in such a uniform way that we can give an alternative presentation that shares some common substructures by construction. Martin-Löf (1971) gives an algorithm for type synthesis that transforms official derivations to avoid duplication of context valid- ity checking. This idea is used by Huet (1989) in the constructive engine, and abstractly explained and proved by Pollack (1994, sec. 4.4.10). The other computational expense in checking a formal system is the side conditions. For example, in CC the rule of type conversion has convertibility of two well-typed terms as a side condition. This is decidable, but certainly not feasible in general, so nei- ther is proof checking. For the purpose of independent checking we can trade derivation size for computation of side conditions. For example, if I have constructed some proof in CC, I can annotate the proof with the conversion paths found by my proof checker, which must be feasible if I did actually check the proof. (However, the size of the an- notations may be prohibitive; we must work to find good annotations.) To recheck the proof independently, your checker need only follow the annotations (checking that they are legal), not discover a conversion path for itself. In this way, independent checking doesn't depend on heuristics for feasibility any more than for proof discovery. Annotation of judgements can allow smaller derivations: with annotation, a full 9This interesting way of viewing linear derivations was pointed out to me by Harold Simmons. Automath used naming of expressions, lines, and contexts to avoid duplication. How to believe a machine-checked proof 217 derivation of a judgement may be mechanically constructed from the judgement itself so full derivations don't have to be constructed or communicated. This idea under- lies the use of decidable type checking as a tool for proof checking; the proof terms are annotations that can be expanded into full derivations. Equivalently, we can think of omitting parts of official derivations that can be mechanically reconstructed, e.g. in CC, terms are essentially derivations with instances of the conversion rule and variable lookup elided. There is a tradeoff: the more information we elide from derivations (making them smaller, so easier to communicate) the more has to be mechanically re- constructed (so making them more difficult to check). 4.2 Feasible formal proofs In the preceding section I discussed choosing formal systems that are suitable for ac- tual checking. This section discusses how to make formal proofs, and more generally, whole bodies of formal mathematics, suitable for actual checking. In programming it is well known that there are feasible functions with infeasible implementations, e.g. the natural recursive defmtion of the Fibonacci function is exponential in its input, while an alternative definition is linear. Analogously, even a well-behaved formal system will have proofs that are infeasible because of proof style. For example, if ack is the Ack- ermann function, trying to prove ack(lOO) — ack(lOO) = 0 by computing ack(lOO) is hopeless, while proving \"in.n — n = 0 is trivial, and gives a trivial proof of the goal. Representation In proof, just as in programming, unsuitable representation of the objects of discourse is a cause of unfeasibility. This is especially so because we are used to representations from conventional mathematics, which were never intended to be used in actual formalisation. When formalising a mathematical notion we make choices about representation, but there is no reason to believe there is a single \"best\" representation that leads to natural statements and short proofs. We can make several definitions for a concept, prove something about their relationship, and move between them as convenient; this is done implicitly in informal presentation. Also note that our choice of representations is constrained by our underlying formal system (e.g. FSo cannot express generalized induction, while Martin-Löf's framework can), and this may be a reason for choosing one framework over another. An example is the use of unary vs. base representation for natural numbers. We probably want to use unary representation as the official definition of the naturals, and base representation for actual computation, e.g. the computational content extracted from constructive proofs. In order to do this, elementary school arithmetic must be formalised, i.e. the correctness of various algorithms for arithmetic operations on base representation numbers. An often mentioned example of a notion that is hard to reason about formally is binding, and there are many representations of A terms in the literature, including naïve variable names (with or without a total ordering on variables), de Bruijn indexes, higher-order abstract syntax, an axiomatic approach (Gordon and Melham 1996), and an approach using distinct classes of free and bound names (Coquand 1991; McKinna and Pollack 1993). These representations are not all \"isomorphic\", e.g. some distin- guish between «-equivalent terms, some do not. They have different theorems, e.g. a 218 R. Pollack presentation of type theory using free and bound names (McKinna and Pollack 1993) has a thinning lemma which is close to the informal statement, while one using de Bruijn indexes (Barras 1995) requires explicit variable lifting. By formalising the relationship between various representations, theorems can be stated and proved in natural forms, and used in different forms when needed. It may not be obvious what the official formalisation of some concept should be (e.g. are de Bruijn terms the \"real meaning\" of A, terms, or just a convenient representation?), but formal mathematics doesn't have to split hopelessly over such questions. As long as your favourite definition can be shown to be appropriately related to other definitions in the formal literature, you can use existing results. Even what I have said about new and different representations for mathematical no- tions is too restricted. We can look for entirely new ways to do mathematics that are especially suited for formalisation. An example of this is the use of formal topologi- cal models that has recently received interest in the type theory community. Persson (1996) describes the formalisation of a completeness theorem for intuitionistic first- order logic using formal topological models. Coquand (1995) proposes a program of proof-theoretic analysis of non-effective arguments using formal topological models. Such problems seemed impossible to formalise until this approach was developed. 4.3 The business of formal mathematics Many people who pursue formal mathematics are seeking the beauty of complete con- creteness, which contributes to their own appreciation of the material being formalised, while to many outside the field formalisation is \"just filling in the details\" of conven- tional mathematics. But \"just\" might be infeasible unless serious thought is given to representation of both the logic of formalisation and the mathematics being formalised. This can be viewed as a hassle, or as the business of formal mathematics. The latter view leads us to be interested in areas of feasibility and expressiveness of formal sys- tems and the power of formal systems to represent algorithms (Cardone 1995; Colson 1991; Fredholm 1995), and to study seriously formal representations of mathematical notions. Bibliography Allen, S. F., Constable, R. L., Howe, O. J. and Aitken, W. E. (1990). The semantics of reflected proof, LICS Proceedings, IEEE. Appel, К. and Haken, W. (1977). Every planar map is four-colourable, Illinois Journal of Mathematics xxi(84): 429-567. Barras, B. (1995). Coq en coq, Master's thesis, DEA Informatique, Mathématiques et Applications, INRIA-Rocquencourt. Bevier, W., Hunt, W., Moore, J. and Young, W. (1989). An approach to systems verifi- cation, Journal of Automated Reasoning 5(4): 411-428. Bishop, E. (1967). Foundations of Constructive Analysis, McGraw-Hill, New York. How to believe a machine-checked proof 219 Boyer, R. (1994). A mechanically proof-checked encyclopedia of mathematics: Should we build one? Can we?, in A. Bundy (ed.), CADE-12, Nancy, LNAI 814, Springer- Verlag. Cardone, F. (1995). Strict fmitism and feasibility, in D. Leivant (ed.), Logic and Com- putational Complexity. Proceedings, 1994, LNCS 960, Springer-Verlag. Cohn, A. (1989). The notion of proof in hardware verification, Journal of Automated Reasoning 5(2): 127-140. Colson, L. (1991). Représentation Intentionnelle d'Algorithmes dans les Systems Fonc- tionnels: Un étude de Cas, PhD thesis, University of Paris VIL Constable, R. L., et al. (1986). Implementing Mathematics with the Nuprl Proof Devel- opment System, Prentice Hall, Englewood Cliffs, NJ. Coquand, T. (1991). An algorithm for testing conversion in type theory, in G. Huet and G. D. Plotkin (eds), Logical Frameworks, Cambridge University Press. Coquand, T. (1995). Formal topology and constructive type theory, Talk at Twenty Five Years of Constructive Type Theory, Venice. DeMillo, R., Lipton, R. and Perlis, A. (1979). Social processes and proofs of theorems and programs, Communications of the ACM 22: 271-280. Feferman, S. (1988). Finitary inductively presented logics, Logic Colloquium '88, Padova, North-Holland, Amsterdam. Fredholm, D. (1995). Intensional aspects of function definitions, Theoretical Computer Science 152: 1-66. Goldreich, О. (1994). Probabilistic proof systems (a survey), Technical Report RS-94- 28, BRICS, Aarhus Univ. Gordon, A. and Melham, T. (1996). Five axioms of alpha conversion, in J. Von Wright, J. Grundy and J. Harrison (eds), Theorem Proving in Higher Order Logics, TPHOL, Turku, Finland, LNCS 1125, Springer-Verlag. Gordon, M., Milner, R. and Wadsworth, C. (1979). Edinburgh LCF: A Mechanized Logic of Computation, LNCS 78, Springer-Verlag. Grundy, J. (1996). Trustworthy storage and exchange of theorems, Technical report, Turku Centre for Computer Science (TUCS), Lemminkäisenkatu 14 A, FIN-20520 Turku, Finland. Harper, R., Honsell, F. and Plotkin, G. (1993). A framework for defining logics, Journal of the ACM 40(1): 143-184. Preliminary version in LICS' 87. Harrison, J. (1995). Metatheory and reflection in theorem proving: A survey and cri- tique, Technical Report CRC-053, SRI Cambridge, UK. Harrison, J. (1996). Formalized mathematics, Technical report, Turku Centre for Com- puter Science (TUCS), Lemminkäisenkatu 14 A, FIN-20520 Turku, Finland. Horgan, J. (1993). The death of proof, Scientific American pp. 74-82. Huet, G. (1989). The constructive engine, in R. Narasimhan (éd.), A Perspective in Theoretical Computer Science, World Scientific Publishing, Singapore. Commemo- rative Volume for Gift Siromoney. 220 R. Pollack Lam, С. (1990). How reliable is a computer-based proof?, The Mathematical Intelli- gencer 12(1): 8-12. Martin-Löf, P. (1971). A theory of types, Technical Report 71-3, University of Stock- holm. McKinna, J. and Pollack, R. (1993). Pure Type Systems formalized, in M. Bezem and J. F. Groóte (eds), TLCA'93, Utrecht, LNCS 664, Springer-Verlag. Nordström, В., Petersson, К. and Smith, J. (1990). Programming in Martin-Löf s Type Theory. An Introduction, Oxford University Press. Paulson, L. C. (1994). Isabelle: A Generic Theorem Prover, LNCS 828, Springer- Verlag. Persson, H. (1996). Constructive Completeness of Intuitionistic Predicate Logic: A Formalisation in Type Theory, Chalmers University of Technology and University of Göteborg, Sweden. Licentiate Thesis. Pollack, R. (1994). The Theory of LEGO: A Proof Checker for the Extended Calculus of Constructions, PhD thesis, University of Edinburgh. Pollack, R. (1995). On extensibility of proof checkers, in P. Dybjer, B. Nordstrom and J. M. Smith (eds), TYPES'94, Bastad, June, LNCS 996, Springer-Verlag. Slaney, J. (1994). The crisis in finite mathematics: Automated reasoning as cause and cure, in A. Bundy (ed.), CADE-12, Nancy, LNAI 814, Springer-Verlag. 12 Building up a toolbox for Martin-Löf's type theory: subset theory Giovanni Sambin and Silvio Valentini Dipartimento di Matemática Pura ed Applicata, Université di Padova a Per Martin-Löf maestro ed amico 1 Introduction Beginning in 1970, Per Martin-Löf has developed an intuitionistic type theory (hence- forth type theory for short) as a constructive alternative to the usual foundation of math- ematics based on classical set theory. We assume the reader is aware at least of the main peculiarities of type theory, as formulated in Martin-Löf 1984 or Nordström et al. 1990; here we recall some of them to be able to introduce our point of view. The form of type theory is that of a logical calculus, where inference rules to derive judgements are at the same time set-theoretic constructions, because of the \"propositions-as-sets\"1 interpretation. The spirit of type theory—expressing our in- terpretation in a single sentence-—is to adopt those notions and rules which keep total control of the amount of information contained in the different forms of judgement. We now briefly justify this claim. First of all, the judgement asserting the truth of a proposition A, which from an intuitionistic point of view means the existence of a verification of A, in type theory is replaced by the judgement a e A which explicitly exhibits a verification a of A. In fact, it would be unwise, for a constructivist, to throw away the specific verification of A which must be known to be able to assert the existence of a verification ! The judgement that A is a set, which from an intuitionistic point of view means that there exists an inductive presentation of A, is treated in type theory in a quite similar way (even if in this case no notation analogous to a e A is used) since the judgement A set in type theory becomes explicit knowledge of the specific inductive presentation of A. In fact, the rules for primitive types and for type constructors are so devised that whenever a judgement A set is proved, it means that one also has complete information on the rules which describe how canonical elements of A are formed. Such a property, which might look like a peculiarity of type theory, is as a matter of fact necessary in order 'Called \"formulae-as-types\" in Howard 1980. A brief note on terminology is necessary here: we use \"set\" exactly as in Martin-Löf 1984, while \"category\" in Martin-Löf 1984 is replaced here with \"type\" as in Nordström et al. 1990. 222 G. Sambin and S. Valentini to give a coherent constructive treatment of quantifiers. Consider for instance universal quantification, and take it for granted that an intuitionistically meaningful explanation of universal quantification is possible only for domains with an inductive presentation, that is for what have been called sets above (by the way, this is the reason why the distinction between sets and types is so basic in type theory, see Martin-Löf 1984). Then the pure knowledge that A is a set is sufficient to say that universal quantification over A gives rise to propositions; however, it would be unwise to forget which specific rules generate A inductively, since, in general, a method verifying a universally quantified proposition over A can be produced, by means of an elimination rule, only by direct reference to the method by which A is generated. Summing up, we see not only that type theory is inspired by the principle of control of information, but also that the same principle should be at the base of any coherent treatment of sets and propositions, if it has to be both intuitionistic and free of waste. Coming back to the formalism in which type theory is expressed, one can see that the principle of keeping control of information is revealed also at the level of syntax, since most inference rules are formulated in a fully analytic style; that is, everything which appears in the premises is present somehow also in the conclusion. A consequence is, for instance, that the derivation of a judgement a e A is so detailed that a is ipso facto a program which satisfies the requirements specified by A. This is why type theory is particularly interesting for computer science. However, our experience in developing pieces of actual mathematics within type theory has led us to believe that \"orthodox\" type theory is not suitable because its control of information is too strict for this purpose. In fact, the fully analytic character of type theory becomes a burden when dealing with the synthetic methods of mathematics, which \"forget\" or take for granted most of the details. This, in our opinion, could be the reason why type theory has generated, up to now, more interest among logicians and computer scientists as a formal system than among mathematicians as a foundational theory. We claim that there is no intrinsic reason why it should remain so, and that actually it is only a matter of developing a stock of \"utilities\": that is, of building up a toolbox which covers the territory between the basic formalism and mathematical practice; after all, this happened for classical set theory ZF long ago. In other words, the situation seems analogous to that of a programmer who, maybe because of a particular skill with the machine language, has not yet developed those higher level constructs and languages which allow him or her to save time and mental energy, and thus in the end are necessary to free the mind for a common human (i.e. abstract) comprehension. So our general aim is to build up those tools, that is definitions and rules, which \"forget\" some information, and thus allow a higher level of abstraction, which can make type theory more handy and suitable to work out (intuitionistic) mathematics based on mathematical intuition, as it has been and should be. 1.1 Content Here, completing the work first announced in Sambin and Valentini 1993, we make a substantial step in the direction stated above and show how to develop a predicative Building up a toolbox for Martin-Löf's type theory: subset theory 223 theory of subsets within type theory. 2 A few years' experience in developing topology in the framework of type theory has taught us that a more liberal treatment of subsets is needed than what could be achieved by remaining literally inside type theory and its traditional notation. In fact, to be able to work freely with subsets in the usual style of mathematics one must come to conceive of them like any other mathematical object (which technically means for instance that the judgement that something is a subset can be taken as an assumption) and have access to their usual apparatus (for instance, union and intersection). Subset theory as developed in Nordström et al. 1990 does not meet the above de- mands since, being motivated by programming, its aim is different. We could say, in fact, that the aim of Nordström et al 1990 is to apply the usual set constructors of basic type theory to a wider notion of set, which includes sets obtained by comprehension over a given set; the price they have to pay is that the justification of the validity of rules for sets must be given anew. The same price must be paid whenever the basic type theory is modified; another example is the recent Turner 1997. The way out is to adopt the simple idea that it is not compulsory that a subset be a set. Then one is free to define subsets in a natural way as propositional functions (as first suggested in Martin-Löf 1984, p. 64, and explicitly adopted in Sambin 1987), and then to introduce the new notion of element of a subset, in terms of which the other standard notions, like inclusion and extensional equality, arbitrary unions and intersections, singletons and finite subsets, quantifiers and functions defined on subsets, can also be defined. The resulting subset theory is a sort of type-less set theory localized to a set and we have experienced that it is sufficient for instance for the development of topology. We prove that all of this can be done in type theory without losing control, that is by \"forgetting\" only information which can be restored at will. This is reduced to the single fact that, for any set A, the judgement A true holds if and only if there exists a such that a e A, and it can be proved once and for all, see Valentin! 1998; this is the price we have to pay to justify our approach. Since for all notions related to subsets we adopt essentially the standard notation, the result is that at first sight a page of mathematics written using subset theory looks like a page of standard mathematical writing, and one might easily overlook or forget the underlying substantial novelty, namely that everything is directly formalized in type theory. Far from being a drawback, this is in a sense our main intention, since it would show that one can develop an intuition free from the underlying formalism. 1.2 Philosophical motivation The attitude illustrated so far in this introduction can be seen as the specific outcome of a more general philosophical position (cf. Sambin 1991) when applied to type theory, and the results we prove can be seen as fragments of a general program (cf. Paulus Venetus 1993) not necessarily bound to type theory. Here we describe briefly both the philosophical position and the general program in the form of some principles, just enough to be able to state the connection with the problem of foundations. 2The second step should be on quotient sets, or abstract data types, or setoids. 224 G. Sambin and S. Valentini To build up an abstract concept from a raw flow of data, one must disregard inessen- tial details; in other words, to simplify the complexity of concrete reality one must idealize over it, and this is obtained by \"forgetting\" some information. To forget in- formation is the same as to destroy something, in particular if there is no possibility of restoring that information, like when the magnetic memory of a disk is erased. So to abstract involves a certain amount of destruction; our principle is that an abstraction is constructive, that is a reliable tool in getting knowledge which is faithful to reality, not when information is kept as much as possible, but when it is \"forgotten\" in such a way that it can be restored at will at any moment. This after all is the test to show that an abstraction does not lead astray from reality; that is, that it preserves truth. It is clear that the first step, and often the only one, to be able to restore what has been \"forgotten\" is to know, to be aware of, what has been forgotten, and to keep con- trol of it. So the second principle is that constructivism does not consist of an a priori self-limitation to full information, which would tie constructivism with reluctance to ab- straction (as was the case around the 1920s when finitism and intuitionism were some- how identified), but rather in the awareness of the destruction which has been operated to build up a certain abstract concept. When it comes to mathematical terms, awareness of what has been destroyed or forgotten can sometimes be put in objective terms, and then it takes the form of a method by which the previous state can be restored. If T' is a theory obtained from a more basic theory T by adding some more abstract constructs and their rules, then a method must be supplied which allows us to transform whatever proof in T' into a proof within T with the same computational content. This allows us to \"forget safely\", since it guarantees that faithfulness to the more concrete level of T is not lost by the more abstract concepts of Г . This, we believe, is the only reasonable way for a constructivist to extract a philo- sophical and mathematical value out of Hubert's program. To obtain a foundation which justifies itself, in Hubert's view it is necessary to rely on a part of mathematics, called real mathematics, which has to be safe beyond any doubt and without any proof. In Hubert's conception this is identified with finitistic mathematics, that is manipulation of concrete objects; here, instead, real mathematics is identified with type theory, which is of course far richer than finitistic mathematics but still serves the purpose. In fact, on one hand the contextual explanation of judgements and rules and on the other hand its interpretation as a programming language (the modern \"manipulation of concrete objects\") indeed make it reliable beyond doubt and without any proof. Hubert was right, of course, in saying that mathematics cannot be restricted to real mathematics; in fact, even the most radical constructivist certainly uses more abstract notions or ideas, even if they do not appear in his or her communications. But which abstract notions can be accepted? We here propose an answer. It is well known that Hubert's view imposes no limitation, as long as the consistency of the formalism in which ideal mathematics is expressed is proven within real mathematics. This cannot be accepted by a constructivist, since a consistency proof is not enough to restore, once and for all, the constructive meaning, that is faithfulness to the concrete reality of com- putations. After all, even classical logic is consistent, and with a finitistic proof! So Building up a toolbox for Martin-Löf s type theory: subset theory 225 the program is to analyze, case by case, how a certain abstract notion is linked with real mathematics; when it is clear which concrete aspects are forgotten and how they can be restored by a suitable method, then that abstract notion can be used freely and safely. In this paper we show how this is possible for the theory of subsets, and thus we accomplish a fragment of the constructive version of Hubert's program, which we have called the Camerino program after the place where we spoke about it for the first time (see Paulus Venetus 1993). The aim is, paradoxically, to save the intuition of an intu- itionist from the rigidity of formal systems by supplying safe bridges between intuition and computation. 2 Reconstructing subset theory In classical mathematics a subset U of a set S is usually defined to be a set such that if then . Importing this definition into type theory as it stands, however, would give a notion of subset not general enough to include all examples of what is undoubtedly to be considered a subset. In fact, if S is a set and U : (x : S) prop is a prepositional function 3 over S, then we surely want the collection of elements of S satisfying U, usually written , to be a subset of S. In ZF, would be a set, by the separation principle; in type theory, however, no form of the sep- aration principle is justified, since in general there are no rules stating how the canon- ical elements of the collection are formed. In fact, a is an element of [x e S\\ U(x)} if a 6 5 and U(a) is true, that is if there exists b s.t. , but this form of judgement is not one of the four forms of judgements considered in type theory and hence there is no canonical way to reach the conclusion that such b exists. For example, if U(x) is the property \"the Turing machine with index x does not stop on input x\", then there are no effective rules to generate Thus, the conclusion is that we want to be a subset of S for any property Í/, but also that it does not need to be a set. A second observation is that in ordinary mathematics, operations like union and intersection are freely defined on the class of all sets, while at the opposite extreme in type theory there is no operation of union or intersection in the ordinary sense available on sets. In fact, the result of any operation of set formation gives rise to a set whose elements are specific to the constructed set, and thus, for instance, we could not have a common statement like a iff and , because ifwer e a set constructor then would be a set different from S and T, and hence its elements could not be in common with S and T. As we will soon see, however, such set-theoretic operations can easily be defined on subsets of a set, as soon as we do not require a subset to be a set. 2.1 A constructive notion of subset We are thus led to take the step of relaxing the requirement that a subset be a set. There- fore a subset will not have canonical elements, nor rules of elimination or of equality. Two ways of defining subsets are traditionally available, which do not require a 3Which means that U applied to x, for is a proposition, written U(x) prop [x : S]. 226 G. Sambin and S. Valentini subset to be a set. The first is that a subset of S is given by a property U(x) with x ranging over S; while in a classical perspective it can be conceived that there are many more subsets than properties, from a constructive point of view there is no sense in assuming the existence of a subset unless we can specify it, namely by a property. Thus the conclusion would be that a subset U of S is nothing but a prepositional function U over S. The second conception of subset of S, namely as a function / : S -» {0, 1}, usually called characteristic function, arrives in the end at the same conclusion, as we now see. Classically, any function / : S -> {0,1} gives rise to a property over S, namely the property /00 = 1, and, given a property U(x) over S, the associated function is If we transfer this as it stands into type theory, we obtain a notion of subset which is too narrow. In fact, owing to the different notion of function, the above argument, when properly translated in type theory, gives a bijective correspondence between functions S 1 —> {0,1} and decidable propositional functions over S (for a detailed proof, see for instance Valentini 1996). However, in the classical conception the above definition of / y can be seen just as a different way of denoting the propositional function U itself. In fact, classically a proposition is just a way to denote a truth value (cf. Frege 1892), so {0, 1} can be identified with the set of values of propositions. Under this reading, the intuitionistic analogue of a characteristic function is a function from S into the type of intuitionistic propositions, that is a propositional function over S. So both traditional approaches lead to the same intuitionistic version. We thus put: Definition 2.1 (Definition of subset) For any set S, a propositional function U with argument ranging in S is called a subset ofS, and is written i _ . Thus we can think that a subset U of S is obtained by abstracting the variable x in the judgement U(x) prop [x : S], that is U = (x : S) U(x). The same effect is usually expressed with the brace notation to form a subset , which does not depend on x any longer. So we put: However, it must be said explicitly that, even if we adopt the common expression for a subset, it remains true that a subset is a propositional function and hence a subset can never coincide with a set, for the simple reason that propositional functions are of a type different from that of sets. By similar reasons, the notion of subset is not automatically accompanied by that of element of a subset: writing , for , never gives a well-formed expression and, on the other hand, writing и : U would mean (x : S) u(x) : (x : S) U(x), which corresponds to the judgement [x : S] in the notation of Martin-Löf 1984, and hence has nothing to do with the intuitive notion of element of Building up a toolbox for Martin-Löf s type theory: subset theory 221 the subset U. So this notion has to be introduced anew. And indeed we need it, because only by virtue of it can an extensional theory of subsets be reconstructed like that of usual mathematical practice; for instance, we surely want two subsets to be equal iff they have the same elements.4 It is worth noting that much of what we are going to do in the case of subsets extends to relations in a natural way. In fact, contrary to the classical approach, a relation in type theory is just a propositional function with several arguments and thus it is a straightforward generalization of the notion of subset. 2.2 Elements of a subset Given a set S and a subset , the intuitive idea is that the element a of S is an element of U when the property U holds on a. In type theory, this is expressed by requiring U(a) true, which means that there exists b such that However, as in mathematical practice, we surely wish not to bother about the information of the specific b which makes U (a) true: for a to be an element of U, it is the pure existence of a proof which is required and not the actual specific verification, which we want to \"forget\".5 The theorem in Valentini 1998 states that we can restore such information when we wish, at the cost of some metamathematical work. At the same time, it is essential to keep the information of which element a is (see for instance -elimination in proposition 2.4), and thus express \"[/ holds on a\" rather than \"[/(a ) true\". In fact, U(a) may lose the information of which element a is considered without the possibility of restoring it from U(a) true. For instance, if U = (x : S) N, where jV is the set of natural numbers, then i is true, but there is no way to recover the element a to which U is applied. Therefore, what we require is a proposition a which, besides giving U (a) true, \"recalls\" which a is considered; that is, which satisfies true iff U(a) true and < Note that the right side of (*) is the conjunction of two judgements, which is usually not treated in type theory: this is the problem we have to face. It can be shown that (*) is equivalent to the following two conditions together: (1) for every с true iff U (a) true (2) if a true, then i To develop subset theory more smoothly, however, it is convenient to adopt an appar- ently stronger formulation in which the first condition is expressed by a proposition, namely the following conditions: 4While the identification of subsets with propositional functions is common to several approaches (for instance, see Coquand 1990 for a calculus of constructions), an explicit introduction of the notion of element of a subset seems to be peculiar to the present one. The details to export it to other type theories must be worked out deliberately. 5 After the meeting in Venice, Prof, de Bruijn kindly called our attention to his notion of proof-irrelevance (cf. de Bruijn 1980), which seems connected with our idea of \"forgetting\". 228 G. Sambin and S. Valentini (1) ( true (2) if a true, then From now on, we will refer to them as the first and second e-condition; we will see that they are all that is needed to be able to develop all of subset theory. Now, to solve the conditions, that is to find a proposition which satisfies them, the crucial remark is that there is substantially one way to include the information given by the judgement into a proposition, and that is Id(S, a, a). In fact, it is easy to prove that a S if and only if Id(S, a, a) true: one direction is just the rule of /¿/-introduction, while the other is obtained by a simple metamathematical argu- ment, namely that from a proof of Id(S, a, a) true one can effectively obtain a proof of Id(S, a, a) prop, which in turn must include a proof of a e S. This is the only addition to be made on top of an implementation of type theory to obtain an implementation of our toolbox. Note that requiring a formal equivalence would not make sense. Thus we simply put The verification of the e-conditions is immediate; let us note explicitly, however, that to prove true the knowledge of ' is essential. This agrees perfectly with the informal requirement that the proposition must coincide with U (a) when is known, but differs from U (a) since it keeps track of a by containing knowledge of Other solutions of the e-conditions are possible. The one proposed above can be seen as the proposition corresponding to \"U(a) true & which means \"there exists b such that and' . If we formalize it directly, we obtain , which is exactly , by the definition of (see Martin-Löf 1984, p. 43). If we note that \"there exists b such that I and i i s equivalent t o \"there existssuc h that jw e reach another solution for the e-conditions, namely (see also section 2.4). However, the particular form of the solution is inessential, as long as it satisfies the e-conditions. We thus put: Definition 2.2 Let S be any set and U any subset of S. If is any propositional function satisfying the e-conditions, we say that a is an element of U when ( is true. Since is a proposition for any and the property of being an element of U respects equality of elements of S; in fact, (substitution of elements) is a consequence of the /¿/-elimination rale (cf. Nordström et al. 1990, p. 64). ° Added in proof. An implementation has now been realized by Venanzio Capretta. We Building up a toolbox for Martin-Löf's type theory: subset theory 229 The few simple steps taken above are enough to develop a theory of subsets. The usual relations (like inclusion and extensional equality), operations on subsets (like fini- tary and infmitary union and intersection) and other usual tools (families indexed over a subset, quantifiers ranging over a subset, the image of a function between sets, func- tions defined on subsets, finite subsets, etc.) can be introduced in a straightforward way by means of the above e-conditions and intuitionistic logic. We repeat such work here in some detail, of course not expecting to produce surprises, but to give a direct feel- ing (experience) that e-conditions are really sufficient, and that they allow a complete formalization which is faithful to the usual intuitions and practice. In this way subset theory, even if type-less, is developed in a predicative way, a fact which is inherited directly from type theory. 2.3 Inclusion and equality between subsets Given two subsets U and У of a set S, it is usual to say that U is included in У if every element of U is also an element of У. We thus put: Definition 2.3 (Inclusion) For any we define the inclusion of U into V by Thus, contrary to _ is a proposition even if often, as in usual mathematical practice, we write to mean true. By the first e-condition, is true; this tells us that could equivalently be defined as The usual basic rules connecting membership with inclusion are immediately deriv- able from the above definition by means of the e-conditions; they confirm the under- standing that is true if and only if every element of U is also an element of V. Proposition 2.4 For any set S and U, , the following rules are derivable: -introduction -elimination Proof A derivation of -introduction is 230 G. Sambin and S. Valentini and a derivation of -elimination is Since is defined in terms of the connective of implication, it inherits all its prop- erties. For instance, is a preorder on subsets, with a top and a bottom element: Proposition 2.5 For any set S and any the following hold: (reflexivity) (transitivity) Moreover, putting and. we obtain (top) (bottom) While the first two statements are an immediate consequence of -rules (and in turn of reflexivity and transitivity of implication), the second two follow by logic from i true and by ex falso quodlibet, respectively, whatever prepositional function U is. Equality between subsets is usually defined by extensionality: that is, for any U, V ! S, U and V are said to be equal if they have the same elements. We thus put: Definition 2.6 (Extensional equality) For any U, V subsets of the set S, we define extensional equality of U and V to be the proposition We say that the subset U is (extensionally) equal to the subset true. The subsets t/ and V are (extensionally) equal if and only if for any true iff 7 true, and thus, by the first -condition, U (a) true iff У (a) true. Such equality must be distinguished from the stronger equality / , which means that, for any i if and only if, which is one of the basic judgements of type theory, and which could be called the intensional equality of the subsets U and V (since it requires U and У to have the same elements and, for each of them, with the same proofs). By the definitions, it is immediately true that the proposition holds. Actually, =5 is the equivalence relation on subsets induced by the preorder by forcing symmetry to hold. As for properties of Cj, the properties characterizing equivalences, in this case reflexivity symmetry transitivity Building up a toolbox for Martin-Löf's type theory: subset theory 231 can also be seen as inherited from the properties of the logical connective -e-. Once the notion of equality has been clarified, the definition of the type of subsets of a given set S is completed: Definition 2.7 (Power of a set) For any set S, the type of all subsets of S equipped with extensional equality is called the power of S and is denoted by PS, When a function (or operation) is to be defined on \"PS, one must take care to check that it is well defined on PS: that is, that it respects extensional equality; in the sequel this verification is sometime not spelled out. 2.4 Subsets as images of functions The notion of subset can be further illustrated, after the introduction of extensional equality, by looking at it from a slightly different perspective. For any set S, and any set /, a function is usually associated with the subset of S whose elements are those a S for which there exists such that Id(S, f(i), a) true. Here this is achieved simply by defining the image of a function as follows: Definition 2.8 (Image of a set along a function) For any sets S and I, and for any function , the subset of S defined by: is called the image of I along f. Other notations for 1 \\ include and /[/]. More generally, given a function with n arguments the image of I\\ ,...,!„ along f is defined by The definition of image associates a subset of a set S with a function into S. Actu- ally, this brings in an alternative characterization of subsets since the converse can also be proved (see Martin-Löf 1984, p. 64). In fact, every subset U of 5 is extensionally equal to the image of some set / along some function or, in more in- formal and suggestive words, we could say that subsets are just one function apart from sets: Theorem 2.9 Every subset U of a set S is extensionally equal to the image of the set S(5 , U) along the left projection ; in symbols, that is, by unwinding definitions, holds for every set S and 232 G. Sambin and S. Valentini Proof By the definitions and the e-conditions, the claim becomes To prove it, assume that a is a n arbitrary element o f S , an d that. . Then , an d thus !„..,, hence , an d therefore . This proves that is the term making true. To prove the converse, assume Then and hence i which, together with the fact that , gives subst |, as required (see Nordström étal. 1990,p. 64). The theorem above gives further evidence to the fact that the notion of being an element of a subset is the result of disregarding some information. Given a function /(/ ) : S [i : I], the subset 1т/[1] can be seen as the result of a process with two different abstraction steps. First, we realize that to know that a is an element in we can abstract on the particular argument i such that Id(S, f(i), a) true and prove only for some c. Note, however, that, owing to the con- structive meaning of existential quantification in type theory, a specific element such that Id(S, f(i), a) true can immediately be obtained from c. So, the second step, where we really forget some information, is to say that a is in if and only if ( true. Now let us consider the case of the function for some subset ¡ Then the above considerations bring the conclusion that a is in if and only if true. By the theorem above, a es U true is equivalent to a is in Imp['E(S, I/)], and hence also to true. It is then interesting to observe that to pass from a given verification of I to the judgement ) true means to forget the verification making U (a) true without forgetting a, since a appears explicitly in the proposition itself. To supply all the details we left out amounts to find a proof of true It is interesting to note that, since is the \"canonical\" solution of the e-conditions, the above equivalence gives an alternative, and more formal, proof of the fact that also is a solution of the e-conditions, as we already stated in section 2.2. 2.5 Singletons and finite subsets Every element a of a set S is equal to any element b making the prepositional function (x : S) Id(S, x, a) true at b; such triviality means that for any we can intuitively form the singleton [a] by putting tHEN Building up a toolbox for Martin-Löf's type theory: subset theory 233 And then the idea is that a finite subset is the union of a finite number of singletons; so if, , for some natural number n, we put But what does it mean, more precisely, to give It means that a is a function from N(n), a set with л elements, into S, and ÖQ, ... , fln-i are its values. It is easy to define a family of sets such that Л'(О) has no elements and, for , the elements oïN(n) are 0„,... , (n - 1)„. Then a singleton is the image of a function a : and a finite subset of S with n elements is the image of a function a : We thus put: Definition 2.10 (Singletons and finite subsets) For every set S, a subset U of S is said to be finite if U is extensionally equal to the image of some function for some , and in particular it is called a singleton if n = 1; more formally U is finite if true In particular, the empty subset of S is also finite, being equal to the image of a function from N(0) into S. Given the above definition, the assertion \"U is finite\" is just a proposition with parameter U. This allows us for instance to express rigorously in type theory a statement of the form \"there exists a finite subset UQ of U such that.. . i/o • • • \" by (a typical example is the definition of Stone cover in Sambin 1987). Proposition 2.1 1 For any set S, if U is a finite subset of S, then either U is empty or there exist a natural number 2nd, such that Proof The proof is nothing but working out definitions, using properties of finite sets, and fixing notation. U finite means that true If w is one of its verifications then p(w) e £(W, (h) N(h) —> S), and so n = p(p(w)) is a natural number and a = q(p(w)) is a function in N(h) —>• 5. Then U =s Ima[N(n)] holds. If л is zero we have finished since Im a[N(n)] is empty. Otherwise, by definition of image, x es Im a[N(n)] true if and only if (3( e N(n)) ld(S, a(i), x) true. Then, writing a¡ for a(in), by the rule of W(n)-elimination we have (x €S Ima[N(n)]) +>• (Id(S, x, ao) v Id(S,x,a\\) V • • • V Id(S, x, a n -l) ) true as required. П 234 G. Sambin and S. Valentini Set-theoretic operations can be defined among finite subsets which give a finite sub- set as a result. For instance, suppose that U and V are finite subsets determined by the elements с and d in £(W, («) N(ri) -> 5), that is, U =$ Imq(c)[N(p(c)}} and V =s lmq(d}[N(p(d))]. Then the union of U and V is the finite subset determined by (p(c) + p(d), AJE. if x < p(c) then q(c)(x) else q(d)(x — p(c))). On the other hand, intersection between the finite subsets U and V, determined by с and d, can- not be determined by an element in E (TV, (n) N(n) ->• S) unless equality among elements of S is decidable. In fact, suppose that there exists a function g such that g(c,d) e £(W, (n) N(n) -> S) determines the finite subset which corresponds to the intersection of U and V. Then consider the case in which U and V are the sin- gletons {a} and {b} for a, b e S, that is, £/ and V are determined by (l,Ajt. a) and (1, AJC. b) in E(W, (n) W(n) ->• 5) respectively. Then the subset determined by g({l, AJC. a), (I, AJC. £}) is either a singleton or empty according to whether Id(S, a, b) is true or not. Hence p(g((l, Ajt. a), (I, Kx. b))) e N is equal to 1 if and only if Id(S, a, b) true, which allows us to decide on the equality of a and b since equality in N is decidable. 7 Many usual properties of singletons and finite subsets are obtained by intuitionistic logic from the above definitions. We give the following proposition as a sample: Proposition 2.12 For any set S, U с S and a e S, a €s U true iff {a} c ^ U true Proof Assume true and let true; then ld(S, x,a) true, and hence by the rule of substitution on elements true, so that, by-introduction, | I true. Conversely if true then, by-elimination, true because obviously a €5 {a} true. However, some other common properties require new definitions to be expressed. An example is for instance , where the notion of union indexed over a subset is necessary (see section 2.9). 2.6 Finitary operations on subsets One of the main reasons for the definition of subsets as propositional functions is that it allows us to define operations on subsets with a subset as value. We begin with the usual set-theoretic operations. 7 A solution to the problem of intersection exists, but it requires a more complex definition of finite subset, for which proposition 2.11 fails. The intuitive idea is that, given a finite set J and, for any , a finite set l(j), a subset is finite if it is extensionally equal to the subset ). More formally, the finite subsets are determined by the elements of the set It can be shown that this definition reduces to the one in the main text if the equality of S is decidable. Building up a toolbox for Martin-Löf's type theory: subset theory 235 Definition 2.13. (Finitary operations on subsets) For any we define intersection: union: implication: opposite: Note the common pattern of the above definitions: an operation on subsets, that is prepositional functions, is obtained by lifting (through abstraction) a connective acting on propositions. More formally, if • is a given connective, then the corresponding operation on subsets о is defined by and hence о : (S : set)(U : (x : S) prop)(V : (x : S) prop)(x : S) prop. This is the direct link between \"subset-theoretic\" operations and intuitionistic logical connectives. It is also clear that all of the above operations on subsets respect extensional equality, by the logical metatheorem of replacement of equivalent propositions. The following proposition states that each of them can be characterized in terms of elements in the expected, traditional way: Proposition 2.14 For any U, and any < , the following hold: true true ' true Proof Under the assumption a & S, the judgement true is equivalent to ( true, that is true, which in turn is equivalent to с true by the first e-condition. Exactly the same argument applies to all other operations. Even if i and l are logically equivalent under the assumption that , note that it is the use of the -notation which allows us to make evident an intuitive content which otherwise would be completely hidden in the syntactic rule of reduction by which for instance i and ¡) are just equal expressions. This is one of the main reasons for introducing it. As for inclusion and equality, the properties of operations on subsets are an immedi- ate consequence of the properties of the corresponding logical connective used to define them. The logical rules of &-elimination say that and while by A-introduction it is immediately true that 236 G. Sambin and S. Valentini and thus ' is the infimum of U and V with respect to the partial order ;. Similarly, by the v-rules, we have and which say that is the supremum of U and V. If instead of rules we consider logical truths, then immediately associativity commutativity idempotency hold, and the same properties hold for U. The link between =>• and is is given by that is, which is obvious because (A —» B) -f> T is logically equivalent to A —» B, for any propositions Л and B. In general, the usual informal argument to prove a certain property of set-theoretic operations is perfectly reflected into a rigorous proof through intuitionistic logic. 2.7 Families of subsets and infmitary operations We now turn to infinitary operations on subsets. The order of conceptual priority, how- ever, is to deal first with families of subsets. The traditional notion of family of subsets has a simple definition in the present approach: Definition 2.15 (Set-indexed family of subsets) A family of subsets of S indexed by a set I is apropositional function U : (i : I)(x : S) prop with two arguments, one in I andone in S. Applying U to an element i of I we obtain a propositional function U(i) on elements of S, that is Following traditional notation, given any we put Hence the usual notation (C/,:)¡g/ can be used for a set-indexed family of subsets. Two families of subsets U, V, indexed by I, are said to be equal if for any index i e / , Uj =s Vi, that is we put In other words, U and V are equal if they are extensionally equal qua binary relations between I and S, that is < and Building up a toolbox for Martin-Löf s type theory: subset theory 237 Infinitary operations are easily defined on set-indexed families of subsets. Just as propositional connectives were used to define unary and binary operations, now quanti- fiers are used to define infinitary operations. Definition 2.16 (Infinitary operations on families) For any set-indexed family of subsets ofS, we put: Clearly and are subsets of S. Moreover, they behave in the expected way with respect to elements: Proposition 2.17 For any set-indexed family (í/,-)¡e/ of subsets ofS, and any true true Proof The proof is perfectly similar to the proof of proposition 2.14. D The standard properties of union are obtained, as expected, from logical properties of the existential quantifier. Given any set-indexed family of subsets (С/;);е/> for any ye / the 3-introduction rule gives which says that for all (2.1) Note that, since is a proposition and not a judgement, we could, more formally, express the above as Similarly, for any and the rule of -elimination can be put in the form which says that (2.2) 238 G. SambinandS. Valéntini Of course, the above two properties (2.1) and (2.2) say that union is the supremum of set-indexed families w.r.t. the order ;. An equivalent formulation of (2.1) and (2.2) together is which corresponds to which is true by the intuitionistic laws of permutation of quantifers with implication. One can actually prove a somewhat stronger statement, namely which can also be expressed in terms of subsets, as and shows the use of the subset operation =>. Similarly, from the rules for V, one obtains that intersection is the infimum of a set-indexed family 2.8 The power of a set In this section some facts specific to the type of subsets of a set 5, equipped with extensional equality, will be illustrated. Let us stress that the type we are consider- ing is not the type of the propositional functions over S, even if a subset of S is the same as a propositional function over S. In fact, a type is determined both by its elements and its equality relation, and we do not consider intensional equality between propositional functions as in Martin-Löf 1984, but extensional equality as defined in definition 2.6. First of all, we want to analyze the structure of PS, equipped with fmitary and infmitary operations, in algebraic terms. The fact that PS is equipped with extensional equality gives as a consequence that inclusion 5 is a partial order on PS. Moreover, l and are semilattices 8 because of the results in sec- tion 2.6. To show that is a lattice, we have to check that c s is the partial order induced by the semilattice operations П and U, that is The first equivalence is immediate by logic (and proposition 2.14) once we expand definitions into ( if and only if . Similarly, the second equivalence holds because Î iff , for any propositions A and В. 8Here and in the whole paper we adhere to the principle of adopting standard algebraic terminology for structures (A, f\\, ..., ./„), where A is a type, and not necessarily a set. Building up a toolbox for Martin-Löf's type theory: subset theory 239 The next step is to show that PS is a complete lattice with respect to infinitary union and intersection. The traditional definition is that a lattice L is complete if any family , where / is a set, of elements of L has a supremum. To express this inside type theory, we lack only the definition of a set-indexed family of elements in a type (or in a set): Definition 2.18 (Set-indexed family of elements) Let С be any type or set. A set- indexed family of elements of С is a function f defined on a set I with values in C. As usual, the notation (/¿)ie/> where , is used. We already used a set-indexed family of elements of a type within this paper in section 2.7, where we introduced the notion of a set-indexed family of subsets of a set. In general, the foundational reason for introducing set-indexed families of elements of a type is that they allow us to give a meaning to quantification over the elements of some subtypes. In fact, given a function / from the set / into the type C, the quantification over the image of / is reduced to a quantification over the set of indexes / . An example coming from mathematical practice is given in Sambin et al 1996, where we introduced set-based Scott domains, that is Scott domains such that the type of compact elements can be indexed by a set. Now, the definition of complete lattice in our approach is literally as above, but one must be careful that it has a different meaning according to the foundational attitude. In the classical view, any subtype of PS can be indexed by a set, while we expect this to be false in type theory. We believe, however, that from a computational point of view it is necessary, but at the same time sufficient, to consider only families of subsets which are set indexed. Hence PS is a complete lattice because we have shown in section 2.7 that any set- indexed family of subsets has both supremum and infimum. It is now easy to prove also: Theorem 2.19 For any set S, is a frame (alias local, com- plete Heyting algebra). Proof After the preceding results, it remains to prove only that infinitary union dis- tributes over intersection, that is It can immediately be seen that this corresponds exactly to a logical law of quantifier shifting, namely a As an example of how a classical theorem is rendered in our notion of power of a set, we give here a constructive version of Cantor's diagonalization theorem: Theorem 2.20 (Cantor's diagonalization) Let S be any set. Then for any set-indexed family of subsets ofS, there is a subset DpS which is extensionally different from FX for any С 240 G. Sambin and S. Valentini Proof Given the family (FX)X£S> that is F(x, y) prop [x : S,y : S], put that is, For any x & S, Dp =.<; F* would mean that , which for y = x would give which is a contradiction. So for any Another example, inspired by topos theory, is the biunivocal correspondence be- tween PS and the collection of families of subsets of the one-element set NI equipped with equality as defined in 2.15. We omit the details. 2.9 Quantifiers relative to a subset The meaning of quantification over a subset U of a set S is that the range of quantifica- tion is restricted to elements of U, rather than all elements of S. A common definition in pure logic is that of quantifiers relative to a property ; the idea is to adapt it to type theory in such a way as to make it explicit that U is considered as the domain of quantification. Definition 2.21 (Quantifiers relative to a subset) Let S be a set and U S. Then, for any propositionalfunction A(x) prop [x : S, x U true] we put The operators and , , are called, respectively, the universal and existential quantifier relative to U. Note that the above definition makes use of the fact, specific to type theory, that A -> В and A & В are propositions provided that Л is a proposition and В is a proposition under the assumption that A is true. It is an easy matter now to check that quantifiers relative to a subset U obey the rules completely similar to those for quantifiers in intuitionistic logic, but with explicit mention of the domain of quantification, as in Martin-Löf 1984: V-introduction V-elimination 3-introduction 3-elimination Building up a toolbox for Martin-Löf's type theory: subset theory 241 Such rules are only abbreviations for deductions in type theory. For instance, the V-introduction rule relativized to U is an abbreviation of Once we have access to quantifiers relative to subsets, many of the notions defined on sets can be extended to subsets in a straightforward way; we now see the case of arbitrary unions and intersections. First, however, the notion of a set-indexed family of subsets must be generalized to subset-indexed families. Definition 2.22 (Subset-indexed family of subsets) Let S be a set, I be a set and U I. Then a prepositional function prop is said to be a family of subsets of S indexed on the subset U if the truth ofV(i, y, x) does not depend on y, that is ] for any ; then one can hide the variable y and write The infinitary operations of union and intersection are immediately extended to subset-indexed families of subsets, simply by replacing quantifiers with quantifiers rel- ative to a subset. So, if V¡ с S [i €¡ U true], we put and As an exercise, we can prove here the property we left out in section 2.5. Proposition 2.23 For any set S and U S, Proof The subset-indexed family is of course , that is Id(S, x, i) prop [i : S, U(i) true, x : S] For any x e S, we have true iff true iff Id(S, x , i) true iff true if\" \" true. 242 G. Sambin and S. Valentini We propose a second exercise: prove that if ' and then A similar result holds also for the weaker assumption but with a more complicated statement and proof. 2.10 Image of a subset and functions defined on a subset The idea of relativized quantifiers makes it natural also to extend to subsets the notion of image of a set: Definition 2.24 (Image of a subset) Let S and I be sets. Then, given any function /(/) e S [i : I] and any subset U of I, the subset of S defined by is called the image of U along f. An alternative notation for j More generally, given a function f(x\\,... ,x n) S [x\\ : I\\,..., x n : /„] and a relation R(x\\ ,...,*/,) prop [xi : I\\, ...,x n : /„], both with n arguments, the image of R along f is defined by Alternative notations for Im/[R] include f[R] and Of course, if U is the trivial subset T/, then In general, all the expected properties can easily be checked. For instance, for any U, V I, follows immediately from definitions by intuitionistic logic. Another instructive exer- cise is to realize that It is also worthwhile to note that the image is always extensionally equal to the image of some set J along some function g: it is enough to consider If n subsets are given, then the image of l/i,..., E/„ under / is obtained as a special case, by putting For instance, given an operation • : S2 —> S, and writing as usual b • с for -(b, c), the image of the two subsets U, V ç S is the subset that is Building up a toolbox for Martin-Löf's type theory: subset theory 243 which, following th e above conventions, is written also a s | } o r •[[/, V ]; it is the latter notation which gives rise to U • V, which is the standard notation for such a subset used in algebra to mean, for instance, the product of ideals / • J or of subgroups H • К, and which we found useful in formal topology. The notion of function itself can be relativized to a subset in the following sense: Definition 2.25 (Function denne d on a subset) If S is a set, I is a set and a function of two arguments is said to be a function from U to S, if the value f(i,y) does not depend on y, that is if , j i true; then one can hide the variable y and write simply The intuitive content of such a definition is that, just like the notion of element of a subset U is obtained by \"forgetting\" the witness y of U(i), so a function / relativized to U is obtained by \"forgetting\" the second argument of the input. This of course can be done only when the specific value of y is irrelevant for the computation of /(/, y), that is when f(i, y) and f(i, y') have the same value for any as required above. A similar definition can also be given when / is a function from / and U(i) set [i : I] into a type C. In this case, to express the fact that / does not depend on the second argument, the equality in С must be used instead of propositional equality, and thus, in general, the condition cannot be expressed by a proposition. Extending the previous terminology to functions defined on subsets, a function is also called a subset-indexed family of elements of C. The remark following definition 2.18 applies here equally well. Again, examples are to be found in Sambin et al. 1996. 3 Conclusion The technical development so far has been quite simple to read. And indeed a useful tool must be simple, so that it is easy to use . It is even possible that the reader has forgotten the substantial novelty, namely that all of what we did is inside type theory. As always with a tool, however, the right way to judge if it works well is to use it in practice. For instance, we know by experience that it works well in developing most of formal topology (see Sambin 1987 and later developments, which will be summed up in a monograph). For us this is not a surprise, since the toolbox for subsets itself was developed by keeping in mind the practical development of formal topology. Most of what we have presented here is the answer to problems actually encountered. We thus expect that new applications of type theory will enrich our toolbox with new tools. Bibliography Coquand, Th. (1990). Metamathematical investigations of a calculus of constructions, in: Logic and Computer Science, P. Odifreddi, ed., Academic Press, London, pp. 91- 122. 244 G. Sambin and S. Valentini de Bruijn, N. G. (1980). A survey of the project Automath., in: To H. B. Curry: Es- says on Combinatory Logic, Lambda Calculus and Formalism, J. P. Seldin and J. R. Hyndley, eds, Academic Press, London, pp. 589-606. Frege, G. (1892). Über Sinn und Bedeutung, Zeitschrift für Philosophie und philosophische Kritik, pp. 25-50. Howard, W. A. (1980). The formulae-as-types notion of construction, in: To H. В. Curry: Essays on Combinatory Logic, Lambda Calculus and Formalism, J. R. Hind- ley and J. P. Seldin, eds, Academic Press, London, pp. 479-490. Martin-Löf, P. (1984). \"Intuitionistic type theory\", notes by Giovanni Sambin of a series of lectures given in Padua, June 1980, Bibliopolis, Naples. Nordström, В., Petersson, К. and Smith, J. M. (1990). Programming in Martin-Löf's Type Theory, an introduction, Clarendon Press, Oxford. Paulus Venetus (alias Sambin, G. and Valentini, S.) (1993). Propositum Cameriniense, sive etiam itinera certaminis ... (Italian), in: Atti degli Incontri di Lógica Matem- ática, vol. viii (XV Incontro), G. Gerla, C. Toffalori, S. Tulipani, eds, Camerino, pp. 115-143. Sambin, G. (1987). Intuitionistic formal spaces - a first communication, in: Mathemat- ical Logic and its Applications, D. Skordev ed., Plenum, New York, pp. 187-204. Sambin, G. (1991). Per una dinámica nei fondamenti (Italian), in: Atti del Congresso \"Nuovi problemi della lógica e délia filosofía délia scienza\", vol. II, G. Corsi and G. Sambin, eds, CLUEB, Bologna, pp. 163-210. Sambin, G. and Valentini, S. (1993). Building up a tool-box for Martin-Löf's type the- ory (abstract), in: G. Gottlob, A. Leitsch and D. Mundici, eds, Computational Logic and Proof Theory. Proceedings of the Third Kurt Gödel Colloquium, KGC'93, Lec- ture Notes in Computer Science, Springer, Berlin-Heidelberg-New York, pp. 69-70. Sambin, G., Valentini, S. and Virgili, P. (1996). Constructive Domain Theory as a Branch of Intuitionistic Pointfree Topology, Theoretical Computer Science, 159, pp. 319-341. Turner, R. (1997). Reading between the lines in constructive type theory, Journal of Logic Computation, 7-2, pp. 229-250. Valentini, S. (1996). Decidability in Intuitionistic Type Theory is functionally decidable, Mathematical Logic Quarterly 42, pp. 300-304. Valentini, S. (1998). The forget- restore principle: a paradigmatic example, this volume. 13 An introduction to well-ordering proofs in Martin-Löf's type theory Anton Setzer 1 Department of Mathematics, Uppsala University 1 Introduction The proof-theoretic strength a of a theory is the supremum of all ordinals up to which we can prove transfmite induction in that theory. Whereas for classical theories the main problem is to show that a is an upper bound for the strength—this usually means to reduce the theory to a weak theory like primitive recursive arithmetic or Heyting arithmetic extended by transfmite induction up to a, which can be considered to be more constructive than the classical theory itself—for constructive theories this is in most cases not difficult, since we can easily build a term model in a classical theory of known strength. For constructive theories in general the main problem is to show that a is a lower bound: that despite the restricted principles available one has a proof- theoretically strong theory. In this article we will concentrate on the direct method for showing that a is a lower bound, namely well-ordering proofs: to carry out in the theory a sequence of proofs of the well-foundedness of linear orderings of order type a n , such that sup ngu)a n = a. Such proofs can be considered to be the logically most complex proofs which one can carry out in the theory; in most cases, in addition to transfinite induction up to a n for each и, only primitive recursive arithmetic is needed in order to analyze the theory proof-theoretically and in order to prove the same D^-sentences. Griffor and Rathjen (1994) have used the more indirect method of interpreting theories of known strength in type theory for obtaining lower bounds for the strength of it. Apart from the fact that in the case of one universe and W-type Griffor and Rathjens' approach did not yield sharp bounds, we believe that the direct method has the advantage of giving a deeper insight into the theory, since one examines the principles of the theory directly without referring to the analysis of another theory, and that the programs obtained by it are of independent interest. In Setzer (1995) and Setzer (1996) we have carried out well-ordering proofs for Martin-Löf's type theory with W-type and one universe and for the Mahlo universe. In 'This article is based on a series of lectures given by the author while he was visiting—at that time based in Munich—the universities of Stockholm and Uppsala. He wants to thank P. Martin-Löf for inviting him and making this fruitful visit possible and the logic group in Uppsala for providing a creative and thoughtful environment. 246 A. Setzer this article, in contrast to these technical articles, we want to concentrate on explaining the techniques used and therefore help to make them accessible to researchers outside proof theory. We will do this for the theories without universes (except in a microscopic universe which contains two types) and plan to continue this exposition later with an article in which we will explain well-ordering proofs for theories with an ordinary uni- verse and with a Mahlo universe. We start our introduction to well-ordering proofs by explaining the ordinal notation systems needed. They seem to be the main obstacle to the understanding of the proof theory of strong systems. In order to motivate what kinds of systems are necessary, we will first introduce ordinal notation systems in general (section 2) and some weak ordinal notation systems (section 3), which are relatively intuitive. We will analyze them, define the concept of ordinal notation systems from below and observe that the systems introduced fall under this concept. An ordinal notation system is essentially from below, if the notation of an ordinal a. is based only on smaller ones and all ordinals below a have notations which can be introduced by a recursive process before a, Therefore the ordinal notations are systematically built up from below and this makes it easy to understand that they are well-founded. In section 4 we introduce the accessible part as the largest well-founded segment of a linear ordering (a segment of the ordinals is a subset of the ordinals A such that i. With this concept we can formalize what we think is the reason why such systems can be seen as intuitively well-founded (see the proof of Lemma 4.3(b): the accessible part is closed under the functions the notation system is built of and therefore we have transfinite induction over the full notation system. This proof can be carried out in a theory which allows us to define the accessible part. Since this is the case for the theories considered here, the proof-theoretic strength of them can no longer be expressed in systems which are from below, and stronger systems are needed. We will explain the extended principles needed for the definition of stronger ordi- nal notation systems (section 5)—we will denote ordinals by using bigger ones—and then carry out the well-ordering proofs for type theory with Kleene's O, one unnested W-type. We will end this article in section 6 with the introduction of stronger ordi- nal notation systems and well-ordering proofs for type theory with arbitrarily nested W-type. Some conventions about sequences of ordinals and natural numbers follow. The sequence of the ordinals coded in the usual way is denoted by , .. . denote sequences of ordinals coded in this way; the /th element of , .. . is ( \"•,... . Ord is the class of ordinals in set theory and Ord* the class of codes for sequences of ordinals. If are natural numbers, (a\\,..., a^) is a code for the sequence a \\, ... ,a/¡ (with the usual properties like primitive recursiveness); sequences of natural numbers are denoted by , met th element of isa¡,oí_ is ¿>¿, etc.; seqlength is the length of the sequence i is the concatenation of the lists and . An introduction to well-ordering proofs in Martin-Lofs type theory 247 2 Ordinal notation systems The usual way of introducing ordinal notation systems is to start with a collection of functions fi : dom Ord and then to introduce a collection of terms T built from symbols /,- representing the functions /¿. In T one usually has more than one notation for the ordinals denoted; therefore one selects normal forms, i.e. subsets nf(/,- ) dom(/,- ), such that in the term system ОТ formed from terms built from normal forms only we have at most one notation for every ordinal. This will be formalized in the following: Definition 2.1 Assume /,- : dom(/,-) с Ord* Ord , nf¿ dom(/})> (I = 1,... , n), . If i , then We omit unnecessary brackets and write /,-, /,- instead of (a) ] (b) ClosureCF, p), the closure of p under /,- in normal form, is the least subset of Ord such that p с Closure and , Closurei and a =NF then a e Closure(.F, p). (c) Т is called a system of ordinal functions in normal form, iff the following hold: (NF1) then ; and (NF 2) If a — (ai,..., a¿) e dom(/¿), a\\,..., ctk e Closure^ , p), then fi (a) e Closure^ , p). (d) An ordinal function with normal form is a pair (/, nf) such that (/, nf)i<;<i is a system of ordinal functions in normal form. (e) We will in the following usually write f¡ instead of f¡. In condition (NF2) we refer to Closure(J\", p) and not only to Closure^ , 0) in order to make extension of the system by adding further ordinal functions easier. Definition 2.2 Assume that. is a system of ordinal functions in normal form. Let instead of f¡ (()) and instead of (a) Tjr, or Т for short, the set of pre-terms for T, is defined inductively by: then Note that Т is a primitive recursive subset of N. (b) length^-, or length for short : N and op, or о for short :__, Ord are defined by length max{length(fi),..., length if dom(//), otherwise. (c) We define OTjr с T?r (or ОТ for short), the set of ordinal notations correspond- in g t o F simultaneously by : О Т an d NF , then. ОТ. (d) For Again, we will usually omit the index f. (e) The ordinal notation system defined by F is the triple . An ordi- nal notation system defined by functions in normal form is a triple wE wRITE 248 A. Setzer (ОТ, , о) such that for some functions F in normal form (ОТ, , о) = (ОТ^г, yr, ojr). We write (ОТ, :), if о is obvious or not used. (f) The ordinal notation system (ОТ, , о) is called primitive recursive, if ОТ and can be defined primitive recursively. (g) (h) We will usually omit the tilde and indices T. (i) In the following, r, s, t usually denote elements of T and a, b, с elements of ОТ (possibly with subscripts). Note that, since we have normal forms, о : ОТ -> Closure(J-\", 0) is bijective. Fur- ther, if we have a primitive recursive ordinal notation system for f, then the relation t = NF /¿ (ii,... , tk) is primitive recursive in t, t\\ ft, since t =NF fi (*i, • • •, ft) О í = /¿(íi,...,ft)Aí,fi,...,ft rçOT . We will give some examples of primitive recursive ordinal notation systems: 1. The Cantor normal form. Let dom(CNF) со, ai e Ord, mi e o>}, CNFl CNFQ := 0. NF(CNF otk, nk), NF(CNF()). The ordinal notation system defined by CNF can easily be seen to be primitive recursive by using the fact that in case of NF(CNF(ai,ni,... ,« ь rik)) and NF(CNF I we have CNF(ai, n\\,'..., « ь n&) , where <iex,iex is the lexicographic ordering on strictly descending sequences based on the lexicographic ordering on pairs (y, n) which itself is based on 2. The Veblen function <p. Let <paß be the (1 + /5)th common fixed point of the functions. and of \\ We can show (see for instance Schütte 1977) that Let NF and NF(CNF) be defined as before. Then CNF and define a primitive recursive ordinal notation system. 3.Th e n-ary Veblen function. : Ord \" -> Ord is defined by(0 , ... , ( and, if oik Ф 0, then , (a\\,..., i , 0,... , 0, ) is the (1 + )th com- mon fixed point of the functions , , , («i,... , cck-\\, ot~, y, 0,... , 0) with a~ < a¿. Define NF : ai,...,a„ i. CNF and define a primitive recursive system of functions in normal form. 4. The Schütte Klammersymbole. Schütte (1954) introduced an extension of the Veblen functions by allowing arguments indexed by ordinals, of which only finitely many are present. The symbol }, with stands for the value of the extended Veblen function, where the /5,-th argument is 04 (and the others are 0). They can be defined formally by transfinite recursion on {(ß\\ ,a\\),..., (ßn, «„)) ordered by <iex,iex> where <iex,iex is the lexicographic ordering on descending An introduction to well-ordering proofs in Martin-Lofs type theory 249 sequences based on the lexicographic on pairs, which is itself based on the ordering on the ordinals. For A as above we define NF( With the properties shown in Schütte (1954) one can see that the Schütte Klammersymbole together with the constant 0 form a primitive recursive ordinal notation system. Simplification of the general situation. We can code a system of ordinal functions ( into one function with normal form (/, nf) as follows. Assume (after some small changes in j r) that dom( , and Closure) Therefore Now the ordinal notation systems formed by (/ , nf) and are essentially the same. In order to simplify the considerations in the following on the development of the general theory we will restrict ourselves to systems of ordinal func- tions consisting of only one function. The examples of systems given will be identified with the system consisting of one function only obtained by the above procedure. 3 Ordinal notation systems from be!ow Ordinal notation systems from below are those in which ordinals are introduced in a systematic way by denoting ordinals using smaller ones. Such systems should be intu- itively well-ordered. The formalization of this leads to three conditions. Ordinals should be denoted by smaller ones; therefore we need that, if then a¡ . One might think that this already defines systems from below com- pletely. However, any ordinal notation system ОТ can be immediately seen as a system fulfilling this condition: take the system consisting of the constant 0, the successor func- tion restricted to natural numbers and the function which assigns to a natural number a, which is a code for an infinite ordinal notation in ОТ, the ordinal o(a). This exam- ple shows that, in order to have notation systems which are intuitively well-ordered, we need that new notations for ordinals are introduced only after having denoted all smaller ordinals. Therefore we have the second condition: all ordinals b below some ordinal a ~ NF should be introduced before a. Either __ and, since a¡ is known, b is known as well, or and , where -' i s some ordering on the argument tuples which expresses what is meant by the word \"before\". We can view this process of introducing new ordinals as recursion on .I n fact it will essentially be the same as the recursion, by which the ordinal function corre- sponding to / can be defined. Now, since we have a recursive process, needs to be a well-ordering. We will look at our examples in order to make more precise the condition required for In the first example - is the lexicographic ordering on descending sequences based on the lexicographic ordering on pairs. If we code up the second example into one function we need the additional constant 0: the.refnre, WP. have to omit () from NF(CNF), and get and . We can now define () , and order tuples (0, c) by the double lexicographic ordering on 250 A. Setzer as before, and triples (1, b, c) by the lexicographic ordering on pairs (b,c). Then, for instance, if with i or with , with an d a exFo r th e system built f CNF, <p n we can take a similar ordering with the lexicographic ordering on n-tuples instead of pairs, and in the last example of the Schütte Klammersymbole we can take as ч ' the double lexicographic ordering similar to that used in the first example. All these orderings have in common that their well-foundedness reduces by a proof- theoretically weak argument to the well-ordering of . We will see later that in all examples for every formula ф(Ь) there exist formulas (a, zi,..., zi) such that from transfinite induction on (ОТ, ) for (a (a, zi, ... , z/)} we can conclude transfi- nite induction for the class by a simple argument. Simple here means that this argument can be carried out uniformly in primitive recursive arithmetic PR A. Uni- formly means that now we can show that for all subsets A of N transfinite induction over i ) reduces to transfinite induction over (ОТ П R, ). The extension to subsets R of ОТ expresses that, whenever we have introduced a set of ordinal notations R such that R is well-ordered, then we already have well-ordering of the corresponding set of argument tuples nf _ We will now give the precise definitions. Definition 3.1 Let PRA be primitive recursive arithmetic, i.e. Heyting arithmetic, but with induction restricted to quantifier-free formulas. PRA+ is the extension of PRA by additional predicates of arbitrary arity without defining axioms and without induction for formulas containing such predicates. We call such predicates free predicates. Definition 3.2 Assume that T is some theory with some standard interpretation of the connectives of PRA and of primitive recursive functions in it (the primitive recursive functions might be represented by relations representing the graphs such that we can show the existence and uniqueness conditions for functions). T is an extension of PRA, if all the rules and axioms of PRA can be derived in the extended language (with this representation of connectives and functions). Definition 3.3 (a) Let ,.. . in the following denote binary relations represented by formulas in PRA+, i.e. n m is some fixed formula, s Let be fixed in the following. (b) (c) A class in any extension of PRA is an expression of the form ' where n is a variable and a formula in the extended language (which means that, if the theory is Martin-Löf's type theory, we can prove set). The variables of the class are the free variables of , excluding n. In the following A , A', B,... denote classes. (d) , similarly for (e) We identify a primitive recursive set A with the class {n \\ f(n) = 1], where / is An introduction to well-ordering proofs in Martin-Löf's type theory 251 the primitive recursive function N —»• N such that /(и) — 1 iff n is an element of A , f(n) = 0 otherwise. (f) We identify [n \\ Q(n)} with Q, if Q is a unary free predicate. (g) t seqlengt h seqlengthi , and we usually omit the index (h) (i) Prog TI< Definition 3.4 Transfinite induction over ( ;, A) is reducible in PRA to transfmite induction over (A,-, - ,•) (z = 1,...,«) ; in short TI(A, ) is PRA-reducible to Т1(л,-,ч,-)> if there exist n¡ e N, variables гг/ь classes B¡j with free variables , such that PRA for some free unary predicate Q. Lemma 3.5 (a) If Tl is PRA-reducible to then for every class В of PRA + there exists classes B¿¡ with free variables ' ~ such that PRA + h (b) IfTl^A,^) is PRA-reducible tc and for each i is PRA-reducible to ', then is PRA-reducible to (c) is PRA-reducible to ' (d) Assume А П В = 0. Define ThenTI(A\\jB,-<) is PRA-reducible to and (e) Lef-q e x be the lexicographic combination of- seqlength(a) = seqlength Then is PRA-reducible to TI^.^) , Т1(д 2>^ 2). (f) Let Des (A) := seqlengthi be the set of all descending sequences in A, -q ex be the lexicographic ordering defined from (seqlength seqlengthseqlength i ,{seqlength(n), seqlength Then is PRA-reducible to (8) then s PRA-reducible to Proof: (a): Replace Q by B. (b): By (a), (c): From follows Т1(Апв,ч)(о). (d), (e): Easy. (f): We use in this proof the notations I, etc. We adapt the Gentzen proof (Gentzen 1943), which shows that follows from PA h TI(a) (this proof is explained well in Schütte 1977). We write Des for Des^(A), and show that TI(Des,^tex)(ß) follows from , where S := {n \\ 252 A. Setzer Assume Prog We show Prog ). Assume ' (this will be called IH), Des Des. We show I First, by Des _ __ . Des and Prog (Q), in ц Q follows. Further, Des Q. , then therefore or / = m and / r\\ Q 01 , with The last case follows by Des _ and the IH / Q. Therefore we have (m, n) r¡ Q. If now we are done. Otherwise , , Des П Q, by IH and therefore i We have now shown that A S. Des ,, мсл _ ; therefore \" ~ \" ' Des, then i for some n r) A, m, and by r Des and n r¡ S lead to\"\" Therefore Des_ Q. (g): PRÄ ,_,., . .._. with ( Now we can define an ordinal notation system from below: Definition 3.6 (a) Let (/, nf) be an ordinal function with normal form, (ОТ, -<, о) be the ordinal notation system defined from (/, nf), and assume that it is primitive recursive and that the linearity of -< can be proved in PRA. (ОТ, -<, о) is an ordinal notation system from below, if for some primitive recursive relation <' the following hold: (Below 1) (Below 2) (Below 3) TI(NF(/)n«*,-;') is PRA-reducible to Т1(отп/г,-о for a unary free predicate R. (b) Assume that .F = (/;, nf¿)i</<n is a system of ordinal functions, (ОТ, -<, о) is the ordinal notation system defined from (/,-, nf¿), and assume that it is primitive recursive. (/) , nfy) is a part of (ОТ, -<, о) from below, if the conditions from (a) hold with OTjr, -<f, Of instead of ОТ, -<, о and / := //. Remark: In Corollary 5.8(b) we will see that ordinal notation systems from below have order type less than the Bachrnann-Howard ordinal. Naturally we would like to get. beyond this bound in a way which is still from below. One idea is to weaken condition (Below 3) and allow proof-theoretically stronger principles for the reduction of -<' to x . This will be considered in a future article where we will reach at least the strength of systems which require usually one large cardinal (one inaccessible). Another approach was taken by Feferman (1970), Howard (1970) by taking finite types, and later by Aczel (1972) by taking transfinite types to denote ordinals. This approach can be seen in the spirit of our first two conditions, although it is not directly comparable. Again we need proof-theoretically stronger principles in order to show that all ordinals below some notation are introduced before it, namely the use of higher types. In all our examples, TI over (where is the ordering of the arguments we de- fined there) was PRA-reducible to TI over , could be obtained from -< by a combi- nation of the lexicographic ordering on pairs (Lemma 3.5(e)), the lexicographic ordering on descending sequences (Lemma 3.5(f)), the union of orderings (Lemma 3.5(d)), the selection of a subset of an ordering (Lemma 3.5(b)), reordering of the arguments and An introduction to well-ordering proofs in Martin-Löf s type theory 253 moving to isomorphic orderings (Lemma 3.5(g)). Therefore these systems were ordinal notation systems from below. 4 The accessible part Definition 4.1 Assume Г is an extension of PRA. Acc(A, ) is the accessible part of (A, -<:) in T, iff in Т the following hold: (Accl) (Ace 2) For every class В of Т We write Acc(A), if the choice of is clear, and Ace, if A = ОТ, where the choice of ОТ is clear from the context. Remark 4.2 Under the assumptions of Definition 4.1 the following hold: (a) T\\~Acc(A, ) С А. (b) T h-V« 77 Acc(A, ) (c) For every class В of Т we have TI( Proof: Induction on Acc(A, ). We will see later that Martin-Löf's type theory with one universe containing a type atom(f) and one non-nested W-type is a theory in which we can define the accessible part of primitive recursive linear orderings. Lemma 4.3 Assume that (ОТ, -<) is a primitive recursive ordinal notation system, and Т is a theory such that Т proves induction over the natural numbers for arbitrary formulas, PRA can be interpreted in T, and we can define in Т the accessible part Acc(OT, -<). (a) If (/, nf) is a part of (ОТ, ) which is from below, then T I- Va r\\ nf(/) П Ace*./(a) r¡ Ace. (b) If (ОТ, ) is from below, then T h Т1(от )(B)for every class B. Proof: (a): We argue in T. Let В := Ace}. We have that TI (B) follows from TI(Acc,-<)(S') f° r some class B'. By assumption, the latter formula is provable; therefore it suffices to show Prog (B). Now assume а щ nf(/) Ace*, nf(/) Ace (this is called the main-IH). We show Ve f] ОТПА.Ь f(a) -> b r/ Ace—we call this formula (*)—by side-induction on length (b). If b _ a¿ for some i, then by a¡ r¡ Ace we have b r\\ Ace. Otherwise, b =NF f(b) with b ~ '(a); therefore by side-IHAce* , by main-IH b = f(b) r\\ Ace. By f(a) ц ОТ and Ace Ace we now obtain f(a) ц Асе. (b): This follows from (a) by induction on length(b) Vb r\\ OT.b r\\ Ace. We can now deduce transfinite induction on ОТ from induction over Ace. Therefore no ordinal notation system from below is sufficient to denote the proof- theoretic ordinal of a theory, in which we can define the accessible part for primitive recursive linear orderings. The following lemma allows us to reduce transfinite induction over the closure of a class by one application of an ordinal function from below to transfinite induction over the class itself: 254 A. Setzer Lemm a 4.4 Assume that (ОТ, ) is a primitive recursive ordinal notation system defined from ordinal functions (/,-, nf,;), the linearity of ч can be proved in PRA and that with f :— fn, nf := nfn (f, nf) и a part from be/ow. Let A be a free predicate, В : , Then is PRA- reducible to Tl(ornA,-0- Proof: Assume Prog (OTn ß ^(ß) . First we show ' by (main-)induction over ОТ П A. Assume a By Prog, (ß) we obtain ОТ .W e show by (side-)induction on , the ordering referred to in the definition of \" / is a part from below\", using that is PRA-reducible to Assume b ц (ОТ П A)*, j ] I and the assertion for We show _ _ L, we are done. Assume therefore therefore (and by main-IH, since b¡ or for some i by side-IH ' and the proof of (*) is complete. Now by Prog (ß) we obtain f(b) r] Q and the side induction is complete. Therefore we have ОТ П В П а с Q and the main induction is complete. By Prog(QTnß -<)(Ô) w e nav e Vb Ц ОТ П A.b ц Q. Now using the same proof as in the inductive proof above (using ОТ П А с Q instead of the main-IH), we show Vb г/ (ОТ П A)*.NP(/(£)) -> f(b) r/ Q and therefore Vb r\\ ОТ П B.b ц Q. Definition 4.5 (a) Let (ML) be the intensional Martin-Lof type theory in the polymorphic formula- tion with sets N, N,-, E, П, +, list and I, where I is the intensional identity type, using the logical framework. (b) In order to avoid having to write £1 we define x e (jci : AI ,... , x n : A n)B as x : (x\\ : AI, ... , Xfi : A n)£l(B); further, if in an expression (jci : A\\,... ,x n : A n) a variable is not mentioned, i.e. it is of the form (... , A,.. . ), this should be read as (... , x : £l(A), ... ) for a fresh variable x. (c) We write r = A s for I(A, r, s). В := N 2> false := 0 2, true := 1 2 . We write f(r) instead of Ap(/, r), which does not cause any confusion with the application of the logical framework function, since it is distinct from this by the arity of / . (d) (ML) + (atom) is the extension of (ML) by the type atom(i) with the following rules: atom : (B) Set, atom(false) = NO, atom(true) = NI. (e) (ML) + (atom) + (Oi) is the extension of (ML) + (atom) by the types Вг(л) and Oi (which stands for Kleene's O) with the rules Br : (N3) Set, Br(0 3) = NO, Вг(1з) = NI, Br(2 3) = N; Oi set, sup and the usual elimination rules for the W-type (f) Let (ML) + (atom) + (W) be the extension of (ML) + (atom) by the rules for the W-type. In (d) we chose the notation atom(i), which stands for \"atomic formula\" and is used by Schwichtenberg. In Smith (1988) atom(f) was denoted by T(a). An introduction to well-ordering proofs in Martin-Löf's type theory 255 In (e) the addition of the type Br(s) is not necessary. By using the type atom(i) it can be replaced by atom(/i (s)) + atom(/2(s)) x N, where I true if i = j fi(j3) = \\ . , -r • / • I false if г ф ]. It is only added to avoid coding. We can interpret PRA in a straightforward way into (ML) + (atom) + (Oi). Further we can define Ace in the following way. Definition 4.6 Let (ОТ, ) be a primitive recursive ordinal notation system from below. Let no N such that («о ц ОТ). (a) Let index (Oi)N3 andpred (w e Oí, Br(mdex(iu)))Oi suchthat index(sup(r, s)) = r and pred(sup(r, s), t) = s(t). (b) For , we define w[n] _ Oi such that $ир(0з, s)[n] = sup(C>3, s), supCls, s)[n] = s(0i), sup(23, s)[n] = s(n). (c) By recursion on / list(N) we define u>[/]n st Oi such that tu[nil]n st = w, w[cons(n, /)]iist = w[/i][/]iist- (d) Ace := {а щ ОТ 3w s O (.3 / (list(N) -> N).Correct(tu, /) /(nil) = N a], where Correct(w, /) := V/ e list(N)./(/) щ ОТ -> (index(w|7]iist) Va r/ OT.a /(/) -> /(append(/, cons(a, nil))) =N a) and append(/, I') is the concatenation of the lists /, /'. Correct(u), /) means that the function /, a labelling function for the subtrees of ш, is in accordance with the ordering of w. Lemm a 4.7 Ace as defined above is an accessible part for (ОТ, :). Proof: First we have to show that, if a £ N, p (a r¡ ОТ), q (ОТ Па с Асе), then а r¡ Асе. From q we can extract s (N)Oi and g (N, list(N))N such that, if и щ ОТ and n a, then index(j(n)) = 2з, g(n, nil) =N n, Correct(i(w), (l) g (a , /)), an d i f ОТ ) or , then index(i(n)) = 0 3, g(n, I) = и 0 (the element not in ОТ). We now define w :— sup(23,i) and / such that /(nil) = a, /(cons(n, /)) = g(n, I) and conclude Correct(w, /) and therefore а ц Асе. Further we have to show that, if В C1(N) and p Prog( 0T, (^) . then Асе с В. It suffices to show that for all ш Oí, / list(N) -> N, p Correct(w, /) /(nil ) ц В follows from /(nil) ц ОТ. This will be done by induction on w. From Correct(w, /), /(nil) f] ОТ we obtain ш = 8ир(2з, s) for some s, for all b ц ОТ, b /(nil) we have Correct(i(и), ./(cons(fe, /))), /(cons(2>, nil)) = N 6, b i) ОТ, b ц В, and therefore by Prog( ( (B) /(nil) ц В, the assertion. 5 Well-ordering proofs for (ML) + (atom) + (Oj) (ML) + (atom) + (Oi) allows us to define the accessible part. Therefore its proof- theoretic strength cannot be expressed in such systems and we need to define ordinal notation systems which are not from below. The traditional way of defining such sys- tems is to violate the condition (Below 1). The idea goes back to Bachmann (1950). We will follow the most refined version, introduced by Buchholz (1986). 256 A. Setzer We start with ordinal functions which are from below and take here CNF. Further we add one ordinal We will violate (Below 1) and define ordinals smaller than by using ordinals bigger than Therefore has to be chosen in such a way that these ordinals can be shown to be smaller than . One approach in order to obtain this is by choosing , the first uncountable cardinal and observing that the set of ordinals which are supposed to be below : form a countable segment of the ordinals and are therefore actually below . We will take this approach here. In a refined approach, one defines and observes that the set of ordinals below form a segment which can represented by a primitive recursive ordinal notation system and is therefore below As long as we add no further functions or only extend the part from below, we have not violated (Below 1) and can easily see that in fact we have defined an ordinal notation system from below. We add a function : Ord —> Ord, violating (Below 1), and defined by recursion on the first argument. In the ordinal notation system defined by CNF, ~ and , we will have a value , although we might later denote new ordinals below L_ using ordinals greater than ~ Therefore belowther e should only be ordinals' i which we can define before . \"Before, % , \" will now be defined similarly as for ordinal notation systems from below. Let / be the function unifying CNF, , (we need the additional constant 0 to reach the indices of the functions), namely ; and Then is defined before if a is lexicographically smaller than ß. The set of ordinals previously defined is the smallest set С (a) closed under / restricted to lexicographic smaller arguments than (2, a): the closure of under CNF and , ). Now , , , will be defined as the least ordinal which was not reached, i.e. := min We will see later that C(a) П Í2 is always a segment. If , then then • for min and_ _ _ 4_. ,. Therefore a good normal form foi , is NFi , and we will restrict by closing it underwit h arguments only in normal form. Definition 5.1 (a) We define Ord and simultaneously by recursion on i ~ ; ) is the least set such that closed under CNF applied to arguments in normal form, and, if , then (b) The normal forms of the functions L, --, and • are defined by П =NF Œ; NF(CNF) is defined as before (with the exception Lemma 5.2 (a) (b) An introduction to well-ordering proofs in Martin-Löf s type theory 257 (c) I f a i s a limit ordinal, then С (d) is a segment o/Ord. (e) where is the first fixed point ofkß.ca^ above £1 Proof: С (a) is countable, and therefore (d) follows by induction on a. The other proofs are easy. Remark: The only property needed for is that Lemma 5.2(a) holds (and that it is an -Number). Below we will see that for every a there is a primitive recursive ordi- nal notation system denoting all ordinals in i v ,, especially all ordinals below i. Therefore : and we can replace . The details of this argument can be found for instance in Rathjen (1993). Lemma 5.3 Let ßi,mi): (a) (b) (c) (d) (e) (f) is a system of ordinal functions with normalforms. Proof: (c) : We have that, if , then ] sup . (d) : therefore C(a). (f): (NF1) follows from Lemma 5.2(a) and the previous assertions of the lemma. (NF2): Assume (a\\,..., a¿) e dom(/¿), a¡ e Closure^ , p) =: Closure, S := i. If j we have nothing to prove. IfClosure , S = O e Closure, or S =NF ' > where the result of deleting some pairs (a, ni) at even positions in (a\\,..., a¿); therefore S e Closure. If then with a' := min(whic h exists, since i for some n e со) we have _ _ 1 , and Closure, .. _ Closure, Closure. Definition 5.4 Let. By induction on max{length(.y), lenjth(i)} we define simultaneously for ~~ whether t r\\ ОТ, and whether s ц C(t). We write . Further we define __ i. All functions and relations will be primitive recursive. Let /Г = N}. (a) (b) 258 A. Setzer and m\\ = 0, then s\\ is not of the form ijf(t') or £2; iff (which reduces to x) . If í = thenCNFi and CNF iff (c) ОТ iff . )iff (d) ОТ; (e) If for is not decided by (a)-(d) then t = r , or whetherhold s is decided by the above clauses and we define iff - Lemm a 5.5 Let ОТ, , С, Т be as in Definition 5.4. Then: (a) (ОТ, ) = (Oiy , f). (b) For a r\\ ОТ in set theory holds. (c) We can prove in PRA that for a, b r\\ ОТ we have a (d) (ОТ, -<) and С are primitive recursive and therefore Т defines a primitive recur- sive ordinal notation system. An outline of the well-ordering proof is as follows. Let Ace be the accessible part of the ordinals below £2 and define А„ as the closure of Ace under n times application of CNF. Using transfinite induction over Ace we conclude transfinite induction over Ace , which is АО. Using that CNF is from below we can show transfinite induction over А„ for every n (but not uniformly for all n). Using transfinite induction we can show that, i f a ~ ) , then ( , an d therefore sup i. We conclude , v..„ x__ , _,, . . . .__ Ace and, since Ace is a segment of ОТ, transfinite induction up to . Definition 5.6 (a) For a r\\ ОТ we define the finite subset (which can be represented as a list of natural numbers in type theory) by: I) (b) Since Ace is closed under CNF, Acc + is the closure of Ace U {Í2} under CNF and A n the closure of the same set under n times application of CNF. Lemma 5.7 In (ML) + (atom) + (Oi) we can show: (a) Ñ С Асе. (b) > (c) (d) For every n and every В 6 Cl (N) (these quantifiers are metaquantifiers) (e) For every Ace. AND An introduction to well-ordering proofs in Martin-Löf s type theory 259 (f) For every we have Prog( Proof: (b): By Lemma 4.3(a), since 0, CNF together form a part of (ОТ, ) which is from below, (c): By (b). (d): By metainduction on n for all B: n = 0: Assume Prog (ß). Since _ , we have Prog j ; therefore Va r¡ Ace.a by Prog (B) and therefore í i is the one-times closure of A n under CN F an d w e ca n r forms a part from below. (e): We show using TI( ) that ' Ace. Assume the IH. We show' , ...., , ,. by induction on length (c): .If with i , then , by IH ,, P(CNF(, iAce , ' . If, , , then Now the side-induction is complete and we have Ace, ОТ Асе, Асе. (f): hereforeAce , an d b y TI ( th e assertion follows. Corollary 5.8 (a) | (ML) + (atom) - = sup ( b) Ordinal notation systems from below have order type smaller than the Bachmann- Howard ordinal. Proof: (a): By Lemma 5.7(f). (b): 4.3(b), 4.7 and (a) of this corollary. Remark: This bound is sharp. 6 Well-ordering proofs for (ML) + (atom) + (W) We now extend the ordinal notation system and the well-ordering proof from the last section to Martin-Löf's type theory with full W-type. In the last section, using one non-nested W-type we could define the accessible part of any ordinal notation system ОТ and define Acc +, the class of ordinals such that the components below il\\ are in Ace. Further we could prove transfinite induction up to А„ := Ace ..,. , , and closure of А„ under V and therefore show transfinite induction up to Now, with no restrictions on the nesting of W-types, we can define the accessible part of any class, especially the accessible part Acci of Acc +. We can easily show that Ace ' Acc2 and that AcC2 is closed under any ordinal functions from below and i/f. Therefore we have transfinite induction over any ordinal notation system having a part from below, Q and An additional function which is not from below is needed in order to express the proof-theoretic ordinal of the theory considered. The method used is just an iteration of what we did before. Call the old , С now , Ci. We need to add an ordinal bigger than any ordinal for which we can prove ) by Lemma 4.4, since CNF 260 A. Setzer that it is in Acc2. We can use or in a refined approach, where , the next admissible ordinal above . Further, in order really to use \" w e need another collapsing function can now be defined similarly as before. However, in order not to interfere with the original , we want to guarantee that _ . _ . . _ Therefore we can define €2(01) as the closure of ! under CNF, $2(01) := min- _ . .. . We have to modify , i as well, since the original definition is constant above . Therefore we addt o C\\ (a) and close it under . We could close it under arbitrary ;, since the definition of is complete. However, in the generalization which follows we have to define collapsing functions for all >, and our first attempt would require them to be defined in decreasing order, which is not possible, since a> with the ordering is not well-founded. Instead we define ф\\ and simultaneously, which means that Ci(a) will be closed under instead of full _. We have already mentioned the extension to higher cardinals and collapsing func- tions and therefore get the following definition. Definition 6.1 (a ) Le t andfo r (b) We define simultaneously for all Ord and by recursion on а: С„(а) is the least set such that .. _ _ 0 is closed under CNF with arguments in normal form and if , then = min (c) The normal forms nfo, nfa, nfcNF. nfy of the ordinal functions 0, A.n.Œn, CNF and ar e defined b y , NF(CNF(o!i,/ii,..., <*/t, и/О) is defined as before, iff a. Lemm a 6.2 (a) (b) (c ) If a i s a limit ordinal, t a segment o f Ord. (e) Lemm a 6.3 Let y =NF (a) (b) (c) (d) ?????? ?????? As before we can define a primitive recursive ordinal notation system based on 0, CNF,. W e writeinstea d ofan d i/r^. ????? ? ??????? ?? ???? ?? ??? ??? ? ?????? ?? ??????? ????????? ???? d An introduction to well-ordering proofs in Martin-Lofs type theory 261 Remark 6.4 In (ML) + (atom) + (W) we can show: Definition 6.5 Assume (a) W A := Degree^«), where Degreeл (b) index and pred are defined as in Definition 4.6. (c) We define under the assumption w, w' : W ¿ the sets Ое§геед(таех(и/))-ргес w and (d) For w e WA we define ЬосСогд(1и) (w is locally correct) by: ЬосСогд(и;) := Vu DegreeA(index(iu)).mdex(pred( I. (Po is the projection of an element of a -type to its first component.) (e) For w WA we define Correct^ (w) (w is correctly defined) by: Correct (f) The accessible part of A is defined by: Acc(A) := {n | Bw e WA .Correct^ (w) л index(w) = «}. Lemm a 6.6 (a) w -<W A sup(r, s) о Эй e Degree A(r).í(«) =w ¿ w ; w ^w A sup(r, s) •& w =WA sup(r, j ) V 3« e DegreeA(r).iy ^WA í(«)- fèj LocCor/i(sup(r, í) ) o Vw e N.Vp e (и г ч г л т ц A).index(j(<m, p>)) = N m ; CorrectA(sup(r, s)) о LocCorA (sup(r, í) ) л Vm e N.V¿> e (m < г л m r¡ A).Correc^(í«m,/?))). fcj Acc(A) ¿í an accessible part of (A, -<) as defined in Definition 4.1. Proof: (a): Obvious, (b): By (a), (c): (Ace 1) follows, since using the assertion we can construct a correct tree from trees of the assumption, and we have that it is correct by (b). In order to conclude (Ace 2), we show that, under the assumption if Prog (/1 x ) (B), by induction on the trees Vw e \\Уд.Соггес1д(ш) -> index(iw) r) B. Definition 6.7 (a) By induction on length(a) we can define for а г/ ОТ, n e N, the component set K„(fl) relative to £2n, which is a finite subset of ОТ: К„(а) := {a}, if n > 1 л a x П„. Otherwise K„(0) := 0, K„(ß m ) := 0, K„(f m (a) ) := K„(a), K„(CNF(ai,ni,...,iz b n*) ) _,' = I (b) We define simultaneously by metarecursion on I ОТ and Асс„: Mo := ОТ, Асс„ := Асе l Remark 6.8 If n m, then ] 262 A. Setzer Lemma 6.9 (a) (b) (c) (d) (e) (f) (g) (h) Proof: (a): For a . (b): Induction on m using 6.8. (c): I , (d): . Accn is trivial. £2o ц Асс„. If , then by (a) and ~ . (e): By Lemma 4.3(a). (f): Induction . Assume the assumption for . We show then . Assume now ... _ .lib ,byside-I H ; therefore by side-IH and by main-IHАсс„ . The proof of (*) is now complete and we have an j (b), again We conclude (g): ; therefore ACCQ, and Acco, and from the assumptions about and the assertion follow, (h): Bibliography Aczel, P. (1972). Describing ordinals using functional of transfinite type. J. Symb. Logic 37 (1), 35-47. Bachmann, H. (1950). Die Normalfunktionen und das Problem der ausgezeichneten Folgen von Ordnungszahlen. Vierteljahresschrift der Naturforschenden Gesellschaft in Zürich, XCV, 5-37. Buchholz, W. (1986). A new system of proof-theoretic ordinal functions. Ann. Pure Appl. Logic, 32, 195-207. Buchholz, W. and Schütte, K. (1988). Proof theory ofimpredicative subsystems of anal- ysis, Bibliopolis, Napoli. ? ????? ????? ?? ???? ???????????? ?? and Otherwise and then An introduction to well-ordering proofs in Martin-Löf s type theory 263 Feferman, S. (1970). Hereditarily replete functionals over the ordinals. In: Kino, A., Myhill, J. and Vesley, R. E. Intuitionism and Proof Theory. Amsterdam, North- Holland, pp. 289-301. Gentzen, G. (1943). Beweisbarkeit und Unbeweisbarkeit von Anfangsfällen der trans- finiten Induktion in der reinen Zahlentheorie. Math. Ann., 119, 149-161. Griffor, E. and Rathjen, M. (1994). The strength of some Martin-Löf type theories. Arch. math. Logic, 33, 347-385. Howard, W. (1970). Assignment of ordinals to terms for primitive recursive functionals of finite type. In: Kino, A., Myhill, J. and Vesley, R. E. Intuitionism and Proof Theory. Amsterdam, North-Holland, pp. 303-326. Jäger, G. (1983). A well-ordering proof for Feferman's theory TQ. Arch. math. Logic, 23, 65-77. Martin-Löf, P. (1984). Intuitionistic type theory, Bibliopolis, Napoli. Nordström, В., Peterson, К. and Smith, J. (1990). Programming in Martin-Löf s type theory. An introduction, Oxford University Press, Oxford. Pohlers, W. (1989). Proof theory. An introduction. Springer Lecture Notes in Mathe- matics, vol. 1407, Springer, Berlin, Heidelberg, New York. Rathjen, M. (1991). Proof-theoretical analysis of KPM. Arch. math. Logic, 30, 377 - 403. Rathjen, M. (1993). How to develop proof-theoretic ordinal functions on the basis of admissible ordinals. Math. Logic Q., 39, (1), 47-54. Rathjen, M. and Weiermann, A. (1993). Proof-theoretic investigations of Kruskal's the - orem. Ann. Pure Appl. Logic, 60,49-88. Schütte, K. (1954). Kennzeichnung von Ordinalzahlen durch rekursiv definierte Funk- tionen. Math. Ann., 127,16-32 . Schütte, K. (1977). Proof Theory, Springer, Berlin, Heidelberg, New York. Seisenberger, M. (1994). Das Ordinalzahlbezeichnungssystem OT(#) und seine Ver- wendung von Kruskals Satz. Masters Thesis, University of Munich, Department of Mathematics. Setzer, A. (1993). Proof theoretical strength of Martin-Löf Type Theory with W-type and one universe, Ph.D . Thesis, University of Munich, Department of Mathematics. Setzer, A. (1994). A type theory for iterated inductive definitions, Draft manuscript. Setzer, A. (1996). Extending Martin-Löf Type Theory by one Mahlo-Universe, submitted. Setzer, A. (1998). Well-ordering Proofs for Martin-Löf Type Theory. Ann. Pure Appl. Logic, to appear. Smith, J. (1988). The independence of Peano's fourth axiom from Martin-Lofs type theory without universes. J. Symb. Logic, 53, 840-845. Troelstra, A. and van Dalen, D. (1988). Constructivism in mathematics. An introduc- tion. Vol. II. North-Holland, Amsterdam. This page intentionally left blank 14 Variable-free formalization of the Curry-Howard theory William W. Tait Department of Philosophy, University of Chicago The reduction of the lambda calculus to the theory of combinators in Schonfinkel 1924 applies to positive implicational logic, i.e. to the typed lambda calculus, where the types are built up from atomic types by means of the operation , , to show that the lambda operator can be eliminated in favour of combinators К and S of each type and i, respectively. ' I will extend that result to the case in which the types are built up by means of the general function type Ух : A.B(x) as well as the disjoint union type Эх : A.B(x)— essentially to the theory of Howard 1980. To extend the treatment of —>• to V we shall need a generalized form of the combinators К and S, and to deal with 3 we will need to introduce a new form of the combinator S (whose type turns out to be a general form of the axiom of choice). But also in the present context, if we are to eliminate variables, then not only the lambda operator for forming terms, but also quantification as a variable-binding operation for forming formulas must be analyzed away; so we will need an analogue of the combinators for formulas. As usual, we shall write if for the value s(t) of the function s for the argument t\\ so rst is (rO))(f), etc. Let D be a free variable of type A. We wish to rewrite the formulas B(v), V* : A.B(x) and Эх : A.B(x), respectively, as B'v, УВ' and 3ß', where B' is a type-valued function on A. If t(v) is a term of type B(v), which we express by t(v) : B(v) then /Ut : A.t(x) is a term of type Vx : A.B(x), denoting a function on A whose value for s : A is t(s) : B(s). We wish to rewrite the terms f (t>), AJC : A.t(x), respectively, as t'v : B'v and t' : VB'. Thus, a two-quantifier formula where Q\\ and Qi are quantifiers, is to be rewritten as 'This observation is essentially contained in the discussion of the so-called theory of functionality in Chapters 9 and 10 of Curry and Feys 1968. 266 W. W. Tait or or simply С\" is a function defined on A such that C\"s is a type-valued function defined on B's for all s : A. Let w and v be free variables of types A and B(u), respectively. A term t(u, t>) of type C(u, u) should be rewritten as i\"itu, where t\" is of type To discuss the general case, we need a definition. Definition 1 The notion of a base offunctionals is defined by induction: (1) The null sequence is a base. (2) If A is a type and FI, ..., F n are functions defined on A such that, for each t:A, (Fit, ..., F nt) is a base, then the sequence (A, F\\,..., F n) is a base. When (A, FI,..., F n) is a base, the base (A, FI, ..,, F n~\\} is uniquely determined by the functional Fn. As an example, in the two-quantifier example above, (А, В', С\") is a base. More generally, an n-quantifier formula 01*1 : ¿ l 02*2 : A2(xi)... Q nx n : A„(XI, ...,x„-i).B(xi,...,x n ) (0.1 ) is to be rewritten as where is a base, or simply as If i>i, i>2,..., vn are free variables of types respec- tively, then a term t(vi, V2,..., vn) of type ß(i>i, vi,. • •, vn) is to be rewritten as f(\"'uit)2 .. . v n , where t^ is of type In order to carry out this analysis, we need to introduce a formalism in which we can represent functionals and objects which depend upon free variables. 1 The calculus We must simultaneously define three notions: (1) The notion of a base of formulas. (a) Bases are finite sequences whose members are called formulas. (b) If (F, G) is a base, then F is called the base of G and denoted by Base(G). (c) When (A) is a base, A is called a (formula) type. (d) A base of formulas is intended to denote a base of functionals for suitable values of the free variables. Variable-free formalization of the Curry-Howard theory 267 (e) With a formula we may associate a rule of conversion, which specifies the meaning of the formula. (2) The notion of a term of type A, where Л is a type. (a) That t is a term of type A is expressed by í : A. (b) With a term we may associate a rule of conversion, which specifies the meaning of the term. (3 ) The notion of definitional equality between two terms or between two functionals. (a) We denote this relation by = . (b) We may specify at once that, for terms s and t, s = í is defined to mean s RED r At RED r for some r, where the relation RED is defined in the usual way in terms of the rules of conversion: call an occurrence of a formula or term X in a formula or term U external if it is not in a part of U of the form R(F), vn(A), P(H), K(G, Я) or SQ(H). For formulas or terms U and V, U > V will mean that V is obtained by replacing some external part X of U by Y, where X CONV Y. RED is the least reflexive and transitive relation which includes >. (c) For formulas F and G, F = G will mean that the base of F and the base of G are of the same length n > 0 and, for some distinct new symbols x\\, ..., x n, Fx\\ ... x n and Gx\\ ... x n RED to a common expression. 2 (d) We may also specify at once that the type of a term is to be determined only to within definitional equality. Thus, as a part of the definition of the type relation we specify that If , then (X, Y) will denotewil l denote will denote { ), etc. 1.1 Atomic formulas If F is a base of formulas none of which contains free variables, then is an atomic formula with base F for each n. There may be conversion rules associated with an atomic formula. 1.2 Instantiation If G has base i and í : A, then G t is a formula with base 1.3 Quantification If H has base < I, then VH and ЭЯ are formulas with base ^Notice that, in our definition, atomic formulas R(F), variables v(A), and terms K(G, H), SQ(H) and P(H) are in normal form, where a formula or term X is in normal form iff there is no Y such that X > Y. Thus, even when the distinct types A and В are =, u(A) ф v(B). However, nothing but simplicity hangs on this: we could extend the definition of ЕЕ by stipulating that A = В implies u(A) = v(B), and similarly in other cases. 268 W. W. Tait (1) If is not null and Q is a quantifier, then we have the conversion rule (2) The (universal) closure of a formula H is where the number of the V is the length of the base of Я. Thus, H* is a type. 1.4 Dummy argument places If ( and are bases, then so is (1) The rules of conversion for are (a) If (b) If. (2) Abbreviations: let Base(G) — Base(H) 1.5 Transposition of argument places If i is a base, then so is ). The subscript V in HI is metanotation, marking which formula in the base we are referring to; the '{/}', on the other hand, is part of the syntax of the formula H¡{i}. The rules of conversion are (1) If, (2) If, REMARK. In the second case, note that s must be a term of type VG and t must be of type F[VG]s, i.e. of type F. Since G has base F, st is defined and is of type Gt, by the principle of V elimination in §1.8 below. So H¡t(st) is defined. 1.6 Variables For each type A and vn(A) is called a free variable of type A. Note that A is a syntactical part of un(A). Variable-free formalisation of the Curry-Howard theory 269 1.7 Constants If A is a type containing no variables, zero or more constant terms of type A may be introduced. 1.8 Quantifier elimination Let (A, F) be a base. (1) V elimination (2) 3 elimination 1.9 Existential quantifier introduction Let H have base The conversion rules for Э are (1) If (2) If 1.10 ThecombinatorJT Let G and H have base , The conversion rules associated with К are (1) If (2) If 270 W. W. Tait 1.11 The combinators and Let H have base and let Q be a quantifier or Then The conversion rules are (1) If (2) Assume that ; and let has base Let s : and , . So t : F and (a) Let must be defined to be of type H{l}st, i.e. of type Ht(st). But st : Gt and so rt(st) : Ht(st). Thus, we may define )rs t by the conversion rule (b) Let Thus So But, and so rtl : Gt and rt2 : Ht(rt\\). So we may define 5з(Я ) by the conversion rules We have completed the description of the calculus. Notice that the type of is a general form of the axiom of choice: for example, let Я have base (А, В [A]). Then Я{1 } has base (A —> B, A[A —> B]) and the type \\ may be written as Vx : A3y : BHxy —> 3/ : A —> BVx : AHx(fx) Variable-free formalization of the Curry-Howard theory 271 2 Some properties of the calculus Let Var(X) denote the set of variables in the formula or term X. Definition 2 The type В of the term t is suitable for t iffVar(B) = Var(t) - {t}. Lemm a The following facts are easily derived. (1) Every variable in a formula in the base of F is in F. (2) Every term has a suitable type. (3) If G and H have bases and , respectively, then (4) If G and H both have base , then (5) Let F, G and H all have base Then Assuming that there are no further conversion rules, we may prove in the usual way: Theorem 1 (Church-Rosser theorem) If the formula or term X reduces to Y and to Z, then Y and Z reduce to some U. In particular, every term or formula has at most one normalform. Theorem 2 (Well-foundedness theorem) IfX is a formula or term, then every sequence ... is finite. In particular, every formula or term has a normal form. In view of these two theorems, the relation = between formulas and terms is decidable. We will not discuss general conditions on extensions of the calculus obtained by adding new conversion rules under which the Church-Rosser and well-foundedness theorems are preserved, since the main result of this paper, the explicit definition theorem below, will be preserved by any such extension. 3 Identity function Let G and H have base and let . Then S is of type which, by 3 and 4 of the lemma is = to (3.1) Let G be B[A] and let Я be C[A]. By 5 of the lemma, (3.1) is = to (A —> (B — » C)) — » ((A —+ B)-+(A-+ С)) (3.2) 272 W. W. Tait So Set i and i. Then KI : A —> and l _ Then Then Thus I A is the identity function on A. Notice that the combinators for positive implicational logic really are a special case of K(G, Я) and 5у(Я). Namely, they are K(A, ß) of type ) and of type (3.2). 4 Explicit definition theorem Definition 3 A variable v is unfettered in the term t (formula F) iff for every variable u(A) occurring in t (F), v does not occur in A. Note: If В is a suitable type for the term t, men v is unfettered in t iff it is unfettered inß . Theorem (Explicit definition theorem) Let v = v(A). (1)If(F\\,..., Fn) isabaseandv is unfettered in Fn, thenthere isabase such that Var and (2) If t : В and v is unfettered in t and in B, then there is a t' : Vß' such that Varí Var(t) - {v} and Note: If В = С, then В' = С'. So, in particular, given a term t in which v is unfettered, we need only find one type С of f in which v is unfettered and construct t' : VC'. If В is another type of t in which v is unfettered, then t' will be of type Vß' as well. Proof The proof is by induction on the definition of the base and term. Case 1. Assume that v does not occur in Fn. Then it does not occur in any F¡. Set F! = VIA]. Case 2. Assume that v is not in f and let ß be a suitable type for t. Then и is not in ß and so B' = B[A]. Set t' = K(B, A)t, which is of type Vß' = A —> В and t'vCONVt. In the remaining cases, we may assume that v occurs in the formula or term in question. Variable-free formalisation of the Curry-Howard theory 273 Case 3. Let us assume that F' is defined for F = G, F = H and for every formula F in the base of G or H. Then we may clearly set For example, . And K(G, H)'v = Note that K(G, Я) ' is of type , which is ' , , so the type is right. Case 4. Let F,- = G¡s, where s : С and (С, G\\,..., G„) is abase. Then (A, C\", G\\,..., G' n) is a base and t' : VC'. Set '. Then Case 5. Let Я have base (B), f : VH, and t : В. We need to define (ft)', f : W H', t' : VJ3' and has base is defined and is of type N '. So set ( '. For Case 6. Let p : ЭЯ, where Я has base B. We need to define (pi)' and (p2)'. p' : УЗЯ', where H' has base has base < . So Set i and I The proof is completed. We may now take Vx : A.B(x) to be an abbreviation for VB', providing the free variable i> = v (A) is unfettered in B(v). If v is fettered in B, then В has the form B(v, u(C(v))), where u(C(v)) is a variable and v is unfettered in C(v). But in this case, does not make any literal sense: u(C(x)) 274 W. W. Tait does not denote a variable of any particular type. Rather we can only think of it as a dependent variable, depending on the value of x. But then we may more accurately replace u(C(v)) by u(VC')v, eliminating at least one context which fetters v. Iterating this proceedure, we finally transform B(v) into a type D(v) in which v is unfettered and such that Vjc : A.D(x) expresses the only reasonable meaning of Vx : A.B(x). Similarly, we may restrict Xx : A.t(x) to the case in which v is unfettered in t(v), and in that case it is an abbreviation for t'. Now we return to the initial discussion of the n-quantifier form. Let В = B(v\\,..., v n~) be a formula and v\\,..., v n a list of variables including all the variables in B, . Assume that the list of variables is in good order, i.e. implies that u ;- does not occur in A,-. So we may write . , displaying all the free variables. Then v n is unfettered in В and we may apply the explicit definition theorem to obtain B' with base (A n), containing at most the variables u,- for г < n and such that is unfettered in B' and so we may construct B\" with base containing at most the variables щ for , such that . Iterat- ing n times, we obtain the variable-free formula B^ with base such that Then (0.1) is precisely Moreover, if í = t(v\\,..., Vn) is a term of type B(v\\,..., v n), then n applications of the explicit definition theorem yield with Bibliography Curry, H. and Feys, R. (1968). \"Combinatory Logic I\", North-Holland, Amsterdam. Howard. W. (1980). The formula-as-types notion of construction, in \"To H. B. Curry: Essays on Combinatory Logic, Lambda Calculus and Formalism\", J. P. Seldin and J. R. Hyndley, eds, Academic Press, London, pp. 479-490. Schönfinkel, M. (1924). Über die Bausteine der mathematische Logik., Mathematische Annalen 23, pp. 123-153. 15 The forget-restore principle: a paradigmatic example Silvio Valentini Dipartimento di Matemática Pura edApplicata, Università di Padova 1 Introduction The aim of this paper is to give a simple but instructive example of the forget-restore principle, conceived by Giovanni Sambin as a discipline for a constructive development of mathematics and which first appeared in print in the introduction of Sambin and Valentini 1998. The best way to explain such a philosophical position is to quote from that paper: \"To build up an abstract concept from a raw flow of data, one must disre- gard inessential details ... this is obtained by forgetting some information. To forget information is the same as to destroy something, in particular if there is no possibility of restoring that information ... our principle is that an abstraction is constructive ... when information .. . is forgotten in such a way that it can be restored at will in any moment.\" The example we want to show here refers to Martin-Löf's intuitionistic type theory (just type theory from now on). We assume knowledge of the main peculiarities of type theory, as formulated in Martin-Löf 1984 or Nordström et al. 1990. Type theory is a logical calculus which adopts those notions and rules which keep total control of the amount of information contained in the different forms of judgement. However, type theory offers a way of \"forgetting\" information: that is, supposing A set, the form of judgement A true. The meaning of A true is that there exists an element a such that a e A but it does not matter which particular element a is (see also the notion of proof irrelevance in de Bruijn 1980). Thus to pass from the judgement a e A to the judgement A true is а clear example of the forgetting process. We will show that it is a constructive way to forget since, provided that there is a proof of the judgement A true, an element a such that a e A can be reconstructed. Of course the simple solution of adding only the rule allows us to obtain such a result but is completely useless in practice. In fact, it does not allow us to operate with judgements of the form A true and, in our experience, judgements of this form are essential in developing constructive mathematics, as for 276 S. Valentini instance in formai topology, and in developing metamathematical arguments (see for instance Sanibin and Valentini 1998 and Maietti and Valentini 1997). To obtain the same result, but avoiding this limitation, we provide a general calculus for expressions, directly inspired by Martin-Lofs Siena lectures in April 1983 (see Bossi and Valentini 1989). This calculus was first published in Valentini 1996 and is similar for instance to that in Nordström et al. 1990. The advantage of our calculus with respect to the other ones present in the literature is that its rules, not only allow us to express all of the judgements of basic type theory, but also permit a rigorous treatment of judgements of the form A true. 2 The multi-level typed ^.-calculus The first idea for the definition of our calculus is to use a sort of simple typed Л-calculus (see Barendregt 1992). In this way it is possible both to abstract on variables and to preserve a decidable theory of equality, which is an essential feature to describe any logical system since decidability is necessary in order to recognize the correct applica- tion of the inference rules. On the other hand, to describe type theory a simple typed Л-calculus is not sufficient. Thus we define the following multi-level typed À-calculus: the intuitive idea is to construct a tower of dependent typed A.-calculi, each one over another, marked by a level. Hence the rules of the multi-level typed A.-calculus are those of a simple typed A.-calculus enriched by a label which specifies the level. The assumption rule states that, if N is an expression of level greater than zero, then we may assume it to be inhabited. The weakening rule states that we may add assumptions of the form x :,-_i N provided that the level of N is greater than zero. Abstraction and application are as usual, except that they apply to any level; note that they do not change the level of an expression. These rules by themselves are not sufficient to develop any logical calculus since no expression can be assigned a type because to prove the conclusion of a rule one should have already proved its premise(s). So, in order to start, one needs some axioms. The first thing one has to do is to settle the maximum level m needed to describe a particular theory; to this end we will introduce the symbol * to indicate the only type of the highest level. One can then define all the other types downward from * by means of axioms of the form Ь с : т * for some constant c. Note that the only elements of * are constants. Then, all the other axioms will have the form for some constant с provided that and there exists a type N such that It is (assumption) (weakening) (abstraction) (application) The forget-restore principle: a paradigmatic example 211 not difficult to recognize here some analogies with the approach to typed A-calculi used in the pure type systems approach (see Barendregt 1992). In the case of type theory, we define a chain to mean that a is an element of A which is a set, i.e. an element of set, which is the only element of *. Thus our first axiom is We can now begin our description of type theory; to this end we will follow the informal explanation by Martin-Löf in Martin-Löf 1984. We start by stating an axiom which introduces a constant for each set-constructor in correspondence with each for- mation rale of type theory. For instance, suppose we want to describe the set П(A, B)\\ to this end we add the axiom which means that П is a set-constructor constant which gives a new set when applied to the set X and to the prepositional function Y on elements of X. It is straightforward to verify that this is a correct axiom since The next step corresponds to the introduction rule(s): we add a new axiom for each kind of canonical element. Let us again consider the case of the set П(Л, В); then we put which states that, if X is a set, У is a propositional function on elements of X and у is a function which gives a proof of Y(x) for any x in X, then A(X, Y, y) is an element of the set . Thus this axiom is just a rephrasing of the П-introduction rule in Martin-Löf 1984. Also the elimination rule becomes a new axiom; it defines the term-constructor constant introduced by the elimination rule. For instance, for the set П (A, B), following the standard elimination rule (see the introduction of Martin-Löf 1984), we put which states that, if X is a set, У is a propositional function on elements of X, Z is a propositional function on elements of I c is an element of ) and d is a method which maps any function у from x in X to Y (x) into an element of Z(),(X, Y, >>)), then F(X, Y, c, d) is an element of Z(c). In a similar way all of the rules of type theory become axioms of the multi-level typed Л-calculus. 278 S. Valentini The notion of level will not be necessary to prove the main theorem of this paper but it is useful to prove that the multi-level typed -calculus is normalizing. In fact, because of the presence of the levels, the multi-level typed -calculus is obtained by just putting together many dependent typed .-calculi with constants which cannot interact with each other. Hence one can adapt to this framework any normalization proof for a dependent typed Л-calculus present in the literature (cf. Capretta and Valentini 1997). Anyway, in order to simplify the notation, in the following we will not write all the indexes of the levels whenever they are not necessary. 3 The judgement A true The main novelty of our approach with respect to a standard simple typed ^.-calculus, besides the notion of level, is that, besides the judgements of the form N : M together with their rules, we can also introduce here the new form of judgement \"M true\", whose intended meaning is that the type M is inhabited. The rules we require on this form of judgement are completely similar to those for the judgement W : M in the previous section. This fact will be crucial in the proof of the next theorem 3.1 which links the judgements of the form W : M with those of the form M true. (assumption) (weakening) (abstraction) (application) It may be useful to note that in most of the previous rules, besides judgements of the form M true, it is necessary to use also those of the form W : M and thus this calculus cannot be expressed independently from the previous one. As for the judgements of the form N : M in the previous section, no type M can be proved to be inhabited, i.e. M true, unless some specific axioms are added. The intended meaning of the judgement M true suggests adding the axiom ' true whenever an axiom of the form : M is present for some constant c. For instance, when we consider the set П(А, В) we will add the following two axioms: which state that the type (X : set)(Y : (x : X) set)(y : (x : X) Y(x)) П(Х, Y) is inhabited; by using it, one can prove for instance that Г 1- П(А, ß) true, provided that : set and : set and . \\ true hold, since if true holds then, by the next theorem 3.1, it is possible to construct an expression b such that The forget-restore principle: a paradigmatic example 279 which shows true provided that (1) : set, (2) : : set, (: : set, (4) and (5) : (x : A) B(x) С (А. (А, В, у)) true hold. Note that, if the set С (г) does not depend on z, the last axiom can be simplified to obtair ' true provided that set, since, by theorem 3.1, true implies that there exists an element с such that I. Since the rules for the judgement N : M are completely similar to those for the judgement M true and whenever an axiom of the form is added to the calculus the axiom ' r true is also added, we can prove the following theorem 3.1. It allows us to give a formal counterpart of the intended meaning of the judgement true. Its proof, in one direction, shows how to reconstruct a witness for the judgement M true while, in the other, it shows how it is possible to forget safely. Theorem 3.1 Let be any set of axioms of the form for some constant с and type K, and let * be obtained from by suitably substituting some of the axioms } in ~ with the corresponding axiom true. Thentrue is derivable from * if and only if there exists an expression N such that : M is derivable from Proof In both directions the proof is by induction on the given proof. When we are \"forgetting\" we must start from below so that we know what can be forgotten. Let us show the inductive steps (provided is a proof, we will write to mean the proof obtained by inductive hypothesis). (axiom) (assumption) (weakening) (abstraction) trueandtrue hold 280 S. Valentini (application) It should now be clear how we obtain the set of axioms from the set of axioms : we have to change only those axioms which appear in a modified proof and this is the reason why we have to \"forget\" from below: for instance, in the rules of weakening or application only one of the premises is modified and only the axioms on that premise have to be changed. For the other case, when we are \"restoring\", we must start from above in such a way that an axiom (possibly in £*) is replaced with a suitable instance of an axiom (in ). (axiom) (assumption) (weakening) (abstraction) (application) It is worth noting that in the process which transforms the proof of I first into true and then into we will not in general obtain the same element, i.e. N and N' may differ for the constants used in the axioms with the same type. The forget-restore principle: a paradigmatic example 281 4 Final remarks What we have illustrated in the previous sections is just an example of the process of \"forgetting\"; for instance, as one of the referees of this paper has suggested, one could also consider the judgements M type and M element as a forgetting abbreviation for the judgement M \\j N with j > 0 and j = 0 respectively and develop for these judgements a suitable calculus analogous to the one we proposed for the judgement M true. Moreover, it should be clear that what we have done is just a simple illustration of the forget-restore paradigm and that it is not a complete description of a full theory for judgements of the form A true within type theory. In fact we chose to develop a dependent type multi-level À-calculus since it is well suited for the framework of Martin-Löf's dependent type theory that we have described, but it is not of immediate application if we also consider the non-dependent part of the theory, as for instance when we define A ->• В as П(А, (x : A) B) provided that the proposition В does not depend on the elements of A. For instance, the rule is admissible in our system but it is not derivable; hence we have too weak a theory for judgements of the form A true. To solve this problem the first step is to be able to deal also with assumptions of the form A true, instead of only those at the form x : A, when the variable x does not appear in the conclusion В true. This is not possible in a general dependent type calculus since even a conclusion of the form В true may in general depend on the variables in the assumptions. We can obtain this result if, when performing the forgetting process, we also take into account which variables appear in the types in the conclusion of a rule. Thus we will have the following transformation of a full proof into a. forgetting one: (assumption) - since the variable x is introduced by the rule and hence cannot appear in N; (weakening) since the variable x is assumed by weakening and hence it cannot appear in L. The case of the abstraction rule (abstraction) 282 S. Valentini deserves a more detailed analysis; in fact we can surely use the transformation that we have proposed in the proof of theorem 3.1, but, provided the variable x does not appear in L, the following transformation can also be used where we have introduced the new notation ((N)L) to mean that the abstracted variables does not appear in the body of the abstraction. Finally, also for the application rule (application) two transformations are possible according to the variables which appear in the conclu- sion. The first is the one that we used in the proof of theorem 3.1 and it can be applied in any case. However, provided M does not depend on x, it is possible also to use the following: It is now possible to change the form of the axioms. Here we will give only a simple example. Suppose that we want to introduce the type A -> B. Then we need the following axioms: If we now consider the transformations used in the prove of theorem 3.1 we obtain but, provided that we also use the notation ((Х)У) for the abstractions when Y does not depends on the elements in X, we can add to them the following new axioms: and it is straightforward to use the last one to derive the rule The forget-restore principle: a paradigmatic example 283 Since any of the new axioms is the result of a forgetting process from a standard axiom and we can restore it simply by adding the abstracted variables, which can be done in an algorithmic way, this is again an instance of a constructive way of forgetting and a theorem like theorem 3.1 can be proved also in this case. Bibliography Barendregt, H. P. (1992). Lambda-calculi with types, in \"Handbook of logic and com- puter science\", vol. II, S. Abramski, D. M. Gabbay and T. S. Maibaum, eds, vol. 2, pp. 118-309, Oxford University Press. Bossi, A. and Valentin!, S. (1989). The expressions with arity, internal report, Dip. Scienze dell'Informazione, Univ. Milano N. 61/89. Capretta, V. and Valentini, S. (1997). A general method to prove the normalization theorem for first and second order typed X-calculi, to appear. de Bruijn, N. G. (1980). A survey of the project Automath, in \"To H. B. Curry: Essays on Combinatory Logic, Lambda Calculus and Formalism\", J. P. Seldin and J. R. Hyn- dley, eds, Academic Press, London, pp. 589-606. Maietti, M. E. and Valentini, S. (1997). Why you should not add power-set to Martin- Löf intuitionistic set theory, to appear. Martin-Löf, P. (1984). \"Intuitionistic type theory\", notes by Giovanni Sambin of a series of lectures given in Padua, June 1980, Bibliopolis, Naples. Nordström, В., Petersson, К. and Smith, J. M. (1990). \"Programming in Martin-Lofs Type Theory, an introduction\", Clarendon Press, Oxford. Sambin, G. and Valentini, S. (1998). Building up a toolbox for Martin-Löf s type theory: subset theory, this volume. Valentini, S. (1996). Another introduction to Martin-Löf's Type Theory, in \"Trends in Theoretical Informatics\", R. Albrecht and H. Herré, eds, Schriftenreihe der Österreichischen Computer Gesellscaft, Bd. 89, München.","libVersion":"0.2.3","langs":""}